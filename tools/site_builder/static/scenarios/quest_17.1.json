{
  "_meta": {
    "input_hash": "a26f0b46424d75fa34010eb8b7949f43"
  },
  "scenario": [
    {
      "command": "pip install \"fastapi[all]\"",
      "output": "Collecting fastapi[all]\n  Downloading fastapi-0.115.2-py3-none-any.whl (92 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.2/92.2 kB 5.2 MB/s eta 0:00:00\nCollecting Starlette<0.41.0,>=0.37.2 (from fastapi[all])\n  Downloading starlette-0.40.0-py3-none-any.whl (70 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.8/70.8 kB 8.1 MB/s eta 0:00:00\nCollecting pydantic<3,>=2 (from fastapi[all])\n  Downloading pydantic-2.9.2-py3-none-any.whl (436 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 436.8/436.8 kB 12.3 MB/s eta 0:00:00\nCollecting \"uvicorn[standard]>=0.30.1\" (from fastapi[all])\n  Downloading uvicorn-0.32.0-py3-none-any.whl (84 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.7/84.7 kB 9.4 MB/s eta 0:00:00\nCollecting python-multipart (from fastapi[all])\n  Downloading python_multipart-0.0.9-py3-none-any.whl (23 kB)\nCollecting itsdangerous<3.0.0,>=2.1.2 (from fastapi[all])\n  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nInstalling collected packages: itsdangerous, python-multipart, pydantic, h11, click, watchfiles, uvloop, uvicorn, typing-extensions, starlette, pyvicorn, fastapi\nSuccessfully installed click-8.1.7 fastapi-0.115.2 h11-0.14.0 itsdangerous-2.2.0 pyvicorn-0.1.0 pydantic-2.9.2 python-multipart-0.0.9 starlette-0.40.0 typing-extensions-4.12.2 uvicorn-0.32.0 uvloop-0.20.0 watchfiles-0.24.0"
    },
    {
      "command": "uvicorn quest_17_1:app --reload",
      "output": "Призываю 'Духа Эмоций' для нашего амулета...\nAll model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n\nSome weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertForSequenceClassification: ['classifier.weight', 'classifier.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nNo `TrainingArguments` passed..., referring to the AutoModel docs: https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModel\n'Dух Эмоций' готов к работе.\nINFO:     Will watch for changes in these directories: ['/home/user']\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [28765] using WatchFiles\nINFO:     Started server process [28767]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)",
      "is_final": true
    }
  ]
}
