"""Квест 6.2: Обучение классификатора.

Этот пергамент — кульминация ритуала Transfer Learning для аудио. Его
главная цель (МАКРО-контекст) — доказать, что можно обучить очень точный
классификатор, используя всего лишь горстку примеров и простую модель.

Мы берем "эссенции голоса", извлеченные могущественным "Духом-Эмпатом" в
предыдущем квесте, и используем их как "учебник" для нашего собственного,
крошечного "Голема-Ученика" (`nn.Linear`). Мы проводим полный ритуал
"ручного" обучения, шаг за шагом показывая, как Голем учится "читать" эти
"эссенции" и выносить вердикт. Этот квест доказывает, что можно стоять на
плечах гигантов для решения своих, узкоспециализированных задач.
"""

# --- Акт 1: Подготовка Гримуаров ---
# Первый акт: мы призываем все необходимые знания и инструменты для ритуала.

# Мы призываем наш главный силовой гримуар `PyTorch`.
import torch

# Мы призываем `nn` — главу гримуара PyTorch со "строительными блоками"
# для моделей.
import torch.nn as nn

# Мы призываем `optim` — главу гримуара с "методами исправления ошибок"
# (оптимизаторами).
import torch.optim as optim

# Мы призываем `T` — главу гримуара `torchaudio` с заклинаниями для
# аудио-трансформаций.
import torchaudio.transforms as T

# Мы призываем "Библиотекаря" `load_dataset` для работы с архивами.
from datasets import load_dataset

# Мы призываем наш "индикатор прогресса" `tqdm`, чтобы видеть, как идет ритуал.
from tqdm import tqdm

# Мы призываем "Настройщика Слуха" и "Духа-Эмпата" из `transformers`.
from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model

# --- Акт 2: Призыв Инструментов и Данных ---
# Второй акт: мы призываем Духа-Эмпата и готовим архив с аудио для анализа.

# Мы оглашаем на кристалл (консоль) о начале ритуала призыва.
print("Призываю Духа-Эмпата и Настройщика Слуха...")
# Мы призываем "Настройщика Слуха", обученного специально для модели
# 'wav2vec2-base'.
feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
    "facebook/wav2vec2-base"
)
# Мы призываем самого "Духа-Эмпата". 'base' — это его средняя по размеру и
# силе версия.
model_extractor = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
# Мы немедленно отправляем Духа-Эмпата на Кристалл Маны (GPU).
model_extractor.to("cuda")

# Мы оглашаем, что обращаемся к нашей локальной сокровищнице с данными.
print("Загружаю данные из локальной сокровищницы...")
# Мы загружаем датасет 'PolyAI/minds14' из локального кэша (скачан ранее).
# `trust_remote_code=True` — это обязательное заклинание для запуска
#  "свитка-инструкции" этого архива.
full_dataset = load_dataset(
    "PolyAI/minds14", name="en-US", split="train", trust_remote_code=True
)

# --- Акт 3: Создание "Учебника" из Эссенций ---
# Третий акт: мы создаем учебные материалы для нашего будущего Голема.

# Мы оглашаем на кристалл о начале создания наших учебных материалов.
print("\nСоздаю учебные материалы: 50 досье и меток...")
# Мы готовим пустой "ящик" (список) для хранения "эссенций"-досье.
embeddings = []
# Мы создаем второй пустой "ящик" (список) для хранения "меток"-ответов.
labels = []

# Мы произносим заклинание `select(range(50))`,
#  чтобы взять только первые 50 записей из архива.
# `tqdm` оборачивает этот процесс в "индикатор прогресса".
for sample in tqdm(full_dataset.select(range(50)), desc="Извлечение эссенций"):

    # Мы извлекаем "сырые вибрации" (числовой массив) из образца.
    audio_data = sample["audio"]["array"]
    # Мы также извлекаем "паспорт" звука (частоту дискретизации).
    original_sampling_rate = sample["audio"]["sampling_rate"]

    # Мы проводим ритуал "Передискретизации": если частота не равна 16000 Гц...
    if original_sampling_rate != 16000:
        # ...мы создаем заклинание-трансформатор для исправления частоты.
        resampler = T.Resample(
            orig_freq=original_sampling_rate, new_freq=16000
        )
        # И применяем его, чтобы привести звук к каноническому виду.
        audio_data = resampler(
            torch.tensor(audio_data, dtype=torch.float32)
        ).numpy()

    # Мы повторяем ритуал извлечения "эссенции" из предыдущего Квеста.
    inputs = feature_extractor(
        audio_data, sampling_rate=16000, return_tensors="pt"
    ).to("cuda")
    # Используем защитное заклинание `no_grad` для экономии маны.
    with torch.no_grad():
        # Просим Духа-Эмпата извлечь "эссенцию".
        outputs = model_extractor(**inputs)
    # Усредняем "эссенцию" во времени, чтобы получить единый "отпечаток".
    essence = outputs.last_hidden_state.mean(dim=1)

    # Мы кладем полученную "эссенцию" в один ящик...
    embeddings.append(essence)
    # ...а ее "метку" (правильный ответ) — в другой.
    labels.append(sample["intent_class"])

# Мы "склеиваем" (`cat`) отдельные "эссенции" в один большой тензор для
# обучения.
embeddings_tensor = torch.cat(embeddings)
# Мы превращаем список номеров-меток в тензор и отправляем на Кристалл Маны.
labels_tensor = torch.tensor(labels).to("cuda")

# --- Акт 4: Создание Нашего Голема-Ученика ---
# Четвертый акт: мы создаем нашего собственного, очень простого Голема.

# `nn.Linear` — это чертеж простейшего "нейронного слоя".
# `in_features=768` — его "глаза" рассчитаны на 768 чисел (размер нашей "эссенции").
# `out_features=14` — его "рот" выдает 14 чисел (по числу классов в датасете).
classifier = nn.Linear(in_features=768, out_features=14).to("cuda")

# --- Акт 5: Ритуал Наставления (Ручной режим) ---
# Пятый, кульминационный акт: мы проводим урок для нашего Голема.
print("\nНачинаю ритуал наставления...")
# Мы создаем "Рулетку" (`CrossEntropyLoss`) для измерения ошибки классификации.
criterion = nn.CrossEntropyLoss()
# Мы создаем "Волшебный Ключ" (`Adam`) для исправления ошибок.
# Мы передаем ему "настройки" нашего ученика (`classifier.parameters()`)
# для "подкрутки".
optimizer = optim.Adam(classifier.parameters(), lr=0.01)

# Мы повторяем урок 100 раз (эпох).
for epoch in tqdm(range(100), desc="Обучение классификатора"):
    # Шаг 1: Мы стираем старые ошибки, чтобы начать урок с чистого листа.
    optimizer.zero_grad()
    # Шаг 2: Наш ученик делает предсказание на основе всех "эссенций".
    outputs = classifier(embeddings_tensor)
    # Шаг 3: Мы измеряем, насколько предсказание отличается от правильных
    # ответов.
    loss = criterion(outputs, labels_tensor)
    # Шаг 4: Мы вычисляем, как именно нужно "подкрутить" настройки, чтобы
    # исправиться.
    loss.backward()
    # Шаг 5: Мы используем "Волшебный Ключ", чтобы реально "подкрутить"
    # настройки.
    optimizer.step()

    # Каждые 10 эпох мы выводим отчет о том, как уменьшается ошибка.
    if (epoch + 1) % 10 == 0:
        # Мы печатаем номер эпохи и текущее значение ошибки.
        print(f"  Эпоха {epoch + 1}/100, Ошибка (Loss): {loss.item():.4f}")

# Мы оглашаем, что ритуал Наставления завершен.
print("Ритуал завершен! Наш Голем-Классификатор обучен.")

# --- Акт 6: Ритуал Сохранения Знаний ---
# Финальный акт: мы запечатываем знания нашего Голема в артефакт.

# Мы даем имя нашему артефакту, который будет хранить знания Голема.
save_path = "voice_classifier_knowledge.pth"
# `torch.save` — это главное заклинание для сохранения.
# `classifier.state_dict()` — это "слепок разума" нашего ученика,
#  его обученные "настройки"-веса.
torch.save(classifier.state_dict(), save_path)
# Мы оглашаем, что знания Голема надежно запечатаны.
print(f"\nЗнания Голема-Классификатора запечатаны в артефакт: '{save_path}'")
