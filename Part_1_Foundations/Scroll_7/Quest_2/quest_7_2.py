# === quest_7_2.py ===
# Имя этого пергамента, хранящего самый сложный ритуал Наставления.
# Квест: 7.2 - Ритуал "Стилевой Печати"
# Каноническое имя Квеста, как оно записано в Великом Кодексе.
# Цель: Обучить "магический блокнот" (LoRA) на нашей палитре изображений,
# чтобы запечатать в него суть нашего художественного стиля.
# Священная цель нашего ритуала.
# Это самый сложный ритуал Наставления на данный момент.
# Предупреждение о высокой сложности и требовательности этого ритуала.

# --- Акт 1: Подготовка Гримуаров ---
# Первый акт: мы призываем все необходимые знания и инструменты для ритуала.

# Мы призываем "Духа-Архивариуса" (`os`), который знает всё о файлах и папках.
import os

# Мы призываем наш главный силовой гримуар `PyTorch`.
import torch

# Мы призываем главу гримуара `functional` с "мерами ошибок" (loss functions).
import torch.nn.functional as F

# Мы призываем "Библиотекаря" `load_dataset` для работы с нашими картинами.
from datasets import load_dataset

# Мы призываем "строительные блоки" Демиурга по отдельности.
from diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel

# Мы призываем магию "блокнотов" из гримуара `peft`.
from peft import LoraConfig, get_peft_model

# Мы призываем гримуар `torchvision.transforms` для трансформаций образов.
from torchvision import transforms

# Мы призываем наш верный "индикатор прогресса".
from tqdm import tqdm

# Мы призываем "Переводчика" и "Кодировщик Текста" из гримуара `transformers`.
from transformers import CLIPTextModel, CLIPTokenizer

# --- Акт 2: Настройка Ритуала ---
# Второй акт: мы устанавливаем все правила и параметры нашего ритуала.
print("Акт 1: Настройка Ритуала...")
# Мы указываем имя базового Духа-Демиурга, на основе которого будем творить.
model_id = "CompVis/stable-diffusion-v1-4"
# Мы указываем путь к папке с нашими "учебными картинами".
palette_dir = "generated_palette"
# Мы даем имя папке, куда мы сохраним нашу обученную "Стилевую Печать".
output_dir = "artist_seal"
# Мы создаем эту папку, если ее еще не существует.
os.makedirs(output_dir, exist_ok=True)

# Мы устанавливаем параметры обучения, адаптированные для нашего Кристалла
# Маны.
resolution = 256
# Устанавливаем размер порции (батча) для обучения.
train_batch_size = 1
# Устанавливаем, через сколько шагов накапливать и применять "опыт"
# (градиенты).
gradient_accumulation_steps = 4
# Устанавливаем "скорость обучения".
learning_rate = 1e-4
# Устанавливаем общее количество эпох (полных проходов по "учебнику").
num_train_epochs = 100

# --- Акт 3: Подготовка "Учебника" ---
# Третий акт: мы загружаем наши картины и готовим их к уроку.
print("Акт 2: Подготовка Учебника...")
# Мы загружаем наши картины из локальной папки как датасет.
dataset = load_dataset(palette_dir, trust_remote_code=True)

# Мы создаем конвейер "магических линз" для аугментации и подготовки.
preprocess = transforms.Compose(
    # Начало списка трансформаций.
    [
        # Первая "линза": уменьшает размер картин до 256x256.
        transforms.Resize((resolution, resolution)),
        # Вторая "линза": случайно отражает картины по горизонтали для
        # разнообразия.
        transforms.RandomHorizontalFlip(),
        # Третья "линза": превращает картину из объекта Pillow в тензор
        # PyTorch.
        transforms.ToTensor(),
        # Четвертая "линза": нормализует цвета в диапазон [-1, 1].
        transforms.Normalize([0.5], [0.5]),
        # Конец списка трансформаций.
    ]
)


# Мы создаем функцию-помощника, которая будет применять этот конвейер к
# каждой картине.
def apply_transforms(examples):
    # Мы проходимся по каждой картине в порции (`batch`) и применяем к ней
    # конвейер.
    images = [preprocess(image.convert("RGB")) for image in examples["image"]]
    # Мы возвращаем результат в формате, понятном датасету.
    return {"input": images}


# Мы "прикрепляем" нашего помощника к датасету, чтобы он работал "на лету".
dataset.set_transform(apply_transforms)
# Мы создаем "подносчик", который будет подавать нам данные на урок порциями.
train_dataloader = torch.utils.data.DataLoader(
    # Мы указываем, какой датасет использовать (тренировочную часть).
    dataset["train"],
    # Мы указываем размер порции (батча).
    batch_size=train_batch_size,
    # Мы приказываем перемешивать картины перед каждой эпохой.
    shuffle=True,
)

# --- Акт 4: Призыв Компонентов и Создание "Блокнота" ---
# Четвертый акт: мы призываем всех духов-помощников и создаем "блокнот".
print("Акт 3: Призыв компонентов...")
# Мы призываем всех помощников Демиурга по отдельности.
tokenizer = CLIPTokenizer.from_pretrained(model_id, subfolder="tokenizer")
# Мы призываем "Кодировщика Текста".
text_encoder = CLIPTextModel.from_pretrained(
    # Указываем имя базовой модели.
    model_id,
    # Указываем подпапку, где лежит его сущность.
    subfolder="text_encoder",
    # Приказываем загружать его в "легком" 16-битном формате.
    torch_dtype=torch.float16,
)
# Мы призываем "Проявителя" (VAE), который переводит образы в латентное
# пространство.
vae = AutoencoderKL.from_pretrained(
    # Указываем имя базовой модели.
    model_id,
    # Указываем подпапку, где лежит его сущность.
    subfolder="vae",
    # Приказываем загружать его в "легком" 16-битном формате.
    torch_dtype=torch.float16,
)
# Мы призываем "Духа-Скульптора" (UNet), сердце Демиурга.
unet = UNet2DConditionModel.from_pretrained(
    # Указываем имя базовой модели.
    model_id,
    # Указываем подпапку, где лежит его сущность.
    subfolder="unet",
    # Приказываем загружать его в "легком" 16-битном формате.
    torch_dtype=torch.float16,
)

# Мы создаем "чертеж" для нашего "магического блокнота" LoRA.
lora_config = LoraConfig(
    # "Толщина" блокнота (ранг): 16 слоев для записей.
    r=16,
    # "Интенсивность чернил" (альфа): насколько сильно влияют новые знания.
    lora_alpha=32,
    # Указываем, к каким частям разума "Скульптора" прикрепить блокнот.
    target_modules=["to_q", "to_k", "to_v", "to_out.0"],
    # Заклинание "забывчивости", чтобы не переучился.
    lora_dropout=0.05,
    # Техническая руна, отключающая обучение смещений.
    bias="none",
)
# Мы "прикрепляем" сотворенный "блокнот" к сердцу Демиурга — UNet.
unet = get_peft_model(unet, lora_config)

# --- Акт 5: Ритуал Наставления ---
# Пятый, кульминационный акт: мы начинаем Великий Ритуал Наставления.
print("Акт 4: Начинаю Великий Ритуал Наставления...")

# Мы перемещаем "Проявителя" на Кристалл Маны (GPU).
vae.to("cuda")
# Мы перемещаем "Кодировщика Текста" на Кристалл Маны.
text_encoder.to("cuda")
# Мы перемещаем "Духа-Скульптора" с "блокнотом" на Кристалл Маны.
unet.to("cuda")

# Мы приказываем Духу-Скульптору (UNet) войти в "режим обучения".
unet.train()

# Мы готовим "инструмент для исправления ошибок" (оптимизатор).
optimizer = torch.optim.AdamW(unet.parameters(), lr=learning_rate)
# Мы призываем "Духа Шума", который будет "портить" наши картины для урока.
noise_scheduler = DDPMScheduler.from_pretrained(
    model_id, subfolder="scheduler"
)

# Мы создаем "магическое слово-активатор", с которым будет ассоциироваться
# наш стиль.
train_prompt = "a beautiful painting in sks style"
# Мы сразу переводим его в числовые руны, чтобы не делать это в цикле.
prompt_ids = tokenizer(
    # Текст, который нужно перевести.
    train_prompt,
    # Мы просим вернуть результат в виде тензора PyTorch.
    return_tensors="pt",
    # Мы приказываем дополнить до максимальной длины.
    padding="max_length",
    # Мы приказываем обрезать, если слишком длинно.
    truncation=True,
    # Мы указываем максимальную длину.
    max_length=tokenizer.model_max_length,
    # Мы отправляем руны на Кристалл Маны.
).input_ids.to("cuda")

# Мы начинаем урок, который повторится 100 раз (эпох).
for epoch in range(num_train_epochs):
    # Мы запускаем внутренний цикл по порциям данных (батчам).
    for step, batch in tqdm(
        # Мы итерируемся по нашему "подносчику".
        enumerate(train_dataloader),
        # Мы указываем общее количество шагов для индикатора.
        total=len(train_dataloader),
        # Мы добавляем описание к индикатору прогресса.
        desc=f"Эпоха {epoch+1}/{num_train_epochs}",
    ):
        # Используем защитное заклинание, так как эти духи не должны учиться.
        with torch.no_grad():
            # Шаг 1: Мы переносим чистую картину в "латентное пространство" с помощью
            # VAE.
            clean_images = batch["input"].to("cuda", dtype=torch.float16)
            # Мы начинаем многострочное заклинание получения латента.
            latents = (
                # VAE "сжимает" картину в ее скрытую суть (латент).
                vae.encode(clean_images).latent_dist.sample()
                # Мы умножаем на специальный магический коэффициент.
                * vae.config.scaling_factor
            )
            # Шаг 2: Мы получаем текстовый контекст от "Кодировщика".
            encoder_hidden_states = text_encoder(prompt_ids)[0]

        # Шаг 3: Мы создаем случайный шум такого же размера, как и наш латент.
        noise = torch.randn_like(latents)
        # Мы начинаем многострочное заклинание выбора "момента времени".
        timesteps = torch.randint(
            # От 0...
            0,
            # ...до максимального числа шагов.
            noise_scheduler.config.num_train_timesteps,
            # Форма тензора.
            (latents.shape[0],),
            # На каком устройстве создать.
            device=latents.device,
            # Мы указываем тип данных.
        ).long()
        # Мы "добавляем" сгенерированный шум к нашему чистому латенту.
        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)

        # Шаг 4: Мы просим Демиурга (UNet) предсказать, какой шум мы добавили.
        noise_pred = unet(
            noisy_latents, timesteps, encoder_hidden_states
        ).sample

        # Шаг 5: Мы считаем ошибку (насколько предсказанный шум отличается от
        # реального).
        loss = F.mse_loss(noise_pred, noise)
        # Шаг 6: Мы вычисляем "направления для исправления" для нашего
        # "блокнота".
        loss.backward()
        # Мы накапливаем "опыт" и исправляемся только каждый 4-й шаг.
        if (step + 1) % gradient_accumulation_steps == 0:
            # Мы применяем исправления.
            optimizer.step()
            # Мы стираем старые записи об ошибках.
            optimizer.zero_grad()

    # Мы сообщаем об ошибке в конце каждой эпохи.
    print(f"  Эпоха {epoch+1} завершена. Ошибка (Loss): {loss.item():.4f}")

# --- Акт 6: Сохранение "Стилевой Печати" ---
# Финальный акт: мы запечатываем наши знания в артефакт.
print("\nРитуал завершен! Сохраняю 'Стилевую Печать'...")
# Мы сохраняем не весь UNet, а только наш обученный "блокнот" LoRA.
unet.save_pretrained(output_dir)
# Мы оглашаем, что наш артефакт успешно создан и сохранен.
print(f"\nТвоя 'Стилевая Печать' сохранена в папке '{output_dir}'.")
