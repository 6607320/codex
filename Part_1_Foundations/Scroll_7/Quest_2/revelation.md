# **Отчет об исследовании: Ритуал «Стилевой Печати» — Всесторонний анализ методологии Low-Rank Adaptation (LoRA) для моделей Stable Diffusion**

## **1\. Введение: Архитектурный контекст и необходимость адаптации**

В современной экосистеме генеративного искусственного интеллекта модели скрытой диффузии (Latent Diffusion Models, LDM), к которым относится семейство Stable Diffusion, представляют собой фундаментальный сдвиг в парадигме синтеза изображений. Эти модели, обученные на миллиардах пар «текст-изображение» (например, набор данных LAION-5B), обладают колоссальной семантической емкостью, позволяющей генерировать визуальный контент широкого спектра.1 Однако, несмотря на их энциклопедические знания, базовые модели часто оказываются недостаточными для решения узкоспециализированных задач, требующих строгого соблюдения конкретной стилистики, брендинга или воспроизведения уникальных персонажей. Процесс адаптации предобученной модели к новым данным без потери её обобщающей способности является одной из центральных проблем глубокого обучения.

Традиционный подход к дообучению (full fine-tuning) подразумевает обновление всех весов нейронной сети. Для модели масштаба Stable Diffusion, содержащей около 1 миллиарда параметров (в версии SD 1.5) или более 2.6 миллиарда (в версии SDXL), это требует вычислительных мощностей промышленного уровня и значительных объемов видеопамяти (VRAM), что делает процесс недоступным для большинства исследователей и независимых разработчиков.2 Более того, полное дообучение несет в себе риск «катастрофического забывания» (catastrophic forgetting), когда модель, оптимизируясь под новый стиль, утрачивает способность генерировать базовые концепты.

Решением этой дилеммы стала технология Low-Rank Adaptation (LoRA), которая позволяет внедрять новые концепции в модель путем обучения лишь небольшой подгруппы параметров. В контексте пользовательского запроса этот процесс аллегорически назван «Ритуалом Стилевой Печати». Данная метафора точно отражает суть метода: создание компактного, переносимого «слепка» стиля (адаптера), который накладывается на «тело» фундаментальной модели, модифицируя её поведение без изменения основной структуры. Этот отчет представляет собой исчерпывающее техническое руководство по методологии LoRA, охватывающее математические основы, архитектурные нюансы, инженерную подготовку данных и стратегии оптимизации, необходимые для создания высококачественных стилевых адаптеров.

## **2\. Математические основания Low-Rank Adaptation (LoRA)**

Для глубокого понимания механизма работы «Стилевой Печати» необходимо обратиться к линейной алгебре, лежащей в основе трансформации весов нейронной сети. Основная гипотеза, на которой базируется LoRA, заключается в том, что изменения весов модели в процессе адаптации к конкретной задаче имеют низкий «внутренний ранг» (intrinsic rank).2

### **2.1 Декомпозиция матриц**

Пусть $W\_0 \\in \\mathbb{R}^{d \\times k}$ представляет собой фиксированную матрицу весов предварительно обученного слоя (например, слоя внимания в U-Net). При традиционном дообучении мы обновляем эту матрицу на значение $\\Delta W$, так что итоговый вес становится $W' \= W\_0 \+ \\Delta W$. Поскольку $W\_0$ имеет полный ранг, обновление $\\Delta W$ в общем случае также имеет ту же размерность $d \\times k$.

Метод LoRA предлагает ограничить обновление $\\Delta W$ путем его разложения на произведение двух матриц низкого ранга: $B \\in \\mathbb{R}^{d \\times r}$ и $A \\in \\mathbb{R}^{r \\times k}$, где ранг $r \\ll \\min(d, k)$. Таким образом, формула обновления весов принимает вид:

$$W' \= W\_0 \+ \\frac{\\alpha}{r} (BA)$$  
В этом уравнении $W\_0$ остается замороженным (градиенты по нему не вычисляются), а обучению подвергаются только матрицы $A$ и $B$. Инициализация этих матриц происходит следующим образом: матрица $A$ заполняется случайными значениями из гауссовского распределения, а матрица $B$ инициализируется нулями. Это гарантирует, что в начале обучения $\\Delta W \= 0$, и модель начинает с состояния, идентичного предобученному.4 Коэффициент $\\frac{\\alpha}{r}$ является масштабирующим фактором, где $\\alpha$ (альфа) — это гиперпараметр, регулирующий интенсивность влияния адаптера.

### **2.2 Экономическая эффективность и плотность параметров**

Эффективность данного подхода трудно переоценить. Если рассматривать слой с размерностью $d=1024$ и $k=1024$, то матрица полного обновления $\\Delta W$ содержала бы $1,048,576$ параметров. При использовании LoRA с рангом $r=4$, общее количество обучаемых параметров составляет $1024 \\times 4 \+ 4 \\times 1024 \= 8,192$. Это сокращение количества параметров более чем в 100 раз.3

Такое радикальное снижение размерности пространства поиска позволяет не только экономить память видеокарты, но и делает файлы моделей (сами «печати») чрезвычайно компактными — от нескольких мегабайт до пары сотен мегабайт, в отличие от гигабайтных чекпоинтов полных моделей. Это открывает возможность для модульности: пользователи могут хранить одну базовую модель и подключать к ней сотни различных LoRA-адаптеров по мере необходимости, смешивая их и переключая на лету без перезагрузки основной сети.5

## **3\. Архитектура диффузии как субстрат для стиля**

Чтобы «Стилевая Печать» легла ровно, необходимо понимать анатомию сущности, на которую она накладывается. Stable Diffusion состоит из трех ключевых компонентов: вариационного автоэнкодера (VAE), текстового энкодера (CLIP) и нейронной сети U-Net, предсказывающей шум.

### **3.1 U-Net и механизм внимания**

Сердцем процесса генерации является U-Net — сеть, которая итеративно очищает изображение от шума. Именно в слоях внимания (Attention Layers) этой сети происходит магия стилевого переноса. U-Net содержит блоки **Self-Attention** (самовнимание), которые отвечают за глобальную связность изображения, и **Cross-Attention** (перекрестное внимание), которые внедряют информацию из текстового запроса в визуальное пространство.7

Исследования показывают, что наиболее эффективными мишенями для LoRA являются проекционные матрицы в механизме внимания: Query ($W\_q$), Key ($W\_k$), Value ($W\_v$) и Output ($W\_{out}$).

- **Query и Key ($W\_q, W\_k$):** Определяют карту внимания — _на что_ именно смотрит модель и какие взаимосвязи между пикселями и токенами она устанавливает. Изменение этих весов влияет на композицию и структуру.
- **Value ($W\_v$):** Определяет _содержание_, которое извлекается при срабатывании внимания. Модификация этих весов напрямую влияет на текстуры, цветовую палитру и детализацию, что критически важно для стилизации.

Современные реализации (например, библиотека peft от Hugging Face) позволяют таргетировать все эти модули, используя суффиксы имен слоев: to_k, to_q, to_v, to_out.0.3 Более глубокое внедрение стиля возможно при таргетировании слоев прямой связи (feed-forward layers), обозначаемых как ff.net или proj, что позволяет захватывать еще более сложные высокоуровневые абстракции стиля, хотя и ценой увеличения размера файла адаптера.3

### **3.2 Текстовый Энкодер (CLIP)**

Текстовый энкодер (обычно CLIP ViT-L/14 для SD 1.5 или OpenCLIP ViT-bigG для SDXL) преобразует промпт пользователя в векторные эмбеддинги. Важный стратегический вопрос «Ритуала» — следует ли обучать текстовый энкодер вместе с U-Net?

- **Аргумент ЗА:** Обучение текстового энкодера позволяет лучше связать уникальный токен-триггер (заклинание призыва стиля) с визуальным концептом, особенно если стиль сложен и не имеет аналогов в базовых знаниях CLIP.10
- **Аргумент ПРОТИВ:** Переобучение энкодера может привести к потере языковой гибкости. Модель может отлично генерировать стиль, но перестать понимать сложные инструкции или композиционные уточнения в промпте. Это явление известно как «языковой дрифт».12

Для задач чистого переноса стиля (например, «масляная живопись») часто достаточно обучать только U-Net. Для задач, связанных с конкретными объектами или персонажами, которые должны быть стилизованы, тонкая настройка текстового энкодера с пониженным learning rate ($1e-5$ или $5e-6$) может быть оправдана.

## **4\. Подготовка артефактов: Инженерия данных**

Никакая магия алгоритмов не исправит дефекты исходного материала. Качество набора данных (датасета) является определяющим фактором успеха. В отличие от языковых моделей, которые могут обучаться на неструктурированном тексте, диффузионные модели требуют строгой организации пар «изображение-текст».

### **4.1 Структура и формат данных**

Стандартным форматом для обучения через библиотеку diffusers является структура ImageFolder. Это иерархия директорий, где изображения могут быть либо разложены по папкам классов, либо сопровождаться файлом метаданных metadata.jsonl.13

Пример оптимальной структуры:  
/dataset_root  
/images  
img_001.png  
img_002.png  
...  
metadata.jsonl  
Файл metadata.jsonl содержит строки JSON для каждого изображения:

JSON

{"file_name": "img_001.png", "text": "a portrait of a woman, ohwx style, cyberpunk lighting"}  
{"file_name": "img_002.png", "text": "a landscape of a city, ohwx style, neon signs"}

Важно, чтобы изображения были высокого разрешения (минимум 512x512 для SD 1.5, 1024x1024 для SDXL). Использование изображений низкого качества или с артефактами сжатия приведет к тому, что LoRA выучит эти артефакты как часть стиля.15

### **4.2 Проблема редкого токена (The Token Engineering)**

Центральным элементом «Ритуала» является выбор триггер-слова — уникального идентификатора, который будет вызывать обученный стиль. В ранних руководствах по Dreambooth предлагалось использовать токен sks. Это было мотивировано тем, что sks является редким токеном в словаре (находится в хвосте частотного распределения). Однако, это стало источником множества проблем.

Анализ показывает, что токен sks в латентном пространстве модели Stable Diffusion жестко ассоциирован с **самозарядным карабином Симонова (SKS)**. При использовании sks в качестве триггера для стиля (например, «девушка в стиле sks»), модель вынуждена преодолевать сильный предварительный приоритет (prior), связывающий этот токен с оружием. В результате на ранних этапах обучения или при недостаточном весе адаптера на изображениях могут спонтанно появляться части винтовок, приклады или характерные металлические текстуры оружия, смешивающиеся с целевым стилем.16

**Рекомендация эксперта:** Следует категорически избегать токена sks. Вместо этого необходимо использовать действительно нейтральные или бессмысленные комбинации букв, которые токенизатор разбивает на редкие подтокени, не имеющие четкого визуального образа. Примеры хороших триггеров: ohwx, zwx, pks (если проверено на отсутствие ассоциаций), или конкатенация style \+ name (например, retrowave_style). Использование уникального, но семантически пустого токена позволяет «записать» стиль в чистую ячейку памяти модели, не конфликтуя с существующими понятиями.19

### **4.3 Стратегия кэпшнинга (Captioning)**

Качество текстовых описаний (кэпшнов) определяет, как модель разделит визуальную информацию между «стилем» и «содержанием».

- Если вы описываете все детали изображения (например, «женщина в красном платье на фоне заката, мазки кистью, текстура холста»), модель может ассоциировать стилистические элементы (мазки, текстуру) с этими словами, а не с вашим триггер-словом.
- Если вы используете лаконичное описание (например, «женщина на фоне заката,»), модель вынуждена приписать все необъясненные визуальные особенности (мазки, палитру, освещение) именно токену-триггеру.20

Для обучения стиля (Style LoRA) наиболее эффективна стратегия **разреженного кэпшнинга**: описывайте субъекты (кто/что изображено), но опускайте описания самого стиля, заменяя их на триггер-слово. Это заставляет механизм внимания перекачивать всю стилистическую информацию в вектор адаптера, связанный с триггером.

## **5\. Конфигурация среды и оборудования (The Apparatus)**

Проведение обучения требует настройки программной среды, обеспечивающей максимальную эффективность использования аппаратных ресурсов. Основными инструментами здесь выступают библиотеки accelerate и diffusers от Hugging Face.

### **5.1 Настройка Accelerate**

Утилита accelerate позволяет абстрагироваться от сложности распределенного обучения и управления устройствами. Перед началом работы необходимо сгенерировать конфигурационный файл через команду accelerate config.21  
Для стандартного обучения на одной GPU (например, NVIDIA RTX 3090/4090) оптимальная конфигурация выглядит так:

- compute_environment: LOCAL_MACHINE
- mixed_precision: fp16 (или bf16 для карт архитектуры Ampere и новее)
- num_processes: 1
- dynamo_backend: NO (если не используются экспериментальные оптимизации Torch 2.0).

Использование смешанной точности (fp16/bf16) критически важно. Это снижает потребление памяти почти вдвое по сравнению с fp32 и ускоряет вычисления тензорных ядер, практически не влияя на качество генерации. Формат bf16 предпочтительнее fp16, так как он сохраняет тот же динамический диапазон, что и fp32, предотвращая проблемы с исчезновением градиентов или появлением значений NaN (Not a Number) во время обучения.23

### **5.2 Оптимизаторы и VRAM**

Стандартный оптимизатор AdamW требует хранения дополнительных состояний (моментов) для каждого параметра, что увеличивает потребление памяти. Для оптимизации используется **AdamW8bit** (из библиотеки bitsandbytes), который квантует состояния оптимизатора до 8 бит, существенно экономя VRAM без потери точности сходимости. Это позволяет обучать LoRA с батчем 1-2 даже на картах с 6-8 ГБ видеопамяти.21

## **6\. Алхимия гиперпараметров**

Успех ритуала зависит от точного баланса числовых коэффициентов, управляющих процессом градиентного спуска. Ниже приведена таблица ключевых параметров и их влияние на процесс.

### **Таблица 1: Рекомендованные гиперпараметры для обучения Style LoRA**

| Параметр                     | Рекомендованное значение | Комментарий эксперта                                                                                                                        |
| :--------------------------- | :----------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ |
| **Learning Rate (U-Net)**    | $1e-4$ ($0.0001$)        | LoRA требует более высокого LR, чем полное дообучение ($1e-6$). Если обучение идет слишком медленно, можно поднять до $5e-4$, но осторожно. |
| **Learning Rate (Text Enc)** | $5e-5$                   | Если обучается TE, скорость должна быть ниже, чтобы не разрушить языковые знания.                                                           |
| **Rank ($r$)**               | 32 или 64                | Для стилей ранг 32 обычно достаточен. Ранг 128 и выше может привести к переобучению и огромным файлам без прироста качества.                |
| **Alpha ($\\alpha$)**        | 16 или 32                | Стандартная практика: $\\alpha \= r$ или $\\alpha \= r/2$. Соотношение $\\alpha/r$ работает как множитель LR.                               |
| **Batch Size**               | 1 \- 4                   | Зависит от VRAM. Для компенсации малого батча можно использовать gradient_accumulation_steps.                                               |
| **Epochs**                   | 10 \- 50                 | Стили схватываются быстро. 100 эпох часто приводят к «пережаренному» (overcooked) результату.                                               |
| **Optimizer**                | AdamW8bit                | Экономит память. Альтернатива: Prodigy или DAdaptation для автоматического подбора LR.                                                      |
| **Resolution**               | 512, 768, 1024           | Должно соответствовать базовому разрешению модели (512 для SD1.5, 1024 для SDXL).                                                           |

### **6.1 Анализ Rank и Alpha**

Параметры $r$ и $\\alpha$ связаны неразрывно. Масштабирование весов происходит по формуле $\\Delta W \\cdot \\frac{\\alpha}{r}$.

- Если $r=32$ и $\\alpha=32$, множитель равен 1\.
- Если $r=32$ и $\\alpha=16$, множитель равен 0.5 (ослабление влияния).
- Если $r=32$ и $\\alpha=64$, множитель равен 2 (усиление).

Существует методика **Rank-Stabilized LoRA (rsLoRA)**, которая предлагает масштабировать обновление как $\\frac{\\alpha}{\\sqrt{r}}$. Это теоретически обосновано для стабилизации обучения при больших рангах (например, $r\>128$), предотвращая взрыв градиентов. В библиотеке peft это включается флагом use_rslora=True.24 Однако для классических задач стилизации (rank 32-64) линейное масштабирование остается стандартом де\-факто.

### **6.2 Функция потерь и Min-SNR**

Модель обучается, минимизируя среднеквадратичную ошибку (MSE) между предсказанным и реальным шумом.26 Однако стандартная MSE имеет недостаток: она уделяет слишком много внимания этапам, где шум легко предсказуем, и недостаточно — сложным этапам формирования структуры.  
Техника Min-SNR Gamma weighting (взвешивание по минимальному отношению сигнал/шум) перебалансирует функцию потерь, заставляя модель фокусироваться на тех временных шагах (timesteps) диффузии, которые наиболее важны для формирования деталей. Это особенно полезно при обучении стилей с тонкими текстурами или сложной геометрией.28

## **7\. Процесс обучения и диагностика**

Запуск процесса осуществляется скриптом train_text_to_image_lora.py или аналогичным (например, через интерфейсы Kohya_ss). В процессе обучения критически важно отслеживать графики функции потерь (Loss).

### **7.1 Интерпретация Loss-кривой**

- **Идеальная кривая:** Быстрое падение в начале, затем выход на плато с небольшими колебаниями. Точка, где падение замедляется (elbow point), часто является лучшим моментом для остановки.
- **Overfitting (Переобучение):** Если Loss продолжает падать почти до нуля, это тревожный знак. Модель начала просто запоминать пиксели обучающих изображений. При генерации такая модель будет выдавать высококонтрастные, «пережаренные» изображения с артефактами и терять способность следовать промпту.24
- **Underfitting (Недообучение):** Если Loss не падает или колеблется на высоком уровне, возможно, Learning Rate слишком мал, или dataset слишком разнороден и противоречив.

### **7.2 Проверка «на лету»**

Лучший способ валидации — сохранение промежуточных чекпоинтов (например, каждые 5 эпох) и генерация тестовых изображений с фиксированным сидом (seed). Это позволяет визуально отследить момент, когда стиль уже захвачен, но гибкость модели еще не утрачена. Если на 10-й эпохе стиль виден, а на 50-й изображения становятся искаженными, значит, оптимальный чекпоинт находится в районе 15-20 эпохи.29

## **8\. Бизнес-кейсы и прикладное значение**

Технология LoRA вышла далеко за пределы академических экспериментов и стала мощным инструментом в маркетинге и дизайне. Способность «запечатать» фирменный стиль в переносимый файл открывает новые горизонты для брендинга.

### **8.1 Кейс Coca-Cola: «Masterpiece»**

Компания Coca-Cola стала одним из пионеров использования Stable Diffusion в масштабной рекламной кампании «Masterpiece». Используя технологии, аналогичные LoRA, они создали модели, обученные на визуальной айдентике бренда — специфическом красном цвете, форме бутылки, логотипе и архивных визуальных образах. Это позволило генерировать тысячи уникальных ассетов, где культовая бутылка интегрировалась в стилистику классических картин и современного 3D-арта. LoRA обеспечила строгое соблюдение бренд-гайдов (consistency), чего невозможно добиться простым промпт-инжинирингом.30

### **8.2 Кейс Heinz: «AI Ketchup»**

Бренд Heinz провел кампанию, основанную на эксперименте с генерацией изображений по запросу "Ketchup". Выяснилось, что модели (DALL-E 2 и производные) имеют сильный уклон (bias) в сторону визуального образа бутылки Heinz, когда их просят нарисовать кетчуп. Heinz использовал это, дообучая модели на своих специфических этикетках и формах, чтобы закрепить доминирование бренда в латентном пространстве. Кампания демонстрирует, как «Стилевая Печать» может использоваться не только для генерации, но и как инструмент доказательства узнаваемости бренда.33

### **8.3 Индустрия моды**

Модные дома используют LoRA для создания виртуальных прототипов. Обучив адаптер на паттернах тканей и крое новой коллекции (например, «Осень-Зима 2025»), дизайнеры могут генерировать фотореалистичные лукбуки, помещая одежду в любые локации и на любых моделей без проведения дорогостоящих фотосессий. Это ускоряет цикл разработки (time-to-market) и снижает затраты на пре-продакшн.35

## **9\. Продвинутые техники и будущее технологии**

Эволюция LoRA продолжается. Появляются новые методы, расширяющие возможности «Стилевой Печати».

- **LoRA+:** Метод, предлагающий использовать разные Learning Rate для матриц $A$ и $B$, что может ускорить сходимость.
- **DoRA (Weight-Decomposed Low-Rank Adaptation):** Разделяет обучение магнитуды и направления весов, что позволяет достичь качества, сравнимого с полным дообучением, при сохранении эффективности LoRA.
- **Pivotal Tuning:** Комбинация Textual Inversion и LoRA. Сначала находится идеальный эмбеддинг для стиля, а затем веса модели подстраиваются вокруг него. Это дает максимальную точность редактирования.5

## **10\. Заключение**

Ритуал «Стилевой Печати» посредством LoRA — это не просто техническая процедура, а акт кристаллизации эстетического намерения в цифровую форму. Метод демократизировал создание кастомных ИИ-моделей, позволив переносить уникальные визуальные языки в нейронные сети с минимальными затратами ресурсов.  
Успех в этом процессе требует дисциплинированного подхода к подготовке данных (исключение sks, качественный кэпшнинг), понимания архитектуры (таргетирование слоев внимания) и тонкой настройки гиперпараметров ($LR$, $Rank$, $\\alpha$). Соблюдение описанных в данном отчете методологий гарантирует создание высококачественного, стабильного и гибкого инструмента, способного интегрировать любой визуальный стиль в бесконечное полотно латентного пространства Stable Diffusion.

### ---

**Приложение: Практический пример загрузки LoRA**

Для активации обученной «печати» в среде Python используется следующий код, демонстрирующий простоту интеграции адаптера 6:

Python

import torch  
from diffusers import StableDiffusionPipeline

\# 1\. Загрузка базовой модели (Субстрат)  
base_model_id \= "runwayml/stable-diffusion-v1-5"  
pipe \= StableDiffusionPipeline.from_pretrained(  
 base_model_id,  
 torch_dtype=torch.float16  
).to("cuda")

\# 2\. Активация Стилевой Печати (Загрузка LoRA)  
\# adapter_name позволяет давать уникальное имя слою для последующего управления  
pipe.load_lora_weights(  
 "./my_trained_style_lora",  
 weight_name="style_seal_v1.safetensors",  
 adapter_name="style_config"  
)

\# 3\. Настройка силы влияния (Scale)  
\# scale=0.8 часто дает лучший результат, чем 1.0, сохраняя гибкость промпта  
pipe.set_adapters(\["style_config"\], adapter_weights=\[0.8\])

\# 4\. Генерация (Ритуал призыва)  
\# Используем триггер-слово 'ohwx', на котором обучали модель  
prompt \= "a futuristic cityscape, ohwx style, neon lights, 8k"  
image \= pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images

image.save("generated_style_artifact.png")

#### **Источники**

1. Teaching Diffusion Models Specific Concepts \- Marvik — AI, дата последнего обращения: декабря 10, 2025, [https://www.marvik.ai/blog/diffusion-models-fine-tuning](https://www.marvik.ai/blog/diffusion-models-fine-tuning)
2. UnGuide: Learning to Forget with LoRA-Guided Diffusion Models \- arXiv, дата последнего обращения: декабря 10, 2025, [https://arxiv.org/html/2508.05755v1](https://arxiv.org/html/2508.05755v1)
3. LoRA Under the Hood: How it Really Works in Visual Generative AI. A Technical Deep Dive | by Efrat taig | Medium, дата последнего обращения: декабря 10, 2025, [https://medium.com/@efrat_taig/lora-under-the-hood-how-it-really-works-in-visual-generative-ai-e6c10611b461](https://medium.com/@efrat_taig/lora-under-the-hood-how-it-really-works-in-visual-generative-ai-e6c10611b461)
4. LoRA \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/peft/en/developer_guides/lora](https://huggingface.co/docs/peft/en/developer_guides/lora)
5. Using LoRA for Efficient Stable Diffusion Fine-Tuning \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/blog/lora](https://huggingface.co/blog/lora)
6. Using CivitAI LoRAs with Diffusers | by Ненавин \- Medium, дата последнего обращения: декабря 10, 2025, [https://medium.com/@natsunoyuki/using-civitai-loras-with-diffusers-e3ef3e47c413](https://medium.com/@natsunoyuki/using-civitai-loras-with-diffusers-e3ef3e47c413)
7. UNet \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/diffusers/en/api/loaders/unet](https://huggingface.co/docs/diffusers/en/api/loaders/unet)
8. Using LoRA in Stable Diffusion \- MachineLearningMastery.com, дата последнего обращения: декабря 10, 2025, [https://machinelearningmastery.com/using-lora-in-stable-diffusion/](https://machinelearningmastery.com/using-lora-in-stable-diffusion/)
9. support lora weights conversion · Issue \#2608 · huggingface/peft \- GitHub, дата последнего обращения: декабря 10, 2025, [https://github.com/huggingface/peft/issues/2608](https://github.com/huggingface/peft/issues/2608)
10. Enhancing Diffusion Models with Text-Encoder Reinforcement Learning \- arXiv, дата последнего обращения: декабря 10, 2025, [https://arxiv.org/html/2311.15657v2](https://arxiv.org/html/2311.15657v2)
11. Training Stable Diffusion with Dreambooth using Diffusers \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/blog/dreambooth](https://huggingface.co/blog/dreambooth)
12. Overtrained Text Encoder vs Overtrained UNET (Details in comments) : r/StableDiffusion \- Reddit, дата последнего обращения: декабря 10, 2025, [https://www.reddit.com/r/StableDiffusion/comments/13hbdpl/overtrained_text_encoder_vs_overtrained_unet/](https://www.reddit.com/r/StableDiffusion/comments/13hbdpl/overtrained_text_encoder_vs_overtrained_unet/)
13. Load image data \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/datasets/v2.12.0/en/image_load](https://huggingface.co/docs/datasets/v2.12.0/en/image_load)
14. Create an image dataset \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/datasets/en/image_dataset](https://huggingface.co/docs/datasets/en/image_dataset)
15. Detailed Stable Diffusion LoRA training guide \- ViewComfy, дата последнего обращения: декабря 10, 2025, [https://www.viewcomfy.com/blog/detailed-LoRA-training-guide-for-Stable-Diffusion](https://www.viewcomfy.com/blog/detailed-LoRA-training-guide-for-Stable-Diffusion)
16. LoRA Trigger Word \+ Tokens : r/StableDiffusion \- Reddit, дата последнего обращения: декабря 10, 2025, [https://www.reddit.com/r/StableDiffusion/comments/1fkhyie/lora_trigger_word_tokens/](https://www.reddit.com/r/StableDiffusion/comments/1fkhyie/lora_trigger_word_tokens/)
17. "Sks" is a bad identifier. It's a gun. · Issue \#71 · XavierXiao/Dreambooth-Stable-Diffusion, дата последнего обращения: декабря 10, 2025, [https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/issues/71](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion/issues/71)
18. From one of the original DreamBooth authors : Stop using SKS as the initializer word : r/StableDiffusion \- Reddit, дата последнего обращения: декабря 10, 2025, [https://www.reddit.com/r/StableDiffusion/comments/yju5ks/from_one_of_the_original_dreambooth_authors_stop/](https://www.reddit.com/r/StableDiffusion/comments/yju5ks/from_one_of_the_original_dreambooth_authors_stop/)
19. A Guide to Training Your Own Style and Look in Stable Diffusion 1.5 \- Titan XT, дата последнего обращения: декабря 10, 2025, [https://www.titanxt.io/post/a-guide-to-training-your-own-style-and-look-in-stable-diffusion-15](https://www.titanxt.io/post/a-guide-to-training-your-own-style-and-look-in-stable-diffusion-15)
20. Essential to Advanced Guide to training a LoRA \- Civitai, дата последнего обращения: декабря 10, 2025, [https://civitai.com/articles/3105/essential-to-advanced-guide-to-training-a-lora](https://civitai.com/articles/3105/essential-to-advanced-guide-to-training-a-lora)
21. Launching Accelerate scripts \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/accelerate/basic_tutorials/launch](https://huggingface.co/docs/accelerate/basic_tutorials/launch)
22. Launching your Accelerate scripts \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/accelerate/v0.20.3/basic_tutorials/launch](https://huggingface.co/docs/accelerate/v0.20.3/basic_tutorials/launch)
23. The Command Line \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/accelerate/package_reference/cli](https://huggingface.co/docs/accelerate/package_reference/cli)
24. LoRA Hyperparameters Guide | Unsloth Documentation, дата последнего обращения: декабря 10, 2025, [https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide)
25. LoRA \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/peft/main/conceptual_guides/lora](https://huggingface.co/docs/peft/main/conceptual_guides/lora)
26. What is Loss Function? | IBM, дата последнего обращения: декабря 10, 2025, [https://www.ibm.com/think/topics/loss-function](https://www.ibm.com/think/topics/loss-function)
27. \[D\] Loss function in Diffusion models : r/MachineLearning \- Reddit, дата последнего обращения: декабря 10, 2025, [https://www.reddit.com/r/MachineLearning/comments/wvnnvb/d_loss_function_in_diffusion_models/](https://www.reddit.com/r/MachineLearning/comments/wvnnvb/d_loss_function_in_diffusion_models/)
28. Understanding LoRA Training Parameters: A research analysis on confusing ML training terms and how they effect image outputs. \- Reddit, дата последнего обращения: декабря 10, 2025, [https://www.reddit.com/r/comfyui/comments/1iknlx3/understanding_lora_training_parameters_a_research/](https://www.reddit.com/r/comfyui/comments/1iknlx3/understanding_lora_training_parameters_a_research/)
29. LoRA Support in Diffusers \- Hugging Face, дата последнего обращения: декабря 10, 2025, [https://huggingface.co/docs/diffusers/v0.14.0/en/training/lora](https://huggingface.co/docs/diffusers/v0.14.0/en/training/lora)
30. What Coca-Cola has learned on its generative AI journey so far | Marketing Dive, дата последнего обращения: декабря 10, 2025, [https://www.marketingdive.com/news/what-coca-cola-learned-generative-ai/741709/](https://www.marketingdive.com/news/what-coca-cola-learned-generative-ai/741709/)
31. AI Creation, AI Validation: A Case Study of Coca-Cola's 'Masterpiece' | by Dmitry Gaiduk, дата последнего обращения: декабря 10, 2025, [https://cooltool.medium.com/ai-creation-ai-validation-a-case-study-of-coca-colas-masterpiece-fbb23b9a2077](https://cooltool.medium.com/ai-creation-ai-validation-a-case-study-of-coca-colas-masterpiece-fbb23b9a2077)
32. Create Real Magic with Coca-Cola's AI \- Analytics Vidhya, дата последнего обращения: декабря 10, 2025, [https://www.analyticsvidhya.com/blog/2023/04/create-real-magic-with-coca-colas-ai/](https://www.analyticsvidhya.com/blog/2023/04/create-real-magic-with-coca-colas-ai/)
33. AI Ketchup \- D\&AD, дата последнего обращения: декабря 10, 2025, [https://www.dandad.org/work/d-ad-awards-archive/ai-ketchup](https://www.dandad.org/work/d-ad-awards-archive/ai-ketchup)
34. Heinz: A.I Ketchup • Ads of the World™ | Part of The Clio Network, дата последнего обращения: декабря 10, 2025, [https://www.adsoftheworld.com/campaigns/a-i-ketchup](https://www.adsoftheworld.com/campaigns/a-i-ketchup)
35. Stable Diffusion: Use Cases and Business Benefits, дата последнего обращения: декабря 10, 2025, [https://www.tenupsoft.com/blog/stable-diffusion-use-cases-benefits.html](https://www.tenupsoft.com/blog/stable-diffusion-use-cases-benefits.html)
36. \[Guide\] Train Custom Lora for Fashion Clothes in Stable Diffusion \- Punya AI, дата последнего обращения: декабря 10, 2025, [https://punya.ai/blog/post/custom-lora-stable-diffusion-fashion-clothes-commercial](https://punya.ai/blog/post/custom-lora-stable-diffusion-fashion-clothes-commercial)
37. haofanwang/Lora-for-Diffusers: The most easy-to-understand tutorial for using LoRA (Low-Rank Adaptation) within diffusers framework for AI Generation Researchers \- GitHub, дата последнего обращения: декабря 10, 2025, [https://github.com/haofanwang/Lora-for-Diffusers](https://github.com/haofanwang/Lora-for-Diffusers)
