"""Квест 5.3: Проверка новых знаний.

Этот пергамент — "экзамен" для нашего Голема после ритуала Наставления.
Его главная цель (МАКРО-контекст) — продемонстрировать, как применять
(инференс) обученный PEFT-адаптер.

Ритуал состоит из двух актов:
1.  **Пробуждение:** Мы призываем "чистое тело" (базовую модель) и
    "надеваем" на него "магическую броню" (наш обученный LoRA-адаптер) с
    помощью заклинания `PeftModel.from_pretrained`.
2.  **Экзамен:** Мы задаем "просветленному" Голему вопрос и оцениваем
    качество его ответа, доказывая, что он усвоил новые знания.

Этот квест закрепляет понимание модульной природы PEFT и демонстрирует,
как эффективно развертывать дообученные модели.
"""

# --- Акт 1: Подготовка Гримуаров ---
# Первый акт: мы призываем все необходимые знания и инструменты для ритуала.

# Мы призываем гримуар `torch` — источник всей нашей магической энергии.
import torch

# Мы призываем специальный чертеж `PeftModel` из гримуара `peft` для
# работы с "блокнотами".
from peft import PeftModel

# Мы призываем чертежи для Голема, Переводчика и инструкции по сжатию.
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
)

# --- Акт 2: Призыв и "Просветление" Голема ---
# Второй акт: мы призываем "чистого" Голема и наделяем его знаниями из
# нашего "блокнота".

# Мы оглашаем на кристалл (консоль) о начале ритуала призыва.
print("Призываю 'чистого' Голема в сжатой 4-битной форме...")
# Мы указываем имя нашего базового Голема.
model_name = "distilgpt2"

# Мы создаем ту же самую инструкцию по сжатию, что и при обучении.
# Это КРИТИЧЕСКИ ВАЖНО: Голем и его "блокнот" должны существовать в одной
# "системе магии".
quantization_config = BitsAndBytesConfig(
    # Руна №1: Приказываем сжимать "мысли" Голема до 4-бит.
    load_in_4bit=True,
    # Руна №2: Во время вычислений использовать 16-битную точность для баланса.
    bnb_4bit_compute_dtype=torch.float16,
)

# Мы призываем "чистого" Голема, применяя к нему сжатие прямо в момент призыва.
model = AutoModelForCausalLM.from_pretrained(
    # Мы называем имя Голема, которого призываем.
    model_name,
    # Мы передаем ему "свиток-инструкцию" по сжатию.
    quantization_config=quantization_config,
    # Мы доверяем "Духу-Ускорителю" распределить части Голема по ресурсам
    # (GPU/CPU).
    device_map="auto",
)

# Мы призываем "Переводчика", который говорит на диалекте нашего Голема.
tokenizer = AutoTokenizer.from_pretrained(model_name)
# Мы устанавливаем 'pad_token', как делали при обучении, для полной
# совместимости.
tokenizer.pad_token = tokenizer.eos_token

# Мы указываем точный путь к нашему артефакту — папке с обученным
# "магическим блокнотом".
adapter_path = "results/checkpoint-250"
# Мы оглашаем на кристалл, что нашли наш артефакт.
print(f"\nНахожу магический блокнот в '{adapter_path}'...")

# КЛЮЧЕВОЕ ЗАКЛИНАНИЕ: `PeftModel.from_pretrained`.
# Оно берет "чистого" Голема (`model`)
#  и "надевает" на него наш "блокнот" (`adapter_path`).
# Внутри оно читает `adapter_config.json`, находит нужные "отделы мозга" Голема
# и прикрепляет к ним обученные "страницы" из `adapter_model.safetensors`.
model = PeftModel.from_pretrained(model, adapter_path)
# Мы оглашаем, что ритуал "Просветления" завершен.
print("Голем прочел блокнот и получил новые знания!")

# --- Акт 3: Экзамен ---
# Третий акт: мы задаем вопрос нашему "просветленному" ученику.

# Мы создаем "экзаменационный билет" (промпт) для нашего Голема.
# Мы используем тот же формат "Instruction: ... Response:", которому учили его.
prompt = "Instruction: Which genre is the hobbit?\n\nResponse:"
# Мы оглашаем на кристалл, какой именно вопрос мы задаем.
print(f"\nЗадаю Голему вопрос: {prompt}")

# Мы переводим наш вопрос в числовые руны-тензоры и отправляем их на
# Кристалл Маны (GPU).
inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

# Мы запускаем ритуал генерации ответа.
# `model.generate` — это главное заклинание для получения ответа от Голема-Сказителя.
outputs = model.generate(
    # Руна №1: мы передаем Голему сами числовые руны нашего вопроса.
    input_ids=inputs["input_ids"],
    # Руна №2: мы передаем "карту внимания", чтобы Голем знал, на какие руны
    # смотреть.
    attention_mask=inputs["attention_mask"],
    # Руна №3: мы ограничиваем длину ответа 20-ю новыми токенами, чтобы он был
    # кратким.
    max_new_tokens=20,
)

# --- Акт 4: Оценка Ответа ---
# Финальный акт: мы расшифровываем ответ Голема и оцениваем его.

# Голем вернул нам ответ в виде числовых рун.
# `tokenizer.decode` — это заклинание для обратного перевода чисел в понятный текст.
response = tokenizer.decode(
    # Мы берем первый (и единственный) вариант ответа из результатов.
    outputs[0],
    # Мы просим не печатать служебные руны вроде "<|endoftext|>".
    skip_special_tokens=True,
)

# Мы оглашаем на кристалл, что сейчас будет представлен ответ нашего ученика.
print("\nОтвет 'Просветленного' Голема:")
# Мы печатаем финальный, расшифрованный ответ.
print(response)
