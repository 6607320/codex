# === quest_5_2.py ===
# Имя этого пергамента, хранящего ритуал Великого Наставления.
# Квест: 5.2 - Ритуал "Эффективной Адаптации"
# Каноническое имя Квеста, как оно записано в Великом Кодексе.
# Цель: Провести первое дообучение (fine-tuning) языковой модели, используя
# продвинутую магию QLoRA, чтобы ритуал был возможен на нашем Кристалле Маны.
# Священная цель нашего ритуала и указание на ключевую технологию.

# --- Акт 1: Подготовка Всех Гримуаров ---
# Первый акт: мы призываем все необходимые знания и инструменты для этого сложного ритуала.

# Мы призываем гримуар `torch` — источник всей нашей магической энергии.
import torch

# Мы призываем "Библиотекаря" `load_dataset` для работы с архивами знаний.
from datasets import load_dataset

# Из гримуара `peft` мы призываем заклинания для "Эффективной Адаптации" (LoRA).
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training

# Из великого гримуара `transformers` мы призываем множество мощных чертежей.
from transformers import (
    # Чертеж для создания Големов-Сказителей, способных продолжать текст.
    AutoModelForCausalLM,
    # Чертеж для создания универсальных "Переводчиков" (текст <-> руны).
    AutoTokenizer,
    # Чертеж для создания "свитка-инструкции" по магическому сжатию (квантизации).
    BitsAndBytesConfig,
    # Чертеж для "Помощника-Упаковщика", который грамотно формирует порции данных для урока.
    DataCollatorForLanguageModeling,
    # Чертеж для самого "Наставника", который проводит ритуал обучения.
    Trainer,
    # Чертеж для "Инструкции Наставнику", где описаны все правила урока.
    TrainingArguments,
)

# --- Акт 2: Призыв Ученика и Подготовка Учебников ---
# Второй акт: мы призываем Голема-ученика и готовим для него учебные материалы.

# Мы оглашаем на кристалл (консоль) о начале подготовительного этапа.
print("Подготовка к ритуалу Наставления...")
# Мы даем имя Голему-ученику, которого будем наставлять.
model_name = "distilgpt2"
# Мы призываем "Переводчика", который говорит на диалекте нашего Голема.
tokenizer = AutoTokenizer.from_pretrained(model_name)
# Техническая руна: мы приказываем Переводчику использовать символ "конца текста" (`eos_token`)
# в качестве "заполнителя" (`pad_token`) для выравнивания длины предложений.
tokenizer.pad_token = tokenizer.eos_token

# Мы создаем "свиток-инструкцию" по "магическому сжатию" (квантизации).
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,  # Руна №1: Приказываем сжимать "мысли" Голема до 4-бит.
    bnb_4bit_quant_type="nf4",  # Руна №2: Указываем использовать эффективный тип сжатия "Normal Float 4".
    bnb_4bit_compute_dtype=torch.float16,  # Руна №3: Во время вычислений использовать 16-битную точность для баланса.
)

# Мы призываем Голема-Сказителя (способного генерировать текст).
model = AutoModelForCausalLM.from_pretrained(
    model_name,  # Мы называем его имя.
    quantization_config=quantization_config,  # Мы передаем ему "свиток-инструкцию" по сжатию.
    device_map="auto",  # Мы доверяем "Духу-Ускорителю" распределить части Голема по ресурсам (GPU/CPU).
)


# Мы создаем "Магический Преобразователь" — заклинание (функцию), которое будет "на лету"
# готовить наши учебные материалы в правильном формате.
def process_dataset(batch):
    # Мы создаем список текстов с помощью магии list comprehension.
    texts = [
        # Создаем отформатированную строку-шаблон для каждого примера.
        f"Instruction: {instr}\n\nResponse: {resp}"
        # Проходимся одновременно по инструкциям и ответам в текущей порции данных (`batch`).
        for instr, resp in zip(batch["instruction"], batch["response"])
    ]
    # Мы переводим этот текст в понятные Голему числовые руны-тензоры.
    return tokenizer(texts, padding="max_length", truncation=True, max_length=128)


# Мы открываем "портал" к архиву 'dolly-15k', используя режим потока.
streaming_dataset = load_dataset(
    # Имя архива, к которому мы обращаемся в Великой Библиотеке.
    "databricks/databricks-dolly-15k",
    # Мы сообщаем, что нам нужны данные из "тренировочной" части архива.
    split="train",
    # Ключевая руна экономии: создаем "портал", не скачивая все данные.
    streaming=True,
    # Руна Доверия: подтверждаем, что доверяем коду загрузки этого архива.
    trust_remote_code=True,
)
# Мы создаем "умный портал", chaining spells together:
# `.take(1000)` — заклинание "взять только первые 1000 записей".
# `.map(...)` — заклинание "прикрепить" к порталу наш "Магический Преобразователь".
processed_dataset = streaming_dataset.take(1000).map(process_dataset, batched=True)

# --- Акт 3: Создание "Магического Блокнота" (LoRA) ---
# Третий акт: мы готовим Голема к обучению и "прикрепляем" к нему адаптеры LoRA.

# Мы произносим над сжатым Големом подготовительное заклинание, чтобы он был готов к адаптации.
model = prepare_model_for_kbit_training(model)

# Мы создаем "чертеж" для нашего "магического блокнота" (адаптера LoRA).
lora_config = LoraConfig(
    r=16,  # "Толщина" блокнота (ранг): 16 слоев для записей.
    lora_alpha=32,  # "Интенсивность чернил" (альфа): насколько сильно влияют новые знания.
    target_modules=[
        "c_attn",
        "c_proj",
    ],  # Указываем, к каким частям разума Голема прикрепить блокнот.
    lora_dropout=0.05,  # Заклинание "забывчивости", чтобы не переучился.
    bias="none",  # Техническая руна.
    task_type="CAUSAL_LM",  # Указываем, что Голем - "Сказитель".
)
# Мы "прикрепляем" сотворенный "блокнот" к нашему Голему.
model = get_peft_model(model, lora_config)

# --- Акт 4: Ритуал Наставления ---
# Четвертый, кульминационный акт: мы призываем Наставника и запускаем процесс обучения.

# Мы создаем "инструкцию для Наставника", описывающую, как вести урок.
training_args = TrainingArguments(
    output_dir="./results",  # Указываем, куда складывать артефакты урока.
    per_device_train_batch_size=1,  # Приказываем учить по одной "учебной карточке" за раз.
    gradient_accumulation_steps=4,  # Но накапливать "опыт" с 4-х карточек перед обновлением знаний.
    learning_rate=2e-4,  # Устанавливаем "скорость обучения".
    max_steps=250,  # Главная руна: урок длится ровно 250 шагов.
    logging_steps=20,  # Приказываем Наставнику докладывать о прогрессе каждые 20 шагов.
)

# Мы призываем самого "Наставника" (`Trainer`).
trainer = Trainer(
    model=model,  # Мы указываем, кого учить (нашего Голема с блокнотом).
    train_dataset=processed_dataset,  # По какому "умному порталу" с учебниками учить.
    args=training_args,  # По какой "инструкции" вести урок.
    # Используем профессионального помощника для упаковки данных.
    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),
)

# Мы оглашаем на кристалл о начале Великого Ритуала Наставления.
print("\nНачинаю Великий Ритуал Наставления...")
# Мы даем команду "Наставнику" начать урок.
trainer.train()

# Мы оглашаем на кристалл, что ритуал завершен.
print("\nРитуал завершен! Голем получил новые знания.")
