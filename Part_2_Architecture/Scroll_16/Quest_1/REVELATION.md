# **Архитектурные основы и операционная динамика отслеживания экспериментов в MLOps: От локального хронографа к распределенным реестрам MLflow**

## **Аннотация**

В данном аналитическом отчете представлено исчерпывающее техническое исследование механизмов отслеживания экспериментов (Experiment Tracking) в рамках парадигмы MLOps, с особым акцентом на архитектуру и функциональность платформы MLflow. Отчет инициирован необходимостью перехода от ручного управления жизненным циклом моделей, характеризующегося как «магический хаос», к строгому, воспроизводимому научному процессу. Исследование начинается с деконструкции локальной реализации MLflow («Хронограф»), анализируя низкоуровневые операции журналирования параметров, метрик и артефактов в файловой системе. Далее проводится глубокий архитектурный анализ эволюции системы от локального хранилища (FileStore) к распределенной клиент-серверной архитектуре, необходимой для коллаборативной работы в крупных командах («Гильдиях»). Рассматриваются вопросы разделения слоев хранения метаданных и бинарных объектов, механизмы проксирования артефактов, стратегии обеспечения воспроизводимости через интеграцию с системами контроля версий и управление средами исполнения. Отчет синтезирует теоретические основы MLOps с практическими аспектами настройки инфраструктуры, предоставляя экспертное руководство по трансформации разрозненных скриптов в единую «Великую Библиотеку» знаний о машинном обучении.

## **1\. Введение: Императив отслеживания экспериментов в современной науке о данных**

Разработка систем машинного обучения фундаментально отличается от традиционной разработки программного обеспечения своей вероятностной природой и зависимостью от данных. В то время как классический код детерминирован, поведение модели ML является функцией от кода (алгоритма), данных (обучающей выборки) и конфигурации (гиперпараметров). В отсутствии систематического подхода к фиксации этих трех компонентов, процесс разработки деградирует до состояния, описанного в техническом задании как «магический хаос». Это состояние характеризуется накоплением множества версий моделей (model_v1, model_v2_final), лишенных контекста их создания, что делает невозможным ни воспроизведение результатов, ни объективное сравнение эффективности различных подходов.  
Отслеживание экспериментов (Experiment Tracking) выступает фундаментом MLOps, превращая процесс обучения моделей из искусства, доступного лишь автору, в инженерную дисциплину. MLflow, как ведущая открытая платформа в этой области, реализует концепцию «Лабораторного Журнала», предоставляя унифицированный интерфейс для записи, организации и анализа экспериментов. В отличие от простых логгеров, MLflow создает структурированное пространство данных, где каждая запись (Run) является атомарной единицей экспериментальной работы, содержащей исчерпывающую информацию о входных параметрах и выходных результатах.  
Цель данного отчета — не просто описать функциональность MLflow, но вскрыть внутреннюю механику его работы, начиная от простейшего локального скрипта и заканчивая сложной распределенной архитектурой, используемой в промышленных средах. Мы проанализируем, как три фундаментальных заклинания — log_param, log_metric и log_artifact — формируют базу знаний, и как эта база трансформируется из локальной папки mlruns в централизованное хранилище метаданных и артефактов.

## **2\. Анатомия локального Хронографа: Механика Клиента MLflow**

Пользовательский сценарий («Квест 16.1») демонстрирует базовый паттерн использования MLflow: инициализацию клиента, настройку эксперимента и выполнение записи данных в локальном контексте. Для глубокого понимания системы необходимо рассмотреть, что происходит «под капотом» каждого вызова API.

### **2.1 Инициализация и контекст выполнения (start_run)**

Центральным элементом архитектуры отслеживания является концепция "Run" (Запуск). Запуск представляет собой единичное выполнение кода, будь то обучение модели, предобработка данных или инференс. В Python-клиенте MLflow управление жизненным циклом запуска осуществляется через менеджер контекста with mlflow.start_run().  
Когда интерпретатор встречает эту конструкцию, клиент MLflow выполняет серию критически важных операций:

1. **Определение контекста**: Клиент проверяет, запущен ли скрипт в рамках существующего эксперимента или нужно создать новый. Если имя эксперимента задано через mlflow.set_experiment(), клиент ищет соответствующий ID или создает новую запись в бэкенде.
2. **Создание объекта Run**: Генерируется уникальный идентификатор запуска (Run ID), представляющий собой 32-символьную шестнадцатеричную строку. Этот ID становится первичным ключом, связывающим все последующие логируемые данные.
3. **Захват состояния среды**: Еще до выполнения первой строки пользовательского кода внутри блока with, MLflow автоматически собирает системные метаданные. Это включает имя пользователя, запустившего процесс (mlflow.user), имя исходного файла (mlflow.source.name), тип запуска (локальный, ноутбук, проект) и версию MLflow.
4. **Управление статусом**: Статус запуска устанавливается в RUNNING. Менеджер контекста гарантирует, что при выходе из блока — успешно или с ошибкой — статус будет обновлен на FINISHED или FAILED соответственно. Это предотвращает появление «зомби-запусков», которые могут исказить статистику экспериментов.

Использование start_run в качестве менеджера контекста является не просто синтаксическим сахаром, а механизмом обеспечения транзакционной целостности записи эксперимента. Без явного завершения (mlflow.end_run()), который автоматически вызывается при выходе из with, запись может остаться в неопределенном состоянии, что затруднит её анализ в будущем.

### **2.2 Гранулярное логирование: Параметры, Метрики и Артефакты**

Разделение данных на параметры, метрики и артефакты — это не просто семантическое удобство, а отражение фундаментальных различий в типах данных и способах их хранения и использования в MLOps.

#### **2.2.1 Параметры: Фиксация конфигурации (log_param)**

Функция mlflow.log*param("key", value) предназначена для записи конфигурационных данных, которые остаются неизменными в течение всего запуска. Это "ингредиенты" ритуала: скорость обучения (learning_rate), количество слоев нейросети, тип оптимизатора, или seed случайных чисел.  
С архитектурной точки зрения, параметры рассматриваются как метаданные с низкой кардинальностью по отношению к одному запуску (один ключ — одно значение). В локальном хранилище FileStore каждый параметр сохраняется как отдельный текстовый файл или запись в YAML, где имя файла соответствует ключу параметра, а содержимое — его значению. Важно отметить, что параметры предназначены для *входных\_ данных. Попытка изменить значение параметра в ходе одного запуска противоречит логике эксперимента: изменение условий эксперимента должно порождать новый запуск. MLflow позволяет логировать параметры пакетами через log_params, что эффективно при загрузке конфигураций из словарей или файлов настроек.  
Таблица 1\. Сравнительная характеристика типов данных MLflow

| Тип данных    | Функция API  | Семантика                                                | Хранение (FileStore)                  | Пример использования                      |
| :------------ | :----------- | :------------------------------------------------------- | :------------------------------------ | :---------------------------------------- |
| **Параметры** | log_param    | Конфигурация, гиперпараметры (Key-Value)                 | Файлы в папке params/                 | learning_rate=0.01, batch_size=32         |
| **Метрики**   | log_metric   | Динамические показатели производительности (Time Series) | Файлы в папке metrics/ с историей     | loss, accuracy, f1_score                  |
| **Артефакты** | log_artifact | Файлы результатов (Binary/Text/Image)                    | Папка artifacts/ (копирование файлов) | model.pkl, confusion_matrix.png, data.csv |
| **Теги**      | set_tag      | Метаданные для организации и поиска                      | Файлы в папке tags/                   | env=production, team=nlp-core             |

#### **2.2.2 Метрики: Отслеживание динамики (log_metric)**

Метрики представляют собой количественные показатели, которые изменяются в процессе выполнения запуска. Функция mlflow.log_metric("key", value, step=x) позволяет записывать временные ряды данных. В отличие от параметров, метрики имеют ось времени (timestamp) и ось итераций (step).  
Это критически важно для глубокого обучения, где динамика изменения функции потерь (loss) или точности (accuracy) по эпохам дает больше информации, чем просто финальное значение. MLflow сохраняет полную историю изменений каждой метрики, что позволяет UI строить графики обучения. В локальном хранилище это реализуется через добавление новых строк (append) в файл, соответствующий имени метрики, в подпапке metrics. Аргумент step позволяет синхронизировать метрики с итерациями обучения, обеспечивая корректное выравнивание на графиках даже при асинхронном логировании.

#### **2.2.3 Артефакты: Материализация результатов (log_artifact)**

Артефакты — это любые файлы, порожденные экспериментом. Это "овеществленный" результат работы: сохраненные веса модели (pickle, ONNX, H5), графики (png, jpeg), файлы конфигурации, или даже выборки данных.  
Вызов mlflow.log*artifact("local_path", artifact_path="dest") инициирует операцию передачи файла. В локальном режиме (Quest 16.1) это операция копирования файла из рабочей директории скрипта в директорию артефактов внутри структуры mlruns. Однако, именно на уровне артефактов происходит главное архитектурное разделение при масштабировании: в то время как параметры и метрики (метаданные) остаются в базе данных, артефакты, обладающие значительным объемом, мигрируют в объектные хранилища (S3, Azure Blob, GCS). Артефакты обеспечивают воспроизводимость *использования\_: имея артефакт модели, можно развернуть её в другом окружении без необходимости переобучения.

### **2.3 Автоматическое логирование (Autologging)**

Хотя в задании используется явное (ручное) логирование, важно упомянуть возможность автоматического логирования (mlflow.autolog()). Этот механизм использует «патчинг» (monkey patching) популярных библиотек (Scikit-learn, TensorFlow, PyTorch, XGBoost), автоматически перехватывая вызовы методов обучения (например, fit) и записывая параметры, метрики и модель без явных команд log\_.  
Ручное логирование, продемонстрированное в квесте, предоставляет полный контроль и идеально подходит для понимания принципов работы системы, а также для записи кастомных метрик, специфичных для бизнес-задачи, которые не могут быть захвачены автоматически.

## **3\. Файловое хранилище (FileStore): Организация mlruns**

Результатом выполнения скрипта в локальном режиме является появление директории mlruns. Эта директория представляет собой **FileStore** — реализацию бэкенда MLflow по умолчанию, использующую локальную файловую систему для хранения всех данных. Понимание структуры mlruns необходимо для диагностики и осознания ограничений данного подхода.

### **3.1 Иерархическая структура данных**

FileStore организует данные в строгой иерархии: ./mlruns (Root) \-\> Experiment ID \-\> Run ID \-\> Data Types.

1. **Уровень Эксперимента (/mlruns/0, /mlruns/1...)**: Каждый эксперимент получает целочисленный идентификатор. Внутри папки эксперимента находится файл meta.yaml, содержащий метаданные эксперимента: его имя ("Первый Свиток Хроник"), жизненный цикл (active/deleted) и путь к хранилищу артефактов.
2. **Уровень Запуска (/mlruns/1/\<uuid\>)**: Внутри папки эксперимента создаются подпапки для каждого запуска, именованные 32-значными UUID. Это гарантирует уникальность и позволяет избежать коллизий при одновременной работе (хотя файловая система плохо справляется с конкурентным доступом).
3. **Уровень Данных**: Внутри папки запуска структура разветвляется на подпапки, соответствующие типам логируемых данных :
   - **params/**: Содержит текстовые файлы, где имя файла \= имя параметра, содержимое \= значение.
   - **metrics/**: Содержит файлы метрик. Каждая строка в файле — это записанное значение с timestamp и step.
   - **tags/**: Хранит системные и пользовательские теги (например, mlflow.user, mlflow.source.type).
   - **artifacts/**: Директория для хранения файлов (моделей, графиков spell.txt).
   - **meta.yaml**: Главный файл описания запуска, содержащий статус, время начала/конца и ссылки на другие компоненты.

### **3.2 Ограничения локального FileStore**

Хотя FileStore идеален для обучения и одиночной разработки («Квест 16.1»), он обладает критическими недостатками для промышленного использования:

- **Производительность**: Для отображения списка экспериментов UI должен открыть и прочитать тысячи мелких файлов. С ростом количества запусков интерфейс становится крайне медленным.
- **Отсутствие ACID**: Файловая система не гарантирует транзакционную целостность при одновременной записи. Попытка нескольких процессов писать в один FileStore может привести к коррупции данных.
- **Сложность поиска**: Поиск запусков по параметрам (например, metrics.accuracy \> 0.9) требует полного сканирования файлов, что вычислительно неэффективно по сравнению с SQL-запросами.

Эти ограничения диктуют необходимость перехода к базе данных в качестве бэкенда (Backend Store) при масштабировании решения.

## **4\. Магическое Зеркало: Интерфейс MLflow UI**

Команда mlflow ui запускает локальный веб\-сервер (обычно на базе Gunicorn/Flask), который читает данные из mlruns и визуализирует их.

### **4.1 Аналитические возможности**

Интерфейс MLflow предоставляет не просто просмотр логов, а инструменты для аналитики экспериментов:

- **Табличное представление**: Позволяет видеть все запуски с их параметрами и метриками в единой таблице, что облегчает поиск корреляций.
- **Сравнение (Compare)**: Выбрав несколько запусков, можно открыть режим сравнения. Здесь доступны диаграммы разброса (Scatter Plots) и графики параллельных координат (Parallel Coordinates), позволяющие визуально оценить влияние гиперпараметров на целевые метрики. Например, можно наглядно увидеть, как увеличение learning_rate влияет на loss в группе экспериментов.
- **Визуализация метрик**: Клик по конкретной метрике открывает график её изменения во времени, что позволяет диагностировать переобучение или проблемы сходимости модели.

### **4.2 Проблема локализации**

В контексте «Квеста», UI работает на localhost. Это означает, что «знания» заперты на машине одного «техноманта». Чтобы поделиться результатами с «Гильдией», пришлось бы физически передавать папку mlruns, что нарушает принципы CI/CD и создает проблемы синхронизации. Решение этой проблемы лежит в переходе к клиент-серверной архитектуре.

## **5\. Расширение до Великой Библиотеки: Централизованная архитектура**

Ответ Мастера в квесте указывает на следующий шаг эволюции: использование централизованного сервера. Это трансформирует MLflow из локальной утилиты в платформу корпоративного уровня. Данный переход подразумевает внедрение трехкомпонентной архитектуры: Клиент, Сервер Отслеживания (Tracking Server) и Разделенное Хранилище.

### **5.1 Роль Сервера Отслеживания (Tracking Server)**

MLflow Tracking Server — это независимый веб\-сервис, который выступает в роли посредника (прокси) между кодом обучения (клиентом) и хранилищем данных. Вместо того чтобы писать напрямую на диск, скрипт обучения отправляет REST API запросы (POST/GET) на сервер.  
Для переключения на этот режим в коде достаточно изменить одну строку:  
`mlflow.set_tracking_uri("http://<адрес_сервера>:5000")`

С этого момента все вызовы log_param и log_metric транслируются в HTTP-запросы.

### **5.2 Разделение Хранилищ: Бэкенд и Артефакты**

В распределенной архитектуре происходит фундаментальное разделение типов данных на два потока, обслуживаемых разными системами хранения :

1. **Backend Store (Хранилище Метаданных)**:
   - _Назначение_: Хранение легковесных структурированных данных (параметры, метрики, теги, метаданные запусков).
   - _Технология_: Реляционные базы данных (RDBMS), поддерживаемые SQLAlchemy (PostgreSQL, MySQL, MS SQL, SQLite).
   - _Преимущества_: Высокая скорость транзакций, поддержка индексации для быстрого поиска (фильтрации) экспериментов, надежность данных (ACID), возможность одновременного доступа множества пользователей. В отличие от файловой системы, база данных эффективно масштабируется до миллионов записей.
2. **Artifact Store (Хранилище Артефактов)**:
   - _Назначение_: Хранение тяжеловесных неструктурированных файлов (модели, датасеты, изображения, логи Docker).
   - _Технология_: Объектные хранилища (Amazon S3, Azure Blob Storage, Google Cloud Storage, MinIO, HDFS) или сетевые файловые системы (NFS).
   - _Преимущества_: Дешевое хранение огромных объемов данных, высокая пропускная способность при загрузке/скачивании файлов, доступность по сети.

### **5.3 Топология взаимодействия: Прямой доступ vs Проксирование**

При настройке «Великой Библиотеки» критически важно выбрать схему взаимодействия клиента с хранилищем артефактов. Существует две основные модели:

#### **5.3.1 Сценарий А: Прямой доступ клиента (Direct Access)**

В этом сценарии клиент обращается к Tracking Server только для записи метаданных (в БД). Для сохранения артефактов (log*artifact) клиент запрашивает у сервера путь к хранилищу (например, s3://my-bucket/...), а затем *самостоятельно\_ и напрямую загружает файл в S3, используя установленные на машине разработчика креды (AWS credentials).

- _Плюсы_: Снижает нагрузку на Tracking Server, так как тяжелый трафик идет напрямую в облако.
- _Минусы_: Требует, чтобы у каждого разработчика («мага») были настроены права на запись в общий S3 бакет. Это создает сложности с безопасностью и управлением ключами доступа.

#### **5.3.2 Сценарий Б: Проксирование через Сервер (Proxied Artifact Access)**

Сервер запускается с флагом \--serve-artifacts (или конфигурируется соответствующим образом). В этом случае клиент не общается с S3 напрямую. Он отправляет артефакты через HTTP-запрос на Tracking Server, а сервер, используя свои привилегированные права, сохраняет их в объектное хранилище.

- _Плюсы_: Централизованная безопасность. Ключи от S3 нужны только серверу. Клиентам достаточно иметь доступ к HTTP API сервера. Упрощает настройку VPN и фаерволов.
- _Минусы_: Весь трафик артефактов проходит через сервер, что может стать узким местом (bottleneck) при интенсивной работе с большими моделями.

## **6\. Воспроизводимость: От Магии к Науке**

Главная бизнес-ценность внедрения MLflow, упомянутая в задании, — это превращение хаоса в "организованную науку". Технически это реализуется через механизмы обеспечения **воспроизводимости** (Reproducibility). Запись метрик (log_metric) отвечает на вопрос «Что получилось?», но для науки важнее ответ на вопрос «Как это повторить?».

### **6.1 Захват Контекста Исполнения (Git Integration)**

Одной из самых мощных функций MLflow является автоматическая интеграция с Git. Если скрипт запускается внутри Git-репозитория, MLflow автоматически извлекает хеш текущего коммита и сохраняет его в тег mlflow.source.git.commit. Также может сохраняться ветка (mlflow.source.git.branch) и URL репозитория.  
Это создает неразрывную связь между кодом и результатом. В любой момент в будущем, глядя на успешный эксперимент в UI, инженер может увидеть точный коммит (например, a1b2c3d), сделать git checkout a1b2c3d и получить ровно тот код, который породил эту модель. Если в репозитории были незакоммиченные изменения (dirty state), MLflow также это зафиксирует, предупреждая о потенциальной невоспроизводимости. Это дисциплинирует разработчиков, побуждая их фиксировать код перед запуском экспериментов.

### **6.2 Управление Окружением (Environment Management)**

Код бесполезен без среды исполнения. MLflow позволяет фиксировать зависимости через файлы conda.yaml или requirements.txt, которые сохраняются как артефакты. При использовании компонента **MLflow Projects**, система может автоматически воссоздать точное окружение (Conda environment или Docker container) перед запуском кода, гарантируя, что различие в версиях библиотек (например, pandas 1.0 vs pandas 2.0) не повлияет на результат.

## **7\. Стратегическое Значение для Предприятия**

Внедрение MLflow трансформирует культуру работы с данными.

### **7.1 От Индивидуализма к Коллаборации**

Централизованный сервер (Remote Tracking Server) становится единой точкой правды. Члены команды могут видеть эксперименты друг друга в реальном времени, сравнивать подходы и избегать дублирования работы. Тегирование (set_tag) позволяет маркировать эксперименты по проектам, фазам (dev/prod) или командам, создавая структурированный каталог знаний.

### **7.2 Управление Жизненным Циклом (Model Registry)**

Логическим продолжением трекинга является Реестр Моделей (Model Registry). Если Tracking сохраняет _все_ эксперименты (даже неудачные), то Registry служит для управления только лучшими моделями, готовыми к внедрению. Он добавляет слой версионирования и управления стадиями (Staging \-\> Production \-\> Archived), позволяя формализовать процесс вывода моделей в эксплуатацию.

### **7.3 Аудируемость и Compliance**

В регулируемых отраслях (финансы, медицина) возможность доказать, на каких данных и с какими параметрами была обучена модель, является юридическим требованием. MLflow предоставляет полный аудиторский след (lineage), связывая артефакт модели с исходным кодом, параметрами и (при использовании MLflow Data) версией датасета.

## **8\. Заключение**

Выполнение Квеста 16.1 по настройке локального «Хронографа» является первым, но критически важным шагом в мир MLOps. Освоенные примитивы — log_param, log_metric, log_artifact — составляют универсальный язык общения между исследователем данных и системой управления жизненным циклом. Локальный mlruns демонстрирует принципы организации данных, но истинная мощь MLflow раскрывается при переходе к распределенной архитектуре с базой данных и объектным хранилищем. Эта трансформация позволяет масштабировать процесс разработки от индивидуальных экспериментов до промышленного конвейера, где каждый «магический ритуал» становится воспроизводимым, прозрачным и управляемым технологическим процессом.

#### **Источники**

1\. MLOps: A Practical Guide to MLflow: From Chaos to Production-Ready ML Workflows | by Omari J | Medium, https://medium.com/@omari.james.data/a-practical-guide-to-mlflow-from-chaos-to-production-ready-ml-workflows-3fa37bd95ef9 2\. Intro to MLOps: Machine learning experiment tracking, https://wandb.ai/site/articles/intro-to-mlops-machine-learning-experiment-tracking/ 3\. Experiment Tracking \- Made With ML by Anyscale, https://madewithml.com/courses/mlops/experiment-tracking/ 4\. Explaining MLOps using MLflow Tool \- Analytics Vidhya, https://www.analyticsvidhya.com/blog/2022/12/explaining-mlops-using-mlflow-tool/ 5\. Machine Learning Workflow Using MLFLOW \-A Beginners Guide \- Analytics Vidhya, https://www.analyticsvidhya.com/blog/2021/07/machine-learning-workflow-using-mlflow-a-beginners-guide/ 6\. Track Experiments and Models by Using MLflow \- Azure Machine Learning | Microsoft Learn, https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?view=azureml-api-2 7\. MLflow Tracking APIs, https://mlflow.org/docs/latest/ml/tracking/tracking-api/ 8\. module provides a high-level “fluent” API for starting and managing MLflow runs. For example, https://mlflow.org/docs/latest/api\_reference/python\_api/mlflow.html 9\. Log metrics, parameters, and files with MLflow \- Azure Machine Learning | Microsoft Learn, https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?view=azureml-api-2 10\. MLflow Tracking Quickstart, https://mlflow.org/docs/latest/ml/tracking/quickstart/ 11\. MLflow Tracking, https://mlflow.org/docs/latest/ml/tracking/ 12\. MLflow Logging API Quickstart (Python) \- Databricks, https://www.databricks.com/notebooks/gallery/MLflowLoggingAPIPythonQuickstart.html 13\. Backend Stores \- MLflow, https://mlflow.org/docs/latest/self-hosting/architecture/backend-store/ 14\. Databricks Autologging | Databricks on AWS, https://docs.databricks.com/aws/en/mlflow/databricks-autologging 15\. Folder Structer With MLflow : r/mlops \- Reddit, https://www.reddit.com/r/mlops/comments/1angxom/folder\_structer\_with\_mlflow/ 16\. Command-Line Interface \- MLflow, https://mlflow.org/docs/latest/cli.html 17\. mlflow/mlflow/store/tracking/file_store.py at master \- GitHub, https://github.com/mlflow/mlflow/blob/master/mlflow/store/tracking/file\_store.py 18\. How to set sqlite database backend mlflow in computing cluster? \#5908 \- GitHub, https://github.com/mlflow/mlflow/discussions/5908 19\. MLOps Gym \- Beginners Guide to MLflow \- Databricks Community \- 62593, https://community.databricks.com/t5/technical-blog/mlops-gym-beginners-guide-to-mlflow/ba-p/62593 20\. Share mlruns folder across machines · Issue \#184 \- GitHub, https://github.com/mlflow/mlflow/issues/184 21\. MLflow Tracking Server, https://mlflow.org/docs/latest/self-hosting/architecture/tracking-server/ 22\. Manage your machine learning life cycle with MLflow in Python | by Rodrigo Arenas | Analytics Vidhya | Medium, https://medium.com/analytics-vidhya/manage-your-machine-learning-lifecycle-with-mlflow-in-python-d678d5f3c682 23\. Track model development using MLflow \- Azure Databricks \- Microsoft Learn, https://learn.microsoft.com/en-us/azure/databricks/mlflow/tracking 24\. MLflow: A Technical Overview of the Machine Learning Lifecycle Platform | by Sendoa Moronta | Dec, 2025 | Medium, https://medium.com/@sendoamoronta/mlflow-a-technical-overview-of-the-machine-learning-lifecycle-platform-852908409898 25\. How to store artifacts on a server running MLflow \- Stack Overflow, https://stackoverflow.com/questions/52331254/how-to-store-artifacts-on-a-server-running-mlflow 26\. Track versions of Git-based applications with MLflow, https://mlflow.org/docs/latest/genai/version-tracking/track-application-versions-with-mlflow/ 27\. MLflow Projects, https://mlflow.org/docs/latest/ml/projects/ 28\. Tracking, Training, and Winning Back Customers with MLflow: A Churnbusters Case Study, https://medium.com/@ryassminh/tracking-training-and-winning-back-customers-with-mlflow-a-churnbusters-case-study-4b57d7edbfea 29\. Search Runs | MLflow, https://mlflow.org/docs/latest/ml/search/search-runs/ 30\. Experiment Tracking with MLflow in 10 Minutes | Towards Data Science, https://towardsdatascience.com/experiment-tracking-with-mlflow-in-10-minutes-f7c2128b8f2c/
