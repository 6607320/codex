"""Квест 16.2: Запись в Хроники.

Этот пергамент объединяет магию Наставления и магию Летописи. Его главная
цель (МАКРО-контекст) — интегрировать `MLflow` в реальный процесс обучения
нашей "Башни Прозрения" (MiniCNN).

Ритуал начинается с открытия новой "страницы" в "Хронографе"
(`mlflow.start_run`). В процессе обучения мы используем:
1. `mlflow.log_param()`: для записи "ингредиентов" (гиперпараметров) в начале.
2. `mlflow.log_metric()`: для записи "ошибки" (`Loss`) на каждом шаге,
   создавая график обучения.
3. `mlflow.pytorch.log_model()`: для сохранения финального артефакта —
   самого обученного Голема — в "Хроники".

Этот квест доказывает, как превратить хаотичный процесс R&D в организованную,
воспроизводимую научную работу.
"""

# Мы призываем наш главный гримуар "Летописец" (`mlflow`).
import mlflow

# --- Акт 1: Подготовка Гримуаров ---
# Начинается первый акт: мы призываем все остальные необходимые инструменты.
# Мы призываем наш силовой гримуар PyTorch, источник всей магической энергии.
import torch

# Мы призываем `torch.nn` (с псевдонимом `nn`) — главу с чертежами базовых
# блоков для Големов.
import torch.nn as nn

# Мы призываем `torch.nn.functional` (с псевдонимом `F`) — гримуар с
# "функциональными" заклинаниями.
import torch.nn.functional as F

# Мы призываем `torch.optim` (с псевдонимом `optim`) — гримуар с
# "инструментами для исправления ошибок".
import torch.optim as optim

# Мы призываем "Библиотеку" с "учебником" MNIST и гримуар трансформаций.
from torchvision import datasets, transforms

# Мы призываем наш верный "индикатор прогресса".
from tqdm import tqdm

# --- Акт 2: Подготовка "Учебника" и Чертежа ---
# Начинается второй акт: мы готовим все необходимое для обучения.
# (Этот акт тебе полностью знаком из Квеста 10.2)

# Мы создаем конвейер "магических линз" для подготовки изображений.
transform = transforms.Compose(
    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]
)
# Мы загружаем "учебник" MNIST.
train_dataset = datasets.MNIST("./data", train=True, download=True, transform=transform)
# Мы создаем "подносчик" данных.
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)


# Мы призываем чертеж нашей "Башни Прозрения".
class MiniCNN(nn.Module):
    # Мы определяем ритуал сотворения.
    def __init__(self):
        # Мы пробуждаем дух предка.
        super().__init__()
        # Мы создаем первый этаж свертки.
        self.conv1 = nn.Conv2d(1, 16, 3, 1, 1)
        # Мы создаем второй этаж свертки.
        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)
        # Мы создаем "зал раздумий".
        self.fc1 = nn.Linear(32 * 7 * 7, 10)

    # Мы определяем путь мысли через разум Голема.
    def forward(self, x):
        # Мы пропускаем образ через первый этаж.
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        # Мы пропускаем образ через второй этаж.
        x = F.relu(F.max_pool2d(self.conv2(x), 2))
        # Мы "сплющиваем" карты в вектор.
        x = x.view(-1, 32 * 7 * 7)
        # Мы пропускаем вектор через "зал раздумий".
        x = self.fc1(x)
        # Мы возвращаем финальный вердикт.
        return F.log_softmax(x, dim=1)


# --- Акт 3: Настройка и Начало Записи в Хроники ---
# Начинается третий акт: мы открываем "Хронограф" для новой записи.
# Мы выбираем "книгу" ("Эксперимент"), в которую будем делать запись.
mlflow.set_experiment("Первый Свиток Хроник")

# `with mlflow.start_run(...)`: Мы начинаем новую "страницу" в нашем журнале.
with mlflow.start_run(run_name="Обучение MiniCNN"):

    # --- Запись "Ингредиентов" (Гиперпараметров) ---
    # Мы создаем переменные для наших настроек, чтобы было удобно их менять и
    # записывать.
    learning_rate = 0.01
    # Мы создаем переменную для размера пачки.
    batch_size = 64
    # Мы создаем переменную для количества эпох.
    epochs = 1
    # `mlflow.log_param()`: Мы записываем каждую нашу "настройку" на "страницу" журнала.
    mlflow.log_param("learning_rate", learning_rate)
    # Мы записываем размер пачки.
    mlflow.log_param("batch_size", batch_size)
    # Мы записываем количество эпох.
    mlflow.log_param("epochs", epochs)

    # --- Акт 4: Ритуал Наставления под Надзором Летописца ---
    # Начинается четвертый, кульминационный акт: мы обучаем Голема под запись.
    # Мы оглашаем на кристалл о начале ритуала.
    print("Начинаю ритуал наставления 'Башни Прозрения' под запись...")
    # Мы сотворяем Голема и отправляем его на Кристалл Маны.
    model = MiniCNN().to("cuda")
    # Мы готовим "Волшебный Ключ", используя нашу переменную `learning_rate`.
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    # Мы готовим "Рулетку" для измерения ошибок.
    criterion = nn.CrossEntropyLoss()

    # Мы переводим модель в режим обучения.
    model.train()
    # Мы начинаем цикл по "учебным годам" (эпохам).
    for epoch in range(epochs):
        # Мы создаем переменную для хранения самой последней ошибки в эпохе.
        final_loss = 0.0
        # `enumerate(train_loader)`: Мы берем "пачки" данных
        #  и их порядковые номера (`step`).
        for step, (data, target) in tqdm(
            # Мы итерируемся по нашему "Подносчику".
            enumerate(train_loader),
            # Мы указываем общее количество шагов для индикатора.
            total=len(train_loader),
            # Мы добавляем описание к индикатору прогресса.
            desc=f"Эпоха {epoch+1}",
        ):
            # Мы отправляем "пачку" данных на Кристалл Маны.
            data, target = data.to("cuda"), target.to("cuda")
            # Мы стираем старые ошибки.
            optimizer.zero_grad()
            # Наш Голем делает предсказание.
            output = model(data)
            # Мы измеряем ошибку.
            loss = criterion(output, target)
            # Мы вычисляем "шепот исправления".
            loss.backward()
            # Мы "подкручиваем руны".
            optimizer.step()

            # --- Запись "Результатов" (Метрик) на каждом шагу ---
            # `if step % 100 == 0`: Мы произносим заклинание
            #  "Если номер шага делится на 100 без остатка..."
            if step % 100 == 0:
                # `mlflow.log_metric()`: "...то записать
                #  текущее значение ошибки (`loss.item()`)
                # в журнал на шаге `step`". Это создаст точки для нашего
                # графика.
                mlflow.log_metric("loss", loss.item(), step=step)
            # Мы запоминаем ошибку этого шага, чтобы сохранить ее в конце.
            final_loss = loss.item()

    # После завершения всех шагов, мы записываем финальную ошибку эпохи.
    mlflow.log_metric("final_loss", final_loss)

    # Мы оглашаем о завершении обучения.
    print(f"\nРитуал завершен! Финальная Ошибка (Loss): {final_loss:.4f}")

    # --- Акт 5: Сохранение Артефакта-Модели в Хроники ---
    # Начинается финальный акт: мы сохраняем самого Голема в "Хронограф".
    # Мы оглашаем о начале сохранения.
    print("Сохраняю обученного Голема как артефакт...")
    # `mlflow.pytorch.log_model`: Мы произносим специальное, мощное заклинание.
    # Оно берет нашу обученную модель PyTorch (`model`) и сохраняет ее
    # целиком (вместе со всеми необходимыми файлами) в подпапку "model"
    # внутри "страницы" нашего журнала.
    mlflow.pytorch.log_model(model, "model")
    # Мы оглашаем, что Голем успешно сохранен.
    print("Голем сохранен в 'Хрониках'.")

# Мы сообщаем, что запись в "Хроники" завершена и даем инструкцию.
print("\nЗапись в 'Хроники' завершена. Запусти 'mlflow ui', чтобы увидеть результат.")
