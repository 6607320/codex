# **Операционализация Глубокого Обучения: Всесторонний Анализ Трекинга Экспериментов, Управления Артефактами и Архитектуры MLOps с Использованием MLflow и PyTorch**

## **Аннотация**

В современной экосистеме искусственного интеллекта переход от экспериментального кода («Jupyter-ноутбуков») к промышленным конвейерам MLOps представляет собой фундаментальный сдвиг парадигмы. Данный отчет представляет собой исчерпывающее исследование этого перехода, основанное на кейсе обучения сверточной нейронной сети («MiniCNN») на наборе данных MNIST с интеграцией платформы **MLflow**.

Мы деконструируем механику процесса обучения, превращая его из стохастического, «магического» ритуала в детерминированный, научный процесс. В отчете детально анализируются механизмы сериализации моделей в PyTorch, архитектура хранения метаданных в MLflow, а также критическая дихотомия между инструментами трекинга экспериментов (MLflow) и версионирования данных (DVC). Особое внимание уделяется «Золотому стандарту» R\&D, который обеспечивает воспроизводимость, прозрачность сравнения гипотез и бесшовную передачу моделей в производственную среду (Production). Исследование базируется на техническом анализе кода, документации и лучших практиках индустрии, предоставляя глубокое понимание того, как метаданные превращаются в бизнес-ценность.

## ---

**Глава 1\. Эпистемология Машинного Обучения и Кризис Воспроизводимости**

### **1.1. От Алхимии к Химии: Необходимость Структурирования R\&D**

Машинное обучение, в отличие от традиционной разработки программного обеспечения, является вероятностной дисциплиной. В классическом программировании функция $f(x) \= y$ детерминирована кодом. В глубоком обучении результат является функцией трех переменных: кода (архитектура модели), данных (обучающая выборка) и внутреннего состояния (гиперпараметры, инициализация весов, стохастичность оптимизатора).

В представленном кейсе «Квест 16.2» исследователь сталкивается с типичной задачей: обучение модели MiniCNN. Без использования специализированных инструментов этот процесс напоминает алхимию. Исследователь меняет learning_rate с 0.01 на 0.001, перезапускает скрипт и перезаписывает файл model.pth. Спустя неделю невозможно ответить на фундаментальные вопросы:

- Какая комбинация параметров привела к метрике Accuracy 98.5%?
- На какой версии данных была обучена модель?
- Является ли текущее улучшение результатом изменения архитектуры или удачной инициализации весов?

Этот феномен известен как «Кризис воспроизводимости» в AI. Внедрение **MLflow** трансформирует этот хаос, вводя понятие «Run» (Запуск) как атомарной единицы экспериментальной работы. Каждый запуск становится неизменяемой записью в «Хрониках» (базе данных экспериментов), содержащей полный контекст выполнения.1

### **1.2. Таксономия Артефактов Глубокого Обучения**

Для построения надежной системы MLOps необходимо классифицировать цифровые активы, порождаемые в процессе обучения. В контексте нашей задачи (python quest_16_2.py) генерируются следующие классы артефактов:

| Класс Артефакта            | Описание в контексте MiniCNN                       | Характеристики хранения                               | Инструмент управления          |
| :------------------------- | :------------------------------------------------- | :---------------------------------------------------- | :----------------------------- |
| **Исходный код**           | Класс MiniCNN, цикл обучения, импорты torch.       | Текстовые данные, версионирование строк.              | **Git**                        |
| **Гиперпараметры**         | learning_rate=0.01, batch_size=64, epochs=1.       | Ключ-значение, малый объем.                           | **MLflow Tracking** (Params)   |
| **Метрики**                | Значения loss на каждом шаге итерации.             | Временные ряды (Time-series), высокая частота записи. | **MLflow Tracking** (Metrics)  |
| **Бинарные данные модели** | Сериализованный объект model (веса и архитектура). | Большие бинарные файлы (BLOB), неделимые.             | **MLflow Artifacts** / S3      |
| **Окружение**              | Версии библиотек (torch==2.0.1, mlflow==2.3).      | Конфигурационные файлы (conda.yaml).                  | **MLflow Artifacts**           |
| **Данные**                 | Набор изображений MNIST.                           | Массивные бинарные файлы, статичные или изменяемые.   | **DVC** (Data Version Control) |

Центральной задачей отчета является анализ того, как MLflow объединяет управление параметрами, метриками и моделями, и где проходит граница ответственности между ним и DVC.3

## ---

**Глава 2\. Анатомия Объекта Исследования: Архитектура MiniCNN и PyTorch**

Прежде чем анализировать процесс _записи_ эксперимента, необходимо детально разобрать _объект_ эксперимента. Понимание внутренней механики PyTorch критично для осознания того, что именно сохраняет MLflow.

### **2.1. Конструкция Нейронной Сети**

Архитектура MiniCNN, представленная в коде, является классическим примером сверточной сети для задачи классификации изображений.

Python

class MiniCNN(nn.Module):  
 def \_\_init\_\_(self):  
 super().\_\_init\_\_()  
 self.conv1 \= nn.Conv2d(1, 16, 3, 1, 1)  
 self.conv2 \= nn.Conv2d(16, 32, 3, 1, 1)  
 self.fc1 \= nn.Linear(32 \* 7 \* 7, 10)

1. **Наследование от nn.Module**: Это фундаментальный аспект. nn.Module в PyTorch — это не просто контейнер для параметров. Это сложная структура, которая отслеживает состояние всех подмодулей, управляет перемещением весов между устройствами (CPU/GPU) и, что критично для нас, поддерживает механизмы сериализации (state_dict).
2. **Сверточные слои (Conv2d)**:
   - self.conv1: Принимает 1 канал (оттенки серого MNIST), выдает 16 каналов признаков. Ядро 3x3, страйд 1, паддинг 1\. Паддинг 1 при ядре 3x3 сохраняет пространственную размерность (28x28 \-\> 28x28), что упрощает расчет размерностей.
   - self.conv2: Увеличивает глубину признакового пространства до 32 каналов.
3. **Полносвязный слой («Зал раздумий»)**:
   - self.fc1: Преобразует сплющенный (flattened) вектор признаков в 10 логитов (по числу цифр). Размерность входа 32 \* 7 \* 7 указывает на то, что после двух операций пулинга (каждая уменьшает размерность в 2 раза: 28-\>14-\>7) пространственное разрешение составляет 7x7 пикселей.

### **2.2. Вычислительный Граф и Функция Потерь**

В методе forward определяется поток данных:

Python

x \= F.relu(F.max_pool2d(self.conv1(x), 2))

Здесь применяются нелинейность ReLU и субдискретизация (Max Pooling). С точки зрения MLflow и метрик, важно то, что происходит в конце:

Python

return F.log_softmax(x, dim=1)

Модель возвращает логарифмы вероятностей. Используемый критерий nn.CrossEntropyLoss ожидает на входе именно логиты (или лог-вероятности, в зависимости от реализации, но CrossEntropyLoss в PyTorch объединяет LogSoftmax и NLLLoss).

- **Значение для метрик**: Лог-функция потерь (loss) — это числовая мера расхождения между распределением предсказаний модели и истинными метками. Это _единственный_ сигнал, который оптимизатор использует для обучения. Поэтому его гранулярное логирование в MLflow (на каждом 100-м шаге, а не раз в эпоху) критически важно для диагностики процесса сходимости.5

### **2.3. Оптимизатор Adam и его Состояние**

Используется optim.Adam. Важный нюанс для MLOps: Adam хранит _свое собственное состояние_ (моменты первого и второго порядка для каждого веса модели).

- **Проблема контрольных точек**: Если мы просто сохраним веса модели (model.state*dict()), мы потеряем состояние оптимизатора. При попытке *продолжить\_ обучение (resume training) модель будет вести себя неоптимально первые несколько эпох, заново накапливая статистику градиентов.
- **Решение MLflow**: Полная сериализация объекта или использование autolog часто позволяет сохранить и состояние оптимизатора, но в рамках данного квеста мы фокусируемся на сохранении _финального артефакта_ для инференса (предсказания), где состояние оптимизатора уже не нужно.6

## ---

**Глава 3\. Механика «Хроник»: Архитектура Трекинга MLflow**

Интеграция MLflow в скрипт переводит локальный запуск Python в статус управляемого эксперимента. Рассмотрим архитектурные слои этого процесса.

### **3.1. Инициализация Эксперимента и Контекста Выполнения**

Команда mlflow.set_experiment("Первый Свиток Хроник") выполняет важную организационную функцию. В базе данных MLflow (backend store) создается запись об эксперименте с уникальным ID. Все последующие запуски («Runs») будут привязаны к этому ID. Это позволяет группировать сотни попыток обучения одной и той же модели.

Конструкция with mlflow.start_run(run_name="...") инициирует сессию трекинга.

1. **Генерация Run UUID**: Создается уникальный идентификатор (например, e13da8ac...).
2. **Захват окружения**: MLflow (особенно в режиме autolog, но и при ручном запуске частично) пытается зафиксировать версию Git (если скрипт в репозитории), имя пользователя, время старта и входные параметры командной строки.

### **3.2. Логирование Параметров: Фиксация «Ингредиентов»**

Python

mlflow.log_param("learning_rate", learning_rate)  
mlflow.log_param("batch_size", batch_size)

Эти вызовы отправляют API-запросы на Tracking Server. Параметры сохраняются как строки типа "ключ-значение".  
Аналитическая значимость: Это позволяет проводить сравнительный анализ. В UI MLflow можно будет отфильтровать запуски: params.learning_rate \> 0.001 AND metrics.final_loss \< 0.1. Без явного логирования параметров такой анализ невозможен, и данные теряются.1

### **3.3. Логирование Метрик: Динамика Обучения**

Python

if step % 100 \== 0:  
 mlflow.log_metric("loss", loss.item(), step=step)

Это, пожалуй, самая визуально значимая часть интеграции.

- **Временные ряды**: В отличие от параметров, метрики — это данные, изменяющиеся во времени. MLflow связывает каждое значение метрики с (a) временной меткой (timestamp) и (b) шагом (step).
- **Важность аргумента step**: В коде явно передается step=step. Это _лучшая практика_. Если не указывать шаг, MLflow будет использовать внутренний счетчик, который может сбиться при перезапусках или сложной логике циклов. Явная привязка к глобальному шагу обучения (step или epoch \* len(loader) \+ batch_idx) обеспечивает корректную отрисовку графика Loss на оси X.5
- **Инсайт по производительности**: Логирование на _каждом_ шаге может замедлить обучение из\-за накладных расходов на HTTP-запросы или запись на диск. Логирование каждые 100 шагов — разумный компромисс между детализацией графика и скоростью обучения.

## ---

**Глава 4\. Ритуал Запечатления: Сериализация Моделей (Deep Dive)**

Кульминацией скрипта является вызов mlflow.pytorch.log_model(model, "model"). Это команда кажется простой, но под капотом она выполняет сложнейшую последовательность операций по упаковке и изоляции артефакта.

### **4.1. Дилемма Сериализации: Pickle vs State Dict**

В экосистеме PyTorch существуют два основных подхода к сохранению моделей 6:

1. **State Dictionary (model.state_dict())**: Сохраняет только тензоры весов (OrderedDict). Это самый надежный и рекомендуемый PyTorch способ. Однако для загрузки такой модели _требуется_ наличие исходного кода класса модели (MiniCNN) в момент загрузки, чтобы сначала инстанцировать объект, а потом загрузить в него веса.
2. **Full Object Serialization (Pickle)**: Сохраняет весь объект Python целиком, используя pickle (или cloudpickle). Это позволяет загрузить модель без явного доступа к коду класса, _если_ структура классов может быть восстановлена.

**Стратегия MLflow**: Метод log_model по умолчанию пытается обеспечить максимальное удобство. Он использует pickle (через cloudpickle), чтобы сохранить объект модели. Это позволяет загружать модель одной строкой mlflow.pytorch.load_model(...) без необходимости вручную импортировать класс MiniCNN.7

Риски и Решения:  
Главный риск такого подхода — зависимость от кода. Если вы измените или удалите файл quest_16_2.py, в котором определен класс MiniCNN, загрузка модели может упасть с ошибкой AttributeError, так как pickle не сможет найти определение класса.

- **Продвинутая техника**: Для Production-уровня надежности рекомендуется использовать аргумент code*paths в log_model. Это позволяет явно сохранить файл с определением класса (например, models.py) *внутри\_ артефакта MLflow. Тогда модель становится полностью самодостаточной.10

### **4.2. Структура MLflow-артефакта**

После выполнения log_model, в папке mlruns/.../artifacts/model создается стандартизированная структура директорий. Это и есть "набор для призыва Голема".7

1. MLmodel (YAML файл):  
   Это паспорт модели. Он описывает "вкусы" (flavors) модели.  
   YAML  
   flavors:  
    pytorch:  
    model_data: data  
    pytorch_version: 2.0.1  
    python_function:  
    loader_module: mlflow.pytorch

   Это сообщает инструментам деплоя (например, MLflow Serving или Seldon), что модель можно загрузить как нативный PyTorch объект ИЛИ как универсальную Python-функцию.

2. conda.yaml и requirements.txt:  
   MLflow автоматически сканирует текущее окружение и записывает версии библиотек. Это критически важно для воспроизводимости. Если модель обучена на PyTorch 1.13, а в продакшене стоит 2.1, поведение может измениться. Файл conda.yaml гарантирует, что для модели будет воссоздана идентичная "капсула" окружения.10
3. data/model.pth:  
   Собственно сам файл с весами модели (или сериализованным объектом). Именно здесь "живет" обученный интеллект.14

### **4.3. Сигнатуры Моделей (Signatures)**

Хотя в базовом квесте это не использовалось явно, "Золотой стандарт" требует добавления сигнатуры (Signature). Сигнатура описывает схему входных и выходных данных (например: Вход \- тензор , тип \`float32\`; Выход \- тензор , тип float32).  
Добавление сигнатуры (signature=infer_signature(...)) позволяет MLflow Server автоматически валидировать запросы при деплое, отбрасывая некорректные данные до того, как они попадут в модель и вызовут неочевидные ошибки.5

## ---

**Глава 5\. Магическое Зеркало: Визуализация и Анализ (MLflow UI)**

Запуск mlflow ui поднимает локальный сервер (обычно на порту 5000), предоставляя графический интерфейс к базе данных экспериментов.

### **5.1. Интерактивная Аналитика Метрик**

Вкладка "Metrics" визуализирует массив значений loss, записанных в цикле.

- **Диагностика сходимости**: Плавное падение кривой потерь подтверждает, что модель обучается. Если кривая скачет (высокая дисперсия) или не падает (плато), исследователь может мгновенно остановить эксперимент, экономя ресурсы.
- **Сравнение (Compare)**: Сила MLflow раскрывается при наличии нескольких запусков. Выделив Run 1 (lr=0.01) и Run 2 (lr=0.001), можно наложить их графики друг на друга. Это эмпирический способ выбора гиперпараметров, заменяющий интуицию фактами.1

### **5.2. Доступ к Артефактам**

Вкладка "Artifacts" предоставляет файловый браузер. Здесь можно скачать папку model целиком.  
Бизнес-ценность: Это точка отчуждения результата. Инженер по эксплуатации (DevOps) не должен запускать Python-код или знать, как работает PyTorch. Он просто заходит в UI, берет артефакт из "лучшего" запуска (с минимальным Loss) и отправляет его в Docker-контейнер для деплоя.18

## ---

**Глава 6\. Битва Хранителей: MLflow vs DVC**

В ответе Мастера на вопрос Техноманта затронута фундаментальная тема архитектуры MLOps. Разберем её подробно, так как это ключевой запрос.3

### **6.1. MLflow: Управление Метаданными и Жизненным Циклом**

Роль: "Лабораторный журнал".  
Природа данных: Легковесные метаданные (параметры, метрики) и артефакты моделей (обычно до нескольких гигабайт).  
Сильные стороны:

- Визуализация экспериментов в реальном времени.
- Удобный API для сравнения запусков.
- Управление реестром моделей (Model Registry) — версионирование готовых к бою моделей (Staging, Production).21  
  Ограничения: Не предназначен для версионирования огромных датасетов (терабайты данных). Загрузка датасета как артефакта MLflow создаст чудовищную дубликацию данных при каждом запуске.3

### **6.2. DVC (Data Version Control): Версионирование Данных**

Роль: "Склад сырья и готовой продукции".  
Природа данных: Тяжелые бинарные файлы (датасеты, видео, аудио).  
Механизм: DVC работает поверх Git. Он хранит сами файлы во внешнем хранилище (S3, Azure Blob, Google Drive), а в Git сохраняет только маленькие мета-файлы (.dvc) с хэшами (MD5) этих файлов.  
Сильные стороны:

- Дедупликация данных (если вы добавили 1 картинку к датасету в 100ГБ, DVC сохранит только разницу).
- Жесткая связка "Код \+ Данные" через Git commit. Вы всегда можете вернуться к состоянию "код версии X и данные версии Y".22

### **6.3. Интегрированный Workflow: Симбиоз**

Как отметил Мастер, мудрые гильдии используют их вместе. Вот схема идеального потока 4:

1. **Подготовка данных (DVC)**:
   - Инженер загружает сырые данные в папку data/.
   - Выполняет dvc add data/. Создается файл data.dvc.
   - Выполняет git add data.dvc и git commit. Теперь версия данных зафиксирована в Git.
2. **Обучение и Эксперименты (MLflow)**:
   - Запускается скрипт обучения (как в Квесте).
   - Скрипт считывает текущий хэш Git-коммита.
   - В MLflow записывается тег: mlflow.set_tag("git_commit", current_git_hash).
   - Логируются параметры, метрики и сама модель.
3. **Анализ и Воспроизведение**:
   - Исследователь видит в MLflow лучший Run.
   - Смотрит тег git_commit.
   - Делает git checkout \<hash\> в репозитории.
   - Делает dvc checkout. DVC подтягивает именно ту версию данных, которая использовалась в этом эксперименте.
   - **Результат**: Полная, побитовая воспроизводимость эксперимента.

## ---

**Глава 7\. Бизнес-Ценность и ROI (Return on Investment)**

Внедрение MLflow — это не просто техническое упражнение, это бизнес-инвестиция.

1. Ускорение Time-to-Market:  
   Команды тратят до 50% времени не на разработку моделей, а на попытки воспроизвести прошлые результаты или найти, где лежит "та самая" модель, которая хорошо работала месяц назад. MLflow устраняет этот "археологический" этап, предоставляя мгновенный доступ к истории всех экспериментов.24
2. Снижение рисков (Governance):  
   В регулируемых индустриях (финансы, медицина) необходимо объяснять, почему модель приняла решение. Связка MLflow (параметры обучения) \+ DVC (версия данных) \+ Git (код) обеспечивает полный Audit Trail (аудиторский след) создания модели.
3. Стандартизация и Коллаборация:  
   MLflow вводит единый стандарт упаковки (MLmodel). Это позволяет разделить труд: Data Scientist обучает модель и сохраняет её в MLflow, а ML Engineer берет стандартизированный артефакт и деплоит его, не вникая в детали обучения. Это разрушает "стену" между Research и Production.17

## ---

**Глава 8\. Практические Рекомендации и Устранение Неполадок**

При выполнении Квеста 16.2 и дальнейшем использовании MLflow могут возникнуть нюансы:

1. Проблема с пользовательскими классами:  
   Если при загрузке модели (load_model) вы получаете ошибку о том, что класс MiniCNN не найден, это значит, что pickle-сериализация сохранила ссылку на класс, но не его код.
   - _Решение_: Вынесите определение модели в отдельный файл .py и используйте аргумент code_paths при логировании, чтобы сохранить этот файл вместе с моделью.9
2. Большие файлы:  
   При сохранении огромных моделей через локальный Tracking Server могут возникать тайм-ауты или ошибки IncompleteRead.
   - _Решение_: Настройте MLflow на прямую запись артефактов в облачное хранилище (S3/Azure Blob), минуя проксирование через сервер трекинга.27
3. Конфликт версий:  
   Если модель не запускается в Production из\-за несовпадения версий PyTorch.
   - _Решение_: Строго следуйте использованию автоматически сгенерированного файла conda.yaml для создания изолированного окружения при инференсе.13

## ---

**Заключение**

Выполнение Квеста 16.2 демонстрирует трансформацию подхода к разработке ИИ. Интеграция **MLflow** превращает написание кода обучения из творческого хаоса в инженерную дисциплину.

Мы научились:

1. **Логировать параметры**, создавая контекст для экспериментов.
2. **Логировать метрики**, обеспечивая наблюдаемость процесса обучения в реальном времени.
3. **Сохранять артефакты моделей**, создавая отчуждаемые, воспроизводимые активы, готовые к внедрению.

Понимание различий между MLflow и DVC позволяет построить архитектуру, где каждый инструмент выполняет свою роль: MLflow управляет знаниями об экспериментах, а DVC гарантирует неизменность фундамента (данных). Это сочетание и есть «Золотой стандарт» современного MLOps, обеспечивающий переход от лабораторных прототипов к надежным промышленным системам искусственного интеллекта.

#### **Источники**

1. MLflow Tracking, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/ml/tracking/](https://mlflow.org/docs/latest/ml/tracking/)
2. Track model development using MLflow | Databricks on AWS, дата последнего обращения: декабря 21, 2025, [https://docs.databricks.com/aws/en/mlflow/tracking](https://docs.databricks.com/aws/en/mlflow/tracking)
3. MLOps : How DVC smartly manages your data sets for training your machine learning models on top of Git \- LittleBigCode, дата последнего обращения: декабря 21, 2025, [https://littlebigcode.fr/how-dvc-manages-data-sets-training-ml-models-git/](https://littlebigcode.fr/how-dvc-manages-data-sets-training-ml-models-git/)
4. ML Done Right: Versioning Datasets and Models with DVC & MLflow \- DEV Community, дата последнего обращения: декабря 21, 2025, [https://dev.to/aws-builders/ml-done-right-versioning-datasets-and-models-with-dvc-mlflow-4p3f](https://dev.to/aws-builders/ml-done-right-versioning-datasets-and-models-with-dvc-mlflow-4p3f)
5. MLflow PyTorch Integration, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/ml/deep-learning/pytorch/](https://mlflow.org/docs/latest/ml/deep-learning/pytorch/)
6. Saving and Loading Models — PyTorch Tutorials 2.9.0+cu128 documentation, дата последнего обращения: декабря 21, 2025, [https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html](https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html)
7. mlflow.pytorch, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pytorch.html](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pytorch.html)
8. \[FR\] mlflow.pytorch.log_model add the option to only save model state_dict \#4479 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/mlflow/mlflow/issues/4479](https://github.com/mlflow/mlflow/issues/4479)
9. PyTorch: Model class definitions are not persisted with saved/logged models \#832 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/mlflow/mlflow/issues/832](https://github.com/mlflow/mlflow/issues/832)
10. Managing Dependencies in MLflow Models, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/ml/model/dependencies/](https://mlflow.org/docs/latest/ml/model/dependencies/)
11. How to save or log pytorch model using MLflow? \- Microsoft Learn, дата последнего обращения: декабря 21, 2025, [https://learn.microsoft.com/en-us/answers/questions/1291132/how-to-save-or-log-pytorch-model-using-mlflow](https://learn.microsoft.com/en-us/answers/questions/1291132/how-to-save-or-log-pytorch-model-using-mlflow)
12. MLflow Models, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/ml/model/](https://mlflow.org/docs/latest/ml/model/)
13. Log, load, and register MLflow models | Databricks on AWS, дата последнего обращения: декабря 21, 2025, [https://docs.databricks.com/aws/en/mlflow/models](https://docs.databricks.com/aws/en/mlflow/models)
14. D6.6 – Tools and Techniques for Tailored Sandboxes and, дата последнего обращения: декабря 21, 2025, [https://ec.europa.eu/research/participants/documents/downloadPublic?documentIds=080166e5ed15de8e\&appId=PPGMS](https://ec.europa.eu/research/participants/documents/downloadPublic?documentIds=080166e5ed15de8e&appId=PPGMS)
15. changed propagation step (d3a919f1) · Commits · Simran Kaur, дата последнего обращения: декабря 21, 2025, [https://www.uni-hildesheim.de/gitlab/kaur/master-thesis/-/commit/d3a919f19f078b52140e0531649e426679ec2cdf?expanded=1\&page=10\&w=0](https://www.uni-hildesheim.de/gitlab/kaur/master-thesis/-/commit/d3a919f19f078b52140e0531649e426679ec2cdf?expanded=1&page=10&w=0)
16. Using MLFlow to Track, Log, and Version PyTorch Models | by nicolae caralicea \- Medium, дата последнего обращения: декабря 21, 2025, [https://medium.com/@ncaraliceanews/using-mlflow-to-track-log-and-version-pytorch-models-93e2efaa5c07](https://medium.com/@ncaraliceanews/using-mlflow-to-track-log-and-version-pytorch-models-93e2efaa5c07)
17. What is MLflow? Streamline Your ML Lifecycle \- Viso Suite, дата последнего обращения: декабря 21, 2025, [https://viso.ai/deep-learning/mlflow-machine-learning-experimentation/](https://viso.ai/deep-learning/mlflow-machine-learning-experimentation/)
18. Log metrics, parameters, and files with MLflow \- Azure Machine Learning | Microsoft Learn, дата последнего обращения: декабря 21, 2025, [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?view=azureml-api-2](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-log-view-metrics?view=azureml-api-2)
19. How to fix Artifacts not showing in MLflow UI \- Stack Overflow, дата последнего обращения: декабря 21, 2025, [https://stackoverflow.com/questions/61980244/how-to-fix-artifacts-not-showing-in-mlflow-ui](https://stackoverflow.com/questions/61980244/how-to-fix-artifacts-not-showing-in-mlflow-ui)
20. DVC vs ML Flow: Which is the best? Pros and Cons of each? : r/mlops \- Reddit, дата последнего обращения: декабря 21, 2025, [https://www.reddit.com/r/mlops/comments/qfibp4/dvc_vs_ml_flow_which_is_the_best_pros_and_cons_of/](https://www.reddit.com/r/mlops/comments/qfibp4/dvc_vs_ml_flow_which_is_the_best_pros_and_cons_of/)
21. MLflow Model Registry | MLflow, дата последнего обращения: декабря 21, 2025, [https://mlflow.org/docs/latest/model-registry.html](https://mlflow.org/docs/latest/model-registry.html)
22. MLOps: Effortlessly track your model experiments with DVC and Mlflow | by LittleBigCode, дата последнего обращения: декабря 21, 2025, [https://medium.com/hub-by-littlebigcode/mlops-effortlessly-track-your-model-experiments-with-dvc-and-mlflow-db650cffab22](https://medium.com/hub-by-littlebigcode/mlops-effortlessly-track-your-model-experiments-with-dvc-and-mlflow-db650cffab22)
23. Why DVC is Crucial for Modern ML Projects (And How It Pairs with MLflow) \- Medium, дата последнего обращения: декабря 21, 2025, [https://medium.com/@venkateshpvnky9/why-dvc-is-crucial-for-modern-ml-projects-and-how-it-pairs-with-mlflow-7ada37e5e688](https://medium.com/@venkateshpvnky9/why-dvc-is-crucial-for-modern-ml-projects-and-how-it-pairs-with-mlflow-7ada37e5e688)
24. Real ROI of Machine Learning: Boost Business Results \- WebMob Technologies, дата последнего обращения: декабря 21, 2025, [https://webmobtech.com/blog/real-roi-machine-learning-business-results/](https://webmobtech.com/blog/real-roi-machine-learning-business-results/)
25. Price Prediction Solution for Real Estate Business Using MLflow 2.0 \- Royal Cyber, дата последнего обращения: декабря 21, 2025, [https://www.royalcyber.com/blogs/price-prediction-solution-for-real-estate-business-using-mlflow-2-0/](https://www.royalcyber.com/blogs/price-prediction-solution-for-real-estate-business-using-mlflow-2-0/)
26. A Comprehensive Guide to MLflow: What It Is, Its Pros and Cons, and How to Use It in Your Python Projects | by Anna | Medium, дата последнего обращения: декабря 21, 2025, [https://medium.com/@ab.vancouver.canada/a-comprehensive-guide-to-mlflow-what-it-is-its-pros-and-cons-and-how-to-use-it-in-your-python-468af13468c6](https://medium.com/@ab.vancouver.canada/a-comprehensive-guide-to-mlflow-what-it-is-its-pros-and-cons-and-how-to-use-it-in-your-python-468af13468c6)
27. \[BUG\] Downloading an artifact from a remote MLflow results in "Connection broken: IncompleteRead" · Issue \#7360 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/mlflow/mlflow/issues/7360](https://github.com/mlflow/mlflow/issues/7360)
