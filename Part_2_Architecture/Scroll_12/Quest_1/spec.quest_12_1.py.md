# quest_12_1.py Specification

## 1. Meta Information

- **Domain:** ML/NLP
- **Complexity:** High
- **Language:** Python
- **Frameworks:** PyTorch, torchvision, tqdm
- **Context:** ../AGENTS.md

## 2. Goal & Purpose (Цель и Назначение)

Легенда: этот файл документирует создание Генератора Сновидений на базе вариационного автоэнкодера. Артефакт учится кодировать рукописные цифры в двумерное скрытое пространство и порождать новые цифры из латентных точек, демонстрируя архитектуру VAE и составную функцию потерь BCE и KLD. Он служит учебно-магическим примером, как через сжатие и реконструкцию можно превратить хаос данных во взаимосвязанное полотно сновидений и сохранить результаты в виде изображений.

## 3. Interface Contract (Интерфейсный Контракт)

### 3.1. Inputs (Входы)

- **Source:** CLI Args | STDIN | API Request | Kafka Topic | Smart Contract Call
- **Format:** JSON | Text | Binary | Stream
- **Schema:**
  interface InputData {
  // Этот артефакт не принимает внешних входов в явном виде
  }

### 3.2. Outputs (Выходы)

- **Destination:** STDOUT | File
- **Format:** JSON | CSV | Text | Binary
- **Success Criteria:** Exit Code 0 | 200 OK | File Created
- **Schema:**
  interface OutputResult {
  success: boolean;
  files?: string[];
  message?: string;
  }

## 4. Implementation Details (The Source DNA / Исходный Код)

### 4.1. Algorithmic Logic (Для исполняемого кода)

1. Притворить входы и выходы под мантру: подготовить Престол Маны и заклятье импорта. Импортируются оракулы папок (os), Источник Маны (torch), глава чертежей nn, гримуар заклинаний F, наставления optim, خدماتы torchvision и заклинание прогресса tqdm.
2. Настроить Пространство Снов: задать латентное измерение равное двум, определить число эпох как десять и размер пачки как сто двадцать восемь.
3. Подготовить Учебник Рукописей (MNIST): объявить трансформацию ToTensor, загрузить MNIST в ./data, собрать подносчик данных с перемешиванием и указанным размером пачки.
4. Создать Чертеж артефакта: построить двухчастную машину VAE с Прессом (Энкодер) и Проектором (Декодер). В Энкодере первый слой преобразует 784 пикселя в 400 скрытых единиц, затем два параллельных слоя выводят mu и logvar по двум координатам латентного пространства. В Декодере из латентной жемчужины размером 2 восстанавливается изображение сто восемьдесят четыре столбца.
5. Определить Меру Ошибок: совокупная потеря состоит из Ошибки Восстановления (BCE) и Регуляризации (KLD). BCE сравнивает восстановленное изображение с оригиналом; KLD минимизирует отклонения латентного пространства от нормального распределения.
6. Ритуал Наставления: инициализировать модель на CUDA и создать оптимайзер Adam с LR 1e-3. Запустить цикл по эпохам: в каждой эпохе перевести модель в режим обучения, пройтись по пачкам данных, прогнать через модель, вычислить и раскрутить градиенты по составной потере, обновить параметры и отслеживать среднюю ошибку.
7. Магия Творения: после обучения запереть мана-руны no_grad, сгенерировать 64 латентные жемчужины в 2-мерном пространстве, декодировать их, сохранить 64 изображения как одну сетку в файл dreams/dream_sample.png и открыть дверь к виду творения. В конце печатается сообщение о готовности сна.

### 4.2. Declarative Content (Для конфигураций и данных)

Истинные данные для воссоздания 1-в-1:

- Latent_dim: 2
- Epochs: 10
- Batch_size: 128
- Input размер: 28x28 изображений, приведённых к 784 признаку
- Архитектура Пресса: 走 784 -> 400 (первый линейный слой)
- mu: линейный слой 400 -> 2
- logvar: линейный слой 400 -> 2
- Архитектура Проектора: 2 -> 400 (линейный слой)
- Восстановление: 400 -> 784 через сигмоид
- Функция потерь: BCE + KLD
- Оптимизатор: Adam
- lr: 1e-3
- Устройство: CUDA по умолчанию (в коде есть to("cuda"))
- Данные: MNIST, transforms.ToTensor, загружаются в ./data
- Выходной файл: dreams/dream_sample.png

## 5. Structural Decomposition (Декомпозиция структуры)

- Класс VAE
  - **init**
  - encode
  - reparameterize
  - decode
  - forward
- Функция loss_function
- Блок подготовки данных
  - transform
  - train_dataset
  - train_loader
- Блок обучения
  - model = VAE().to("cuda")
  - optimizer = optim.Adam(...)
  - цикл epochs
  - цикл по batch
  - вычисление потерь, backward, optimizer.step
- Блок творения сновидений
  - no_grad контекст
  - генерация z = randn
  - sample = model.decode(z)
  - создание директории dreams
  - save_image(sample, dreams/dream_sample.png)

## 6. System Context & Constraints (Системный контекст и Ограничения)

### 6.1. Technical Constraints

- **Performance:** Оптимизировано под CUDA-устройства; использование GPU ускоряет обучение больших тензоров.
- **Concurrency:** Внутренний DataLoader предполагает пакетную обработку; параллельность не явно задана, управление по сути синхронное в рамках эпох.
- **Dependencies:** PyTorch, torchvision, tqdm — требуются для выполнения, загрузок MNIST и сохранения изображений.

### 6.2. Prohibited Actions (Negative Constraints)

- DO NOT hardcode secrets в артефакте или в логах.
- DO NOT выводить сырой набор данных в консоль в продакшене.
- DO NOT выполнять синхронные сетевые вызовы в горячем цикле обучения без обвязки.
- DO NOT оборачивать конфиги (.yaml, .json) внутрь скриптов без явной необходимости.
- DO NOT изменять версии библиотек или путей к файлам во время реконструкции артефакта.

## 7. Verification & Testing (Верификация)

### 1-2 Gherkin сценария

Функциональность: Генератор Сновидений на базе VAE

Scenario: Успешное обучение и создание образца сна
Given MNIST доступен по пути ./data и GPU-устройство доступно
When выполняется цикл обучения на 10 эпох с батчем 128 и Adam lr 0.001
Then файл dreams/dream_sample.png создается и в консоли появляется уведомление об успешном завершении

Scenario: Ошибка из-за отсутствия CUDA-доступа
Given окружение без доступного CUDA-устройства
When запускается процесс создания Гогенератора сновидений
Then процесс завершается с указанием требуемого доступного GPU и корректного падения

ИССЛЕДУЕМЫЙ АРТЕФАКТ: quest_12_1.py

ИМИНДАЖНЫЕ ЭФИРЫ: этот трактат описывает алхимию обучения вариационных автоэнкодеров на MNIST и создание мистических изображений, сохранённых в dreams/dream_sample.png. Все ключевые элементы артефакта остаются без изменений, чтобы можно было повторить путь от подготовки артефакта до финального сна.
