# === quest_12_1.py (Финальная Версия с Полными Комментариями) ===
# Имя этого пергамента, хранящего ритуал создания "Генератора Снов".
# Квест: 12.1 - Создание "Генератора Снов"
# Каноническое имя Квеста, как оно записано в Великом Кодексе.
# Цель: Реализовать с нуля Variational Autoencoder (VAE). Это генеративная модель,
# Священная цель нашего ритуала.
# которая учится "сжимать" образы в компактное "пространство снов" (латентное),
# Детальное описание цели.
# а затем творить (генерировать) новые образы из случайных точек этого пространства.
# Продолжение детального описания.

# Мы призываем "Духа-Архивариуса" (`os`) для работы с папками.
import os

# --- Акт 1: Подготовка Гримуаров ---
# Начинается первый акт: мы призываем все необходимые знания и инструменты.
# Мы призываем `torch` — наш Источник Маны.
import torch

# Мы призываем `torch.nn` (с псевдонимом `nn`) — главу с чертежами базовых блоков.
import torch.nn as nn

# Мы призываем `torch.nn.functional` (с псевдонимом `F`) — гримуар с "заклинаниями".
import torch.nn.functional as F

# Мы призываем `torch.optim` (с псевдонимом `optim`) — гримуар с "наставниками".
import torch.optim as optim

# Мы призываем гримуар `torchvision` для работы с образами.
from torchvision import datasets, transforms

# Мы призываем особое заклинание `save_image` для сохранения сетки образов.
from torchvision.utils import save_image

# Мы призываем наш верный "индикатор прогресса".
from tqdm import tqdm

# --- Акт 2: Настройка Ритуала ---
# Начинается второй акт: мы устанавливаем все правила и параметры нашего ритуала.
# Мы определяем "глубину" нашего "пространства снов". 2 измерения, чтобы его можно было
# легко представить как плоскую карту.
latent_dim = 2
# Мы устанавливаем количество "учебных лет" (полных проходов по всему учебнику).
epochs = 10
# Мы устанавливаем количество "страниц" в одной пачке, которую мы показываем ученику за раз.
batch_size = 128

# --- Акт 3: Подготовка "Учебника Снов" (MNIST) ---
# Начинается третий акт: мы готовим "учебные рукописи" для нашего Голема.
# Мы оглашаем на кристалл (консоль) о начале подготовки.
print("Готовлю 'учебник' с рукописными цифрами (MNIST)...")
# Мы создаем конвейер трансформаций. `transforms.ToTensor()` превращает
# картинку из формата Pillow в Тензор PyTorch и нормализует пиксели к диапазону [0, 1].
transform = transforms.ToTensor()
# Мы загружаем (или скачиваем один раз) учебник MNIST.
train_dataset = datasets.MNIST("./data", train=True, download=True, transform=transform)
# Мы создаем "подносчик", который будет подавать нам данные пачками по 128 штук.
train_loader = torch.utils.data.DataLoader(
    # Какой "учебник" использовать.
    train_dataset,
    # Размер одной "пачки".
    batch_size=batch_size,
    # Перемешивать "страницы" перед каждым "учебным годом".
    shuffle=True,
)


# --- Акт 4: Чертеж Нашего "Генератора Снов" ---
# Начинается четвертый акт: мы создаем "чертеж" для нашего артефакта.
# Мы создаем чертеж нашего артефакта, который состоит из двух частей: Пресса и Проектора.
class VAE(nn.Module):
    # Мы определяем заклинание Инициализации, которое создает все "механизмы".
    def __init__(self):
        # Мы произносим обязательное заклинание, пробуждающее магию родительского класса.
        super().__init__()
        # --- Чертеж "Магического Пресса" (Энкодер) ---
        # Первый слой: принимает "расплющенную" картинку (28*28=784 пикселя) и сжимает до 400.
        self.fc1 = nn.Linear(784, 400)
        # Второй слой (параллельный): из 400 "мыслей" создает "средние" координаты жемчужины (mu).
        self.fc21 = nn.Linear(400, latent_dim)
        # Третий слой (параллельный): из тех же 400 "мыслей" создает "разброс" жемчужины (logvar).
        self.fc22 = nn.Linear(400, latent_dim)

        # --- Чертеж "Проектора Снов" (Декодер) ---
        # Первый слой: принимает "жемчужину" (2 числа) и "распаковывает" ее до 400 "мыслей".
        self.fc3 = nn.Linear(latent_dim, 400)
        # Второй слой: из 400 "мыслей" воссоздает полную "расплющенную" картинку на 784 пикселя.
        self.fc4 = nn.Linear(400, 784)

    # Мы определяем заклинание "Сжатия", описывающее работу "Пресса".
    def encode(self, x):
        # Мы пропускаем данные через первый слой и "магический переключатель" ReLU.
        h1 = F.relu(self.fc1(x))
        # Мы возвращаем ДВА результата: "средние" координаты (mu) и "разброс" (logvar).
        return self.fc21(h1), self.fc22(h1)

    # Мы определяем заклинание "Магической Случайности" (Репараметризационный трюк).
    def reparameterize(self, mu, logvar):
        # Мы вычисляем стандартное отклонение из логарифма вариации.
        std = torch.exp(0.5 * logvar)
        # Мы создаем случайный "шум" той же формы, что и отклонение.
        eps = torch.randn_like(std)
        # Мы создаем финальную "жемчужину", смещая "среднюю" точку на случайную величину.
        # Это позволяет "пространству снов" быть гладким и непрерывным.
        return mu + eps * std

    # Мы определяем заклинание "Восстановления", описывающее работу "Проектора".
    def decode(self, z):
        # Мы пропускаем "жемчужину" (`z`) через слои "Проектора".
        h3 = F.relu(self.fc3(z))
        # Финальный слой мы пропускаем через "сигмоиду", чтобы все пиксели
        # восстановленной картинки были в диапазоне [0, 1].
        return torch.sigmoid(self.fc4(h3))

    # Мы определяем главное заклинание, описывающее полный цикл "сжатие-восстановление".
    def forward(self, x):
        # Мы сжимаем исходный образ (`x.view(-1, 784)` "расплющивает" его) и получаем mu и logvar.
        mu, logvar = self.encode(x.view(-1, 784))
        # Мы создаем "жемчужину" с элементом случайности.
        z = self.reparameterize(mu, logvar)
        # Мы восстанавливаем образ из "жемчужины" и возвращаем его вместе с mu и logvar.
        return self.decode(z), mu, logvar


# --- Акт 5: Особая "Мера Ошибки" для VAE ---
# У VAE сложная "рулетка", состоящая из двух частей.
def loss_function(recon_x, x, mu, logvar):
    # Часть 1: Ошибка Восстановления (BCE). Насколько воссозданная картинка
    # похожа на оригинал.
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction="sum")
    # Часть 2: Ошибка Регуляризации (KLD). "Наказание" за то, что "жемчужины"
    # в "пространстве снов" разбросаны хаотично, а не лежат красивым "облаком".
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    # Общая ошибка — это сумма двух.
    return BCE + KLD


# --- Акт 6: Ритуал Наставления ---
# Начинается шестой, кульминационный акт: мы обучаем нашего Голема.
# Мы сотворяем наш "Генератор Снов".
model = VAE().to("cuda")
# Мы готовим "Волшебный Ключ" для исправления ошибок.
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# Мы оглашаем на кристалл о начале ритуала Наставления.
print("\nНачинаю ритуал наставления 'Генератора Снов'...")
# Мы запускаем урок на 10 "учебных лет".
for epoch in range(1, epochs + 1):
    # Мы переводим Голема в режим "обучения".
    model.train()
    # Мы создаем "счетчик" для общей ошибки за эпоху.
    train_loss = 0
    # Мы берем пачки "учебных страниц" из нашего "подносчика".
    for batch_idx, (data, _) in tqdm(
        # Мы итерируемся по нашему "Подносчику".
        enumerate(train_loader),
        # Мы указываем общее количество шагов для индикатора.
        total=len(train_loader),
        # Мы добавляем описание к индикатору прогресса.
        desc=f"Эпоха {epoch}",
    ):
        # Мы отправляем данные на Кристалл Маны.
        data = data.to("cuda")
        # Мы стираем старые ошибки.
        optimizer.zero_grad()
        # Мы прогоняем данные через модель.
        recon_batch, mu, logvar = model(data)
        # Мы считаем сложную, составную ошибку.
        loss = loss_function(recon_batch, data, mu, logvar)
        # Мы вычисляем "шепот" для исправления.
        loss.backward()
        # Мы добавляем ошибку к общему счетчику.
        train_loss += loss.item()
        # Мы "подкручиваем" все руны.
        optimizer.step()
    # Мы печатаем отчет в конце каждого "учебного года".
    print(f"====> Эпоха: {epoch} Средняя ошибка: {train_loss / len(train_dataset):.4f}")

# --- Акт 7: Магия Творения (Сновидение) ---
# Начинается финальный акт: мы просим нашего Голема сотворить новый образ.
# Мы оглашаем на кристалл о начале ритуала творения.
print("\nРитуал завершен! Прошу 'Генератор' увидеть сон...")
# Мы используем защитное заклинание `no_grad` для экономии маны.
with torch.no_grad():
    # Мы создаем 64 случайные "жемчужины" в нашем 2-мерном "пространстве снов".
    z = torch.randn(64, latent_dim).to("cuda")
    # Мы просим "Проектор" (декодер) воссоздать образы из этих случайных "жемчужин".
    # `.cpu()` — переносит результат обратно с Кристалла Маны для сохранения.
    sample = model.decode(z).cpu()

    # Мы готовим "ящик" для наших снов, создавая папку.
    os.makedirs("dreams", exist_ok=True)
    # `save_image` — это заклинание, которое красиво укладывает 64 маленькие
    # картинки в одну большую сетку и сохраняет ее.
    save_image(sample.view(64, 1, 28, 28), "dreams/dream_sample.png")

# Мы оглашаем, что ритуал успешно завершен.
print(
    "Сон материализован! Открой 'dreams/dream_sample.png', чтобы увидеть новые, сотворенные цифры."
)
