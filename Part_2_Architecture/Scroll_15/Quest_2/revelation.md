# **Архитектурный анализ высокопроизводительного ввода данных в PyTorch: Стратегии оптимизации параллелизма DataLoader и управление ресурсами**

## **1\. Введение: Экономическая и вычислительная парадигма подготовки данных**

В современной экосистеме глубокого обучения (Deep Learning) эффективность вычислительного конвейера определяется не только скоростью матричных операций на графических процессорах (GPU) или тензорных процессорах (TPU), но и способностью подсистемы ввода-вывода (I/O) обеспечивать непрерывный поток данных к этим ускорителям. Проблема, известная как «GPU starvation» (голодание GPU), когда дорогостоящие вычислительные ресурсы простаивают в ожидании данных от центрального процессора (CPU), представляет собой критический барьер для масштабирования систем искусственного интеллекта.  
Экономические последствия неэффективной загрузки данных огромны. Анализ инфраструктурных затрат показывает, что организации часто теряют до 60-70% бюджета, выделенного на GPU, из\-за простоя ресурсов.1 В контексте кластеров, состоящих из ускорителей класса NVIDIA H100, простой в 40% из\-за субоптимальной настройки конвейера данных может транслироваться в десятки тысяч долларов ежемесячных операционных потерь только на аренде оборудования, не считая затрат на электроэнергию и упущенной выгоды от задержки вывода моделей на рынок.2 Более того, простаивающий GPU потребляет значительное количество энергии, что напрямую влияет на углеродный след обучения моделей и противоречит целям устойчивого развития.2  
В данном отчете проводится всесторонний анализ механизма DataLoader в библиотеке PyTorch, с особым акцентом на гиперпараметр num_workers. Мы исследуем архитектурные принципы, лежащие в основе параллельной загрузки данных, взаимодействие с Global Interpreter Lock (GIL) в Python, механизмы управления памятью операционной системы (такие как Copy-on-Write), а также аппаратные ограничения, возникающие при масштабировании количества рабочих процессов. Отчет базируется на эмпирических данных, документации PyTorch и анализе поведения системы в условиях синтетических (как в «Квесте 15.2») и реальных нагрузок.

## **2\. Теоретические основы конвейера данных: Модель Производитель-Потребитель**

### **2.1 Синхронный режим и бутылочное горлышко фон Неймана**

В своей простейшей реализации процесс обучения нейронной сети представляет собой цикл, состоящий из трех фаз: загрузка и предобработка данных (CPU), передача данных (PCIe шина), и вычисление градиентов (GPU). При использовании DataLoader с параметром num_workers=0, вся эта цепочка выполняется последовательно в рамках одного процесса.3  
В этом режиме, который мы называем «Ленивый Подносчик», основной процесс Python (Main Process) берет на себя ответственность за чтение данных с диска, их декодирование (например, JPEG в тензор), применение аугментаций (вращение, изменение размера) и формирование батча (collate). Только после завершения всех этих операций управление передается GPU. В это время GPU полностью простаивает. Соответственно, когда GPU выполняет вычисления, CPU простаивает, ожидая завершения шага обучения. Это классическая проблема синхронного блокирующего ввода-вывода.  
Для небольших датасетов (например, MNIST), которые полностью помещаются в оперативную память (RAM) и требуют минимальной предобработки, этот подход может быть приемлем.4 Однако в задачах компьютерного зрения или обработки естественного языка, где данные хранятся на диске, а предобработка включает тяжелые математические операции, время подготовки данных часто превышает время их обработки на GPU. В таких сценариях использование num_workers=0 становится главным фактором деградации производительности.6

### **2.2 Асинхронная развязка через мультипроцессинг**

Для решения этой проблемы PyTorch реализует паттерн «Производитель-Потребитель» (Producer-Consumer) через механизм мультипроцессинга. Установка num_workers \> 0 трансформирует архитектуру загрузчика данных. Вместо последовательного выполнения, основной процесс делегирует задачу подготовки данных пулу независимых рабочих процессов (workers).3  
Эти рабочие процессы функционируют параллельно с основным циклом обучения. Пока «Кристалл Маны» (GPU) занят вычислением градиентов для батча $N$, «Духи-Помощники» (Workers) уже загружают, декодируют и аугментируют данные для батчей $N+1, N+2$ и так далее. Подготовленные данные помещаются в очередь результатов (Result Queue), находящуюся в разделяемой памяти. Когда основной цикл запрашивает следующие данные, он мгновенно получает их из очереди, практически устраняя задержку на ожидание I/O и CPU-операций.7  
Это фундаментальное изменение архитектуры позволяет скрыть латентность подготовки данных, но вводит сложный слой управления межпроцессным взаимодействием (IPC), синхронизацией и памятью, который требует тонкой настройки.

## **3\. Архитектура параллелизма в Python и роль GIL**

### **3.1 Ограничения потоков и необходимость процессов**

Ключевой вопрос, который возникает при анализе архитектуры DataLoader: почему PyTorch использует тяжеловесные процессы (multiprocessing), а не легковесные потоки (threading)? Ответ кроется в архитектуре интерпретатора CPython и Глобальной Блокировке Интерпретатора (Global Interpreter Lock — GIL).3  
GIL — это мьютекс, который предотвращает одновременное выполнение байт-кода Python несколькими нативными потоками внутри одного процесса. Хотя GIL освобождается во время операций ввода-вывода (например, чтение файла с диска), он удерживается во время любых вычислений на CPU. Поскольку современная предобработка данных (аугментация изображений, токенизация текста) является вычислительно интенсивной задачей, использование потоков привело бы к тому, что аугментация выполнялась бы последовательно, просто переключаясь между ядрами, но не используя их параллельно.  
Использование multiprocessing позволяет обойти это ограничение. Каждый рабочий процесс (worker) запускает собственный экземпляр интерпретатора Python с собственным GIL и собственным пространством памяти. Это позволяет полностью утилизировать многоядерные архитектуры современных процессоров, выполняя аугментацию данных истинно параллельно.3

### **3.2 Методы создания процессов: Fork против Spawn**

Способ, которым операционная система порождает эти рабочие процессы, имеет критическое значение для производительности и потребления памяти. PyTorch поддерживает три метода старта процессов: fork, spawn и forkserver, выбор которых зависит от операционной системы и конфигурации.8

| Метод          | Механизм                                                                                           | Преимущества                                                                | Недостатки                                                                                              | Платформа по умолчанию               |
| :------------- | :------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------ | :----------------------------------- |
| **Fork**       | Клонирование родительского процесса через копирование страниц памяти в режиме Copy-on-Write (COW). | Быстрый старт; Изначально низкое потребление памяти (разделяемые страницы). | Небезопасен при использовании CUDA до форка; Проблемы с многопоточными библиотеками.                    | Linux / macOS (до недавнего времени) |
| **Spawn**      | Запуск нового интерпретатора Python с нуля; повторный импорт модулей и сериализация объектов.      | Чистое состояние; Безопасен для CUDA; Кроссплатформенный.                   | Медленный старт; Высокое потребление памяти (нет разделения страниц); Требует pickling всех аргументов. | Windows / macOS (современные)        |
| **Forkserver** | Запуск сервера, который порождает процессы по запросу.                                             | Баланс между скоростью и изоляцией; избегает некоторых проблем fork.        | Сложность реализации; Требует явной настройки.                                                          | Опционально на Linux                 |

На Unix-системах PyTorch по умолчанию использует fork из\-за его эффективности. Однако, как будет показано в разделе об управлении памятью, взаимодействие fork с механизмом подсчета ссылок в Python может приводить к значительному росту потребления RAM.9  
Важно отметить проблему «poison fork»: если инициализация контекста CUDA происходит в основном процессе _до_ создания рабочих процессов через fork, это может привести к непредсказуемым ошибкам или сбоям в дочерних процессах, так как контекст CUDA не предназначен для копирования.8 Поэтому золотое правило инженерии данных в PyTorch: **рабочие процессы DataLoader не должны взаимодействовать с GPU**. Их задача — подготовить тензоры в оперативной памяти CPU. Перенос на GPU должен осуществляться основным процессом.

## **4\. Динамика масштабирования num_workers: Анализ производительности и переподписка**

В «Квесте 15.2» Техномант задает фундаментальный вопрос: если 4 духа работают быстрее, чем 0, будут ли 16, 32 или 100 духов работать еще быстрее? Ответ на этот вопрос лежит в плоскости взаимодействия программного обеспечения с физическими ресурсами процессора.

### **4.1 Кривая убывающей полезности**

Зависимость пропускной способности (throughput) от количества рабочих процессов не линейна. Вначале добавление каждого нового процесса заполняет простои I/O и позволяет утилизировать свободные ядра CPU. Если время подготовки одного батча занимает $T\_{prep}$, а время его обработки на GPU — $T\_{train}$, то в идеальном сценарии нам нужно столько воркеров, чтобы скорость их совокупной генерации данных превышала скорость потребления GPU ($N \\times \\frac{1}{T\_{prep}} \\ge \\frac{1}{T\_{train}}$).  
Однако, как только пропускная способность загрузки данных начинает превышать скорость обучения модели, добавление новых воркеров перестает давать прирост производительности. Система переходит из состояния I/O Bound (ограничена вводом-выводом) в состояние Compute Bound (ограничена вычислениями GPU). В этот момент дополнительные процессы просто заполняют очередь результатов быстрее, чем она опустошается, блокируясь в ожидании свободного слота.12

### **4.2 Переподписка CPU (CPU Oversubscription) и контекстное переключение**

Более того, чрезмерное увеличение num*workers может привести к *деградации\_ производительности. Это связано с явлением, известным как переподписка (Oversubscription). Если физический процессор имеет, например, 8 ядер, а мы запускаем 32 рабочих процесса, планировщик операционной системы (OS Scheduler) вынужден распределять процессорное время между ними через квантование времени.8  
Этот процесс требует частого **переключения контекста** (Context Switching). При каждом переключении процессор должен сохранить состояние текущего процесса (регистры, программный счетчик) в память, загрузить состояние следующего процесса и, что самое критичное, сбросить кэши (L1/L2/L3) и буфер ассоциативной трансляции (TLB). Эти накладные расходы могут быть существенными. Если процессы проводят больше времени в переключении контекста, чем в полезной работе, общая производительность системы падает.  
В реальных сценариях, где аугментация данных требует интенсивных вычислений (например, поворот 3D-тензоров или спектрограмм), каждый рабочий процесс стремится полностью загрузить ядро CPU. В таких условиях оптимальное количество воркеров обычно равно количеству физических ядер процессора (или чуть меньше, чтобы оставить ресурсы для основного процесса и ОС).13

### **4.3 Специфика эксперимента «Квест 15.2»**

Важно проанализировать специфику эксперимента, предложенного в квесте. Использование time.sleep(0.05) создает искусственную нагрузку, которая является чисто блокирующей, но не потребляет ресурсы CPU \[User Query\]. В терминологии ОС процесс находится в состоянии SLEEP или WAIT.  
В таком синтетическом сценарии масштабирование num_workers может казаться почти линейным даже при значениях, превышающих количество ядер. Поскольку спящие процессы не конкурируют за вычислительные циклы, планировщик ОС может легко управлять сотнями таких процессов с минимальными накладными расходами. Это создает ложное впечатление бесконечной масштабируемости.  
Однако, как только мы заменяем time.sleep на реальную нагрузку (например, transforms.Resize), ситуация меняется. Реальная аугментация переводит процессы в состояние RUNNING. В этот момент конкуренция за ядра становится жесткой, и вступают в силу законы переподписки. Инженер должен понимать, что результаты, полученные на синтетическом тесте с sleep, не переносятся напрямую на продакшн-системы с тяжелой вычислительной нагрузкой.15

## **5\. Управление памятью: Механизм Copy-on-Write и проблема утечек**

Одной из самых сложных и неочевидных проблем при использовании DataLoader с num_workers \> 0 является взрывной рост потребления оперативной памяти (RAM). Инженеры часто сталкиваются с ситуацией, когда потребление памяти растет линейно с числом воркеров, приводя к Out-Of-Memory (OOM) ошибкам на уровне системы, даже если размер батча невелик.

### **5.1 Механизм Copy-on-Write (COW) в Linux**

При создании процесса через fork() операционная система Linux не копирует всю физическую память родительского процесса для дочернего. Вместо этого она копирует только таблицы страниц (Page Tables), указывающие на те же физические адреса. Страницы помечаются как «только для чтения» (read-only). Если любой из процессов пытается записать данные в такую страницу, процессор генерирует прерывание (page fault), и ядро ОС создает копию этой страницы для пишущего процесса. Это называется Copy-on-Write.17  
В теории это должно позволять рабочим процессам читать данные из общего объекта Dataset (загруженного в основном процессе) без дублирования памяти. Однако на практике в Python это работает иначе.

### **5.2 Проблема подсчета ссылок (Reference Counting)**

Python использует механизм подсчета ссылок для управления памятью и сборки мусора. Каждый объект Python (PyObject) содержит поле счетчика ссылок. Даже простая операция чтения объекта (например, доступ к элементу списка self.data\[idx\]) временно увеличивает, а затем уменьшает этот счетчик.  
С точки зрения операционной системы, изменение счетчика ссылок — это операция **записи** в память. Когда рабочий процесс итерируется по датасету, он массово модифицирует счетчики ссылок объектов датасета. Это вызывает лавину событий Copy-on-Write. Страницы памяти, которые должны были оставаться общими, дублируются для каждого рабочего процесса. Если датасет занимает 20 ГБ в RAM, а мы запускаем 10 воркеров, потребление памяти может потенциально вырасти до 200 ГБ \+ 20 ГБ.9

### **5.3 Стратегии минимизации потребления памяти**

Существует несколько архитектурных паттернов для борьбы с этим явлением:

1. **Ленивая загрузка (Lazy Loading):** В методе \_\_init\_\_ датасета следует хранить только минимально необходимые метаданные (например, список путей к файлам, а не сами изображения). Сами данные загружаются только в методе \_\_getitem\_\_. Поскольку \_\_getitem\_\_ выполняется внутри рабочего процесса, данные аллоцируются в его памяти и освобождаются после обработки, не вызывая дублирования больших структур родительского процесса.5
2. **Использование разделяемой памяти (Shared Memory):** Для передачи тензоров между процессами PyTorch использует механизм разделяемой памяти (обычно через /dev/shm в Linux). Это позволяет избежать накладных расходов на сериализацию тензоров. Однако это касается только результатов работы воркера. Для входных данных можно использовать структуры типа multiprocessing.Array или файлы, отображаемые в память (mmap), которые не подвержены проблеме refcounting так, как стандартные объекты Python.21
3. **Принудительная заморозка объектов:** В новых версиях Python и специализированных форках (как Cinder от Meta) появляются механизмы для «заморозки» счетчиков ссылок долгоживущих объектов, что предотвращает COW, но это пока не является стандартной практикой повсеместно.23

## **6\. Задержки пропускной способности и персистентность воркеров**

### **6.1 Цена границы эпохи (Epoch Boundary Cost)**

По умолчанию (persistent_workers=False), PyTorch уничтожает все рабочие процессы в конце итерации по DataLoader (обычно это конец эпохи обучения) и создает их заново при начале следующей. Этот процесс создания и уничтожения (teardown и respawn) является дорогим.  
Он включает в себя системные вызовы fork/clone, инициализацию интерпретатора Python, импорт библиотек (особенно в режиме spawn), и первичную загрузку данных. В результате, в начале каждой эпохи наблюдается всплеск простоя GPU, пока воркеры «разогреваются». Для коротких эпох или быстро обучаемых моделей этот оверхед может составлять значительную часть общего времени обучения.24

### **6.2 Использование persistent_workers=True**

Параметр persistent_workers=True меняет жизненный цикл воркеров. Они не уничтожаются после исчерпания итератора, а переходят в режим ожидания, сохраняя свое состояние и память. При следующем вызове iter(dataloader) они мгновенно готовы к работе.25  
**Преимущества:**

- Устранение латентности между эпохами.
- Сохранение кэшей и открытых файловых дескрипторов внутри воркеров.

**Риски и недостатки:**

- **Блокировка памяти:** Воркеры продолжают удерживать память, даже если обучение приостановлено (например, для валидации). Если создается отдельный DataLoader для валидации с собственными персистентными воркерами, общее потребление памяти системой может удвоиться, так как воркеры тренировочного загрузчика не освобождают ресурсы.26
- **Сброс состояния:** Если логика датасета предполагает изменение состояния между эпохами (например, пересчет глобальной статистики), персистентные воркеры могут не подхватить эти изменения автоматически, так как объект Dataset внутри них не пересоздается. Требуется явное управление через методы сброса или worker_init_fn.26

## **7\. Аппаратный интерфейс: Pin Memory и трансфер Хост-Устройство**

В то время как num*workers оптимизирует этап *Диск \-\> RAM* и \_CPU-трансформации*, финальный этап конвейера — это перемещение данных из _RAM в VRAM_ (память видеокарты) через шину PCIe.

### **7.1 Страничная (Paged) и Закрепленная (Pinned) память**

Стандартная оперативная память, выделяемая ОС для программ, является страничной (pageable). Это означает, что менеджер виртуальной памяти может перемещать страницы физической памяти или выгружать их в swap-файл на диске. Контроллер DMA (Direct Memory Access) видеокарты не может безопасно читать данные из такой памяти, так как физический адрес данных может измениться в любой момент.  
Поэтому, перед передачей данных на GPU, драйвер CUDA неявно копирует их в специальную область «закрепленной» (pinned или page-locked) памяти, которая гарантированно находится в физическом RAM и не может быть выгружена. Это создает лишний шаг копирования: _Pageable RAM \-\> Pinned RAM \-\> GPU VRAM_.28

### **7.2 Роль pin_memory=True**

Установка флага pin_memory=True в DataLoader заставляет PyTorch выделять тензоры сразу в закрепленной памяти (или копировать их туда специальным потоком).  
Когда num_workers \> 0 и pin_memory=True, в основном процессе создается специальный поток pin_memory_thread. Этот поток забирает тензоры из очереди результатов воркеров, копирует их в закрепленную память и помещает в финальную очередь для потребления циклом обучения.29  
**Ключевые преимущества:**

1. **Асинхронный DMA:** Передача данных из закрепленной памяти на GPU может происходить асинхронно по отношению к CPU. Вызов tensor.to(device, non_blocking=True) возвращает управление немедленно, позволяя CPU готовить следующий батч или запускать ядра, пока данные льются по шине PCIe.7
2. **Повышение пропускной способности:** Исключается промежуточное копирование внутри драйвера, что увеличивает эффективную пропускную способность PCIe.

**Архитектурный нюанс:** Поток pin_memory работает в основном процессе. Если количество воркеров очень велико, они могут генерировать данные быстрее, чем этот единственный поток успевает их «пинить», создавая новое бутылочное горлышко уже на стороне основного процесса.31

## **8\. Стохастика и воспроизводимость в параллельной среде**

Критический аспект параллельной загрузки — управление случайностью. В задачах глубокого обучения воспроизводимость (reproducibility) является обязательным требованием для отладки и сравнения моделей.  
Стандартные генераторы псевдослучайных чисел (PRNG) в библиотеках Python (random) и NumPy (numpy.random) могут наследовать состояние (seed) родительского процесса при форке. Без явного переинициализирования это приводит к тому, что все рабочие процессы будут генерировать _идентичные_ последовательности случайных чисел.  
В контексте аугментации данных это катастрофа: каждый воркер будет применять одни и те же «случайные» трансформации (например, поворот на 15 градусов) к своим батчам. Это резко снижает разнообразие обучающих данных и ведет к переобучению.33  
PyTorch автоматически управляет своим внутренним генератором (torch.rand), обеспечивая уникальные сиды для каждого воркера. Однако для сторонних библиотек (NumPy, OpenCV, Albumentations) необходимо использовать функцию worker_init_fn. Эта функция должна вызываться при инициализации каждого воркера для установки уникального зерна генерации, зависящего от worker_id и текущей эпохи (чтобы аугментации менялись от эпохи к эпохе).34  
Пример корректной инициализации:

Python

def seed_worker(worker_id):  
 worker_seed \= torch.initial_seed() % 2\*\*32  
 numpy.random.seed(worker_seed)  
 random.seed(worker_seed)

## **9\. Стратегии эвристического тюнинга и диагностики**

На основе анализа архитектурных ограничений (GIL, COW, PCIe, переподписка) можно сформулировать матрицу решений для выбора оптимального значения num_workers.

### **9.1 Матрица решений**

| Сценарий                            | Рекомендация num_workers                   | Обоснование                                                                                                                                          |
| :---------------------------------- | :----------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Отладка / Разработка**            | 0                                          | Детерминизм, простота стека вызовов, отсутствие оверхеда на старт процессов. Идеально для проверки кода модели.                                      |
| **I/O-Bound (HDD / Сеть)**          | $2 \\times$ \- $4 \\times$ Кол-во ядер CPU | Если узкое место — ожидание диска, CPU простаивает. Переподписка допустима и полезна для скрытия латентности диска.                                  |
| **CPU-Bound (Тяжелая аугментация)** | $1 \\times$ Кол-во ядер CPU                | Узкое место — вычисления CPU. Переподписка вредна из\-за context switching.                                                                          |
| **Большие сервера (64+ ядер)**      | Ограничить до 16-32                        | Закон убывающей отдачи. Слишком много процессов создают нагрузку на планировщик ОС и шину памяти, не давая прироста.                                 |
| **Распределенное обучение (DDP)**   | $\\frac{\\text{Ядра CPU}}{\\text{GPU}}$    | Каждый GPU запускает свой процесс. Общее число воркеров на узле \= num_workers $\\times$ world_size. Ошибка здесь приводит к фатальной перегрузке.37 |

### **9.2 Диагностика проблем**

Для точной настройки необходимо использовать инструменты профилирования, такие как **PyTorch Profiler**.

- Если на временной шкале профилировщика видны пробелы в работе GPU (Kernel execution), совпадающие с активностью DataLoader — налицо голодание GPU. Требуется увеличить num_workers или оптимизировать Dataset.
- Если загрузка CPU системы 100%, а GPU простаивает — достигнут предел пропускной способности CPU. Увеличение num_workers не поможет (или ухудшит ситуацию). Требуется упростить аугментации или перейти на DALI (GPU-аугментации).
- Если потребление RAM растет линейно со временем — вероятна утечка памяти из\-за накопления ссылок в DataLoader или некорректной работы с Python-объектами в мультипроцессной среде.19

## **10\. Распределенные системы и масштабирование (DDP)**

В контексте распределенного обучения (Distributed Data Parallel \- DDP) архитектура загрузки данных усложняется. Каждый процесс DDP (обычно один на GPU) создает свой собственный экземпляр DataLoader.  
Распространенная ошибка инженеров — устанавливать num_workers равным количеству ядер процессора на машине, забывая, что этот параметр множится на количество GPU.

- _Пример:_ Сервер с 48 ядрами и 4 GPU.
- _Ошибка:_ Установка num_workers=48.
- _Результат:_ 4 процесса DDP $\\times$ 48 воркеров \= 192 процесса. Это приводит к массовой переподписке, конкуренции за кэш процессора и коллапсу производительности.39
- _Правильная настройка:_ num_workers \= 48 / 4 \= 12\.

Также в DDP необходимо использовать DistributedSampler. Этот семплер гарантирует, что разные процессы DDP загружают разные части датасета, предотвращая обучение на дублирующихся данных.

## **11\. Заключение**

Эксперимент «Квест 15.2» и последующий глубокий анализ демонстрируют, что оптимизация DataLoader — это не просто перебор одного параметра, а комплексная инженерная задача балансировки ресурсов.  
Параметр num_workers является рычагом управления параллелизмом, но его эффективность ограничена физическими законами работы процессора, пропускной способностью памяти и накладными расходами операционной системы на управление процессами. «Магия» параллелизма заканчивается там, где начинается конкуренция за ресурсы.  
Для Техноманта и любого ML-инженера выводы однозначны:

1. Параллельная загрузка (num_workers \> 0\) обязательна для эффективного обучения.
2. Чрезмерное увеличение числа воркеров вредно (oversubscription).
3. Необходимо учитывать контекст: тип нагрузки (I/O или CPU), наличие закрепленной памяти (pin_memory), персистентность (persistent_workers) и особенности распределенной среды.
4. Профилирование и эксперименты — единственный надежный способ найти «Золотую середину».

Эффективный пайплайн данных — это фундамент, на котором строятся современные ИИ-системы. Понимание его внутреннего устройства позволяет превратить хаотичный набор процессов в стройный, высокопроизводительный механизм, максимально раскрывающий потенциал дорогостоящего вычислительного оборудования.

#### **Источники**

1. Improving GPU Utilization: Strategies and Best Practices \- Mirantis, дата последнего обращения: декабря 20, 2025, [https://www.mirantis.com/blog/improving-gpu-utilization-strategies-and-best-practices/](https://www.mirantis.com/blog/improving-gpu-utilization-strategies-and-best-practices/)
2. idle gpus are bleeding money, did the math on our h100 cluster and it's worse than I thought, дата последнего обращения: декабря 20, 2025, [https://www.reddit.com/r/mlops/comments/1op6p00/idle_gpus_are_bleeding_money_did_the_math_on_our/](https://www.reddit.com/r/mlops/comments/1op6p00/idle_gpus_are_bleeding_money_did_the_math_on_our/)
3. torch.utils.data.DataLoader \- PyTorch documentation, дата последнего обращения: декабря 20, 2025, [https://docs.pytorch.org/docs/stable/data.html](https://docs.pytorch.org/docs/stable/data.html)
4. Can ideal num_workers for a large dataset in PyTorch be 0? \- Stack Overflow, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/73331758/can-ideal-num-workers-for-a-large-dataset-in-pytorch-be-0](https://stackoverflow.com/questions/73331758/can-ideal-num-workers-for-a-large-dataset-in-pytorch-be-0)
5. A clear explanation of what num_workers=0 means for a DataLoader \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/a-clear-explanation-of-what-num-workers-0-means-for-a-dataloader/177614](https://discuss.pytorch.org/t/a-clear-explanation-of-what-num-workers-0-means-for-a-dataloader/177614)
6. How the "Number of Workers" Parameter in PyTorch DataLoader Actually Works, дата последнего обращения: декабря 20, 2025, [https://www.geeksforgeeks.org/deep-learning/how-the-number-of-workers-parameter-in-pytorch-dataloader-actually-works/](https://www.geeksforgeeks.org/deep-learning/how-the-number-of-workers-parameter-in-pytorch-dataloader-actually-works/)
7. Performance Tuning Guide — PyTorch Tutorials 2.9.0+cu128 documentation, дата последнего обращения: декабря 20, 2025, [https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html](https://docs.pytorch.org/tutorials/recipes/recipes/tuning_guide.html)
8. Multiprocessing best practices — PyTorch 2.9 documentation, дата последнего обращения: декабря 20, 2025, [https://docs.pytorch.org/docs/stable/notes/multiprocessing.html](https://docs.pytorch.org/docs/stable/notes/multiprocessing.html)
9. Demystify RAM Usage in Multi-Process Data Loaders \- Yuxin's Blog, дата последнего обращения: декабря 20, 2025, [https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/](https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/)
10. Potential memory leak in multiprocessing · Issue \#50902 · python/cpython \- GitHub, дата последнего обращения: декабря 20, 2025, [https://github.com/python/cpython/issues/50902](https://github.com/python/cpython/issues/50902)
11. Automatic differentiation package \- torch.autograd — PyTorch 2.9 documentation, дата последнего обращения: декабря 20, 2025, [https://docs.pytorch.org/docs/stable/autograd.html](https://docs.pytorch.org/docs/stable/autograd.html)
12. How to choose the value of the num_workers of Dataloader \- vision \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/how-to-choose-the-value-of-the-num-workers-of-dataloader/53965](https://discuss.pytorch.org/t/how-to-choose-the-value-of-the-num-workers-of-dataloader/53965)
13. Guidelines for assigning num_workers to DataLoader \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813](https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813)
14. What is the recommended number of threads for PyTorch relative to available CPU cores?, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/76084214/what-is-the-recommended-number-of-threads-for-pytorch-relative-to-available-cpu](https://stackoverflow.com/questions/76084214/what-is-the-recommended-number-of-threads-for-pytorch-relative-to-available-cpu)
15. DataLoader slower with num_workers \> 0 \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/dataloader-slower-with-num-workers-0/100970](https://discuss.pytorch.org/t/dataloader-slower-with-num-workers-0/100970)
16. Why next(iter(train_dataloader)) takes long execution time in PyTorch \- Stack Overflow, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/78225920/why-nextitertrain-dataloader-takes-long-execution-time-in-pytorch](https://stackoverflow.com/questions/78225920/why-nextitertrain-dataloader-takes-long-execution-time-in-pytorch)
17. Understanding and Optimizing Python multi-process Memory Management | by Luis Sena, дата последнего обращения: декабря 20, 2025, [https://luis-sena.medium.com/understanding-and-optimizing-python-multi-process-memory-management-24e1e5e79047](https://luis-sena.medium.com/understanding-and-optimizing-python-multi-process-memory-management-24e1e5e79047)
18. unexpected memory footprint differences when spawning python multiprocessing pool, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/27809586/unexpected-memory-footprint-differences-when-spawning-python-multiprocessing-poo](https://stackoverflow.com/questions/27809586/unexpected-memory-footprint-differences-when-spawning-python-multiprocessing-poo)
19. Pytorch data loader with multiple workers | Amazon Q, Detector Library, дата последнего обращения: декабря 20, 2025, [https://docs.aws.amazon.com/codeguru/detector-library/python/pytorch-data-loader-with-multiple-workers/](https://docs.aws.amazon.com/codeguru/detector-library/python/pytorch-data-loader-with-multiple-workers/)
20. Overall memory usage using multi-process data loading with Subset \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/overall-memory-usage-using-multi-process-data-loading-with-subset/186585](https://discuss.pytorch.org/t/overall-memory-usage-using-multi-process-data-loading-with-subset/186585)
21. PyTorch DataLoaders and Shared Memory \- Walking in the Latent Space, дата последнего обращения: декабря 20, 2025, [https://latentwalk.io/2023/08/19/torch-shmem/](https://latentwalk.io/2023/08/19/torch-shmem/)
22. python multiprocessing \- Pytorch dataset and shared memory? \- Stack Overflow, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/60542153/pytorch-dataset-and-shared-memory](https://stackoverflow.com/questions/60542153/pytorch-dataset-and-shared-memory)
23. Issue 40255: Fixing Copy on Writes from reference counting and immortal objects \- Python tracker, дата последнего обращения: декабря 20, 2025, [https://bugs.python.org/issue40255](https://bugs.python.org/issue40255)
24. Speed Up Model Training — PyTorch Lightning 2.6.0 documentation, дата последнего обращения: декабря 20, 2025, [https://lightning.ai/docs/pytorch/stable/advanced/speed.html](https://lightning.ai/docs/pytorch/stable/advanced/speed.html)
25. DataLoader persistent_workers Usage \- data \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/dataloader-persistent-workers-usage/189329](https://discuss.pytorch.org/t/dataloader-persistent-workers-usage/189329)
26. What are the (dis) advantages of persistent_workers \- vision \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/what-are-the-dis-advantages-of-persistent-workers/102110](https://discuss.pytorch.org/t/what-are-the-dis-advantages-of-persistent-workers/102110)
27. Open file leak when dataloader is using persistent_workers and pin_memory AND you create multiple dataloaders. · Issue \#91252 · pytorch/pytorch \- GitHub, дата последнего обращения: декабря 20, 2025, [https://github.com/pytorch/pytorch/issues/91252](https://github.com/pytorch/pytorch/issues/91252)
28. Pytorch. How does pin_memory work in Dataloader? \- Stack Overflow, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/55563376/pytorch-how-does-pin-memory-work-in-dataloader](https://stackoverflow.com/questions/55563376/pytorch-how-does-pin-memory-work-in-dataloader)
29. Why not multiprocess pin_memory in data loader? \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/why-not-multiprocess-pin-memory-in-data-loader/197345](https://discuss.pytorch.org/t/why-not-multiprocess-pin-memory-in-data-loader/197345)
30. How do I use pinned memory with multiple workers in a PyTorch DataLoader?, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/how-do-i-use-pinned-memory-with-multiple-workers-in-a-pytorch-dataloader/176927](https://discuss.pytorch.org/t/how-do-i-use-pinned-memory-with-multiple-workers-in-a-pytorch-dataloader/176927)
31. Very high CPU utilization with pin_memory=True and num_workers \> 0 \#25010 \- GitHub, дата последнего обращения: декабря 20, 2025, [https://github.com/pytorch/pytorch/issues/25010](https://github.com/pytorch/pytorch/issues/25010)
32. How do I use pinned memory with multiple workers in a PyTorch DataLoader?, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/75944587/how-do-i-use-pinned-memory-with-multiple-workers-in-a-pytorch-dataloader](https://stackoverflow.com/questions/75944587/how-do-i-use-pinned-memory-with-multiple-workers-in-a-pytorch-dataloader)
33. \[P\] Using PyTorch \+ NumPy? A bug that plagues thousands of open-source ML projects. : r/MachineLearning \- Reddit, дата последнего обращения: декабря 20, 2025, [https://www.reddit.com/r/MachineLearning/comments/mocpgj/p_using_pytorch_numpy_a_bug_that_plagues/](https://www.reddit.com/r/MachineLearning/comments/mocpgj/p_using_pytorch_numpy_a_bug_that_plagues/)
34. Reproducibility — PyTorch 2.9 documentation, дата последнего обращения: декабря 20, 2025, [https://docs.pytorch.org/docs/stable/notes/randomness.html](https://docs.pytorch.org/docs/stable/notes/randomness.html)
35. PyTorch DataLoader uses identical random transformation across each epoch, дата последнего обращения: декабря 20, 2025, [https://stackoverflow.com/questions/67196075/pytorch-dataloader-uses-identical-random-transformation-across-each-epoch](https://stackoverflow.com/questions/67196075/pytorch-dataloader-uses-identical-random-transformation-across-each-epoch)
36. Seeds for Dataloader \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/seeds-for-dataloader/205807](https://discuss.pytorch.org/t/seeds-for-dataloader/205807)
37. Dataloader fails when using num_worker\>0 in multiprocessing on ubuntu \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/dataloader-fails-when-using-num-worker-0-in-multiprocessing-on-ubuntu/116366](https://discuss.pytorch.org/t/dataloader-fails-when-using-num-worker-0-in-multiprocessing-on-ubuntu/116366)
38. DataLoader memory usage keeps increasing \- data \- PyTorch Forums, дата последнего обращения: декабря 20, 2025, [https://discuss.pytorch.org/t/dataloader-memory-usage-keeps-increasing/200461](https://discuss.pytorch.org/t/dataloader-memory-usage-keeps-increasing/200461)
39. DDP with DataLoader num_workers\>0 seems to result in GIL (CPU summing to 100%) \#18149 \- GitHub, дата последнего обращения: декабря 20, 2025, [https://github.com/Lightning-AI/pytorch-lightning/issues/18149](https://github.com/Lightning-AI/pytorch-lightning/issues/18149)
