# === quest_10_3.py ===
# Имя этого пергамента, хранящего ритуал сборки Голема из готовых блоков.
# Квест: 10.3 - Сборка Рунного Камня
# Каноническое имя Квеста, как оно записано в Великом Кодексе.
# Цель: Собрать свою первую Сверточную Нейронную Сеть (CNN) с нуля,
# Священная цель нашего ритуала.
# используя готовые "строительные блоки" из PyTorch (nn.Conv2d, nn.Linear).
# Указание, что мы будем использовать готовые артефакты.
# Мы обучим ее на классической задаче распознавания рукописных цифр MNIST.
# Указание на "учебник", который мы будем использовать.

# Мы призываем `torch` — наш Источник Маны.
import torch

# Мы призываем `torch.nn` (с псевдонимом `nn`) — главу с чертежами базовых
# блоков для Големов.
import torch.nn as nn

# Мы призываем `torch.nn.functional` (с псевдонимом `F`) — гримуар с
# "заклинаниями".
import torch.nn.functional as F

# Мы призываем `torch.optim` (с псевдонимом `optim`) — гримуар с
# "наставниками".
import torch.optim as optim

# Мы призываем `torchvision.datasets` и `torchvision.transforms` для
# работы с образами.
from torchvision import datasets, transforms

# Мы призываем наш верный "индикатор прогресса".
from tqdm import tqdm

# --- Акт 1: Подготовка "Учебника" (Данные MNIST) ---
# Начинается первый акт: мы готовим "учебные рукописи" для нашего Голема.
# Мы оглашаем на кристалл (консоль) о начале подготовки.
print("Готовлю 'учебник' с рукописными цифрами (MNIST)...")
# Мы создаем конвейер "магических линз" для подготовки изображений.
transform = transforms.Compose(
    # Начало списка трансформаций.
    [
        # Первая "линза": превращает картинку из объекта Pillow в тензор
        # PyTorch.
        transforms.ToTensor(),
        # Вторая "линза": нормализует яркость пикселей по среднему и стандартному
        # отклонению датасета MNIST.
        transforms.Normalize((0.1307,), (0.3081,)),
        # Конец списка трансформаций.
    ]
)
# Мы скачиваем и готовим "учебник" (тренировочный датасет).
train_dataset = datasets.MNIST(
    "./data", train=True, download=True, transform=transform
)
# Мы создаем "Духа-Подносчика", который будет подавать рукописи пачками по
# 64 штуки.
train_loader = torch.utils.data.DataLoader(
    train_dataset, batch_size=64, shuffle=True
)


# --- Акт 2: Чертеж Нашей "Башни Прозрения" (Модель CNN) ---
# Начинается второй акт: мы создаем "чертеж" для нашего Голема.
class MiniCNN(nn.Module):
    # Мы определяем ритуал сотворения, в котором мы создаем этажи нашей
    # "Башни".
    def __init__(self):
        # Мы произносим обязательное заклинание, призывающее дух предка
        # (`nn.Module`).
        super().__init__()
        # Мы создаем первый этаж: 1 входной канал (ч/б), 16 "гномов с фонарями",
        # трафарет 3x3.
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        # Мы создаем второй этаж: 16 входных карт, 32 "гнома", трафарет 3x3.
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        # Мы создаем "Магистра-Оценщика": он принимает "сплющенный" атлас и выдает
        # вердикт по 10 классам (цифры 0-9).
        self.fc1 = nn.Linear(32 * 7 * 7, 10)

    # Мы определяем ритуал "прямого прохода", описывающий путь сигнала через
    # "Башню".
    def forward(self, x):
        # Мы прогоняем образ через 1-й этаж, "магический переключатель" ReLU и
        # "уменьшитель" MaxPool.
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        # Мы прогоняем результат через 2-й этаж, снова с ReLU и MaxPool.
        x = F.relu(F.max_pool2d(self.conv2(x), 2))
        # Мы "сплющиваем" финальный атлас в один длинный вектор.
        x = x.view(-1, 32 * 7 * 7)
        # Мы отдаем этот вектор "Магистру-Оценщику" для вынесения вердикта.
        x = self.fc1(x)
        # Мы возвращаем логарифм вероятностей — финальный вердикт Голема.
        return F.log_softmax(x, dim=1)


# --- Акт 3: Ритуал Наставления ---
# Начинается третий, кульминационный акт: мы обучаем нашего Голема.
# Мы оглашаем на кристалл о начале ритуала.
print("Сотворяю 'Башню Прозрения' и начинаю ритуал наставления...")
# Мы сотворяем Голема по нашему чертежу и отправляем его на Кристалл Маны
# (GPU).
model = MiniCNN().to("cuda")
# Мы выбираем "наставника" (алгоритм Adam), который будет корректировать
# "разум" Голема.
optimizer = optim.Adam(model.parameters(), lr=0.01)
# Мы выбираем "меру ошибки" — как мы будем оценивать промахи Голема.
criterion = nn.CrossEntropyLoss()

# Мы проводим один полный "учебный год" (эпоху).
# Мы переводим Голема в режим "обучения".
model.train()
# Мы запускаем цикл по всем пачкам рукописей, оборачивая его в "индикатор
# прогресса".
for batch_idx, (data, target) in tqdm(
    # Мы итерируемся по нашему "Подносчику".
    enumerate(train_loader),
    # Мы указываем общее количество шагов для индикатора.
    total=len(train_loader),
    # Мы добавляем описание к индикатору прогресса.
    desc="Обучение 'Башни'",
):
    # Мы отправляем пачку изображений и их истинные метки на Кристалл Маны.
    data, target = data.to("cuda"), target.to("cuda")
    # Мы произносим заклинание "Очисти память наставника от прошлых ошибок".
    optimizer.zero_grad()
    # Наш Голем смотрит на изображения и выносит вердикт.
    output = model(data)
    # Мы сравниваем вердикт с истинными метками и вычисляем ошибку.
    loss = criterion(output, target)
    # Мы вычисляем, в какую сторону нужно исправить "разум" Голема.
    loss.backward()
    # Наш "наставник" делает шаг, исправляя "разум" (веса).
    optimizer.step()

# Мы оглашаем, что ритуал завершен, и сообщаем финальную ошибку.
print(f"\nРитуал завершен! Финальная Ошибка (Loss): {loss.item():.4f}")

# --- Акт 4: Экзамен (Проверка на одной цифре) ---
# Начинается финальный акт: мы проверяем, чему научился наш Голем.
# Мы оглашаем на кристалл о начале экзамена.
print("\nПровожу экзамен: показываю 'Башне' одну случайную цифру...")
# Мы берем один тестовый образец.
test_dataset = datasets.MNIST("./data", train=False, transform=transform)
# Мы извлекаем первый экзаменационный билет (картинку и правильный ответ).
sample_data, sample_label = test_dataset[0]

# Мы переводим Голема в режим "экзамена" (отключаем обучение).
model.eval()
# Мы используем защитное заклинание `no_grad`, так как не хотим ничего менять.
with torch.no_grad():
    # Наш Голем смотрит на незнакомую рукопись.
    output = model(sample_data.unsqueeze(0).to("cuda"))

# Мы находим вердикт с самой высокой уверенностью и извлекаем его числовое
# значение.
prediction = output.argmax(dim=1, keepdim=True).item()
# Мы оглашаем, что увидел наш Голем.
print(f"  -> 'Башня' увидела цифру: {prediction}")
# Мы оглашаем, какой был правильный ответ.
print(f"  -> Правильный ответ был: {sample_label}")
# Мы проверяем, прав ли Голем.
if prediction == sample_label:
    # Если предсказание совпало с истиной, мы оглашаем успех.
    print("  Вердикт: Успех! 'Башня Прозрения' видит!")
# Если предсказание не совпало...
else:
    # ...мы оглашаем, что требуется доработка.
    print("  Вердикт: Ошибка! 'Башня' еще требует тренировок.")
