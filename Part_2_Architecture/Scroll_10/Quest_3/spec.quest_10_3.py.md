# quest_10_3.py Specification

Погружение в Ритуал Specification: здесь Скрижаль описывает путь Архитектора-ИИ от тайных чертежей к Головному Голему и его Испытанию.

1. Meta Information

- Domain: Scripting
- Complexity: Medium
- Language: Python
- Frameworks: PyTorch, torchvision, tqdm
- Context: ../AGENTS.md

2. Goal & Purpose (Цель и Назначение)
   Легенда: Этот файл — Скрижаль, что превращает атомарные ритуалы создания нейронной сети в целый магический механизм. Задача модуля — спроектировать, собрать и обучить Сверточную Нейронную Сеть для чтения рукописных цифр MNIST, используя готовые гримуары PyTorch (nn.Conv2d, nn.Linear) и собрать “Башню Прозрения” через построение, обучение и экзамен голема. В контексте этого скрипта мы переходим от отдельных элементов к полноформатной нейронной архитектуре, которая может распознавать цифры, и завершаем испытанием на одной рукописи.

3. Interface Contract (Интерфейсный Контракт)
   Instruction for AI: Strictly implement these data structures. Do not hallucinate fields. Use TypeScript interfaces to define shapes.

3.1. Inputs (Входы)

- Source: CLI Args | STDIN | API Request | Kafka Topic | Smart Contract Call
- Format: JSON | Text | Binary | Stream
- Schema:
  - interface InputData {
    // Для этого квеста явных входных данных нет; структура сохранена для совместимости.
    }

    3.2. Outputs (Выходы)

- Destination: STDOUT
- Format: JSON | CSV | Text
- Success Criteria: Exit Code 0
- Schema:
  - interface OutputResult {
    status: 'ok' | 'error';
    details?: string;
    }

4. Implementation Details (The Source DNA / Исходный Код)

4.1. Algorithmic Logic (Для исполняемого кода)

- Ритуал подготовки эфира: подготавливаем Эфир данных MNIST. Загружаем набор изображений MNIST, применяем трансформации ToTensor и Normalize, создаём загрузчик данных с размером порции 64 и перемешиванием.
- Чертеж башни: объявляем архитектуру Голема MiniCNN. Первый этаж — свертка 1 входной канал, 16 фильтров 3×3, padding 1, stride 1; второй этаж — свертка 16 входных, 32 фильтра 3×3, padding 1, stride 1; затем выпрямляем к ленивому атласу и подаем на линейный слой 32×7×7 → 10 классов.
- Прямой путь и заклинания обучения: создаём модель на CUDA, выбираем наставника Adam с шагом обучающего процесса 0.01, используем CrossEntropyLoss как меру промаха. Переводим модель в режим обучения и проходим по всем пачкам обучающих данных, выполняем очистку градиентов, вычисляем выход, считаем потерю, выполняем обратное распространение и шаг оптимизации. В процессе отображаем прогресс через индикатор tqdm.
- Финал ритуала: печатаем итоговую ошибку Loss после завершения эпохи.
- Экзамен Голема: подготавливаем тестовый набор MNIST, выбираем первый тестовый образец, помещаем его на GPU, переводим модель в режим экзамена и без градиентов выполняем прогноз, затем выводим предсказание и правильную метку; если совпадение — объявляем успех, иначе — указания на доработку.
- Эфир лика: на выходе достаточно информации для проверки, что ритуал прошёл успешно или обнаружено отклонение, и можно продолжить обучение или отладку.

  4.2. Declarative Content (Для конфигураций и данных)
  Указ Ткачу и точные данные для воссоздания 1-в-1:

- Данные и трансформации:
  - Источник Эфира: MNIST.train и MNIST.test из torchvision.datasets, путь ./data
  - Трансформации: ToTensor() и Normalize(0.1307, 0.3081)
  - Пакет данных: train_batch_size = 64
- Архитектура Голема:
  - MiniCNN:
    - conv1: input_channels=1, output_channels=16, kernel_size=3, stride=1, padding=1
    - conv2: input_channels=16, output_channels=32, kernel_size=3, stride=1, padding=1
    - fc1: входной размер 32 _ 7 _ 7, выход 10
  - Активация: ReLU
  - Подсушивание: MaxPool2d с kernel_size=2
  - Выход: log_softmax по размерности 1
- Обучение:
  - Устройство: "cuda"
  - Оптимизатор: Adam, lr=0.01
  - Функция потерь: CrossEntropyLoss
  - Эпохи: 1
- Экзамен:
  - Тестовый набор: MNIST.train=False, transform=transform
  - Один тестовый образец: первый элемент test_dataset[0]
  - Режим: model.eval(), torch.no_grad()
  - Прогноз: output.argmax(dim=1, keepdim=True).item()
  - Вывод: печать предсказания и правильной метки, сообщение об успехе или необходимости доработок

5. Structural Decomposition (Декомпозиция структуры)

- Ключевые элементы кода:
  - MiniCNN класс: **init** с определением слоёв; forward с последовательностью применения conv → ReLU → max-pool → flatten → fc → log_softmax
  - Подготовка данных: transform, train_dataset, train_loader
  - Обучение: модель, optimizer, criterion, цикл по batches с zero_grad, forward, loss, backward, step
  - Экзамен: переключение модели в eval, no_grad, один прогон на тестовом примере
  - Приветственный вывод: печать статусов и финальных значений

6. System Context & Constraints (Системный контекст и Ограничения)

6.1. Technical Constraints

- Performance: Оптимизировано под GPU-cuDA, стандартный цикл обучения на одной эпохе
- Concurrency: Синхронный обучающий цикл (однопоточный цикл по батчам, но выполнение может распаралл بيع на GPU)
- Dependencies: PyTorch, torchvision, tqdm
- Memory: Требование к VRAM зависит от размера батча и размера модели; Script ожидает доступности CUDA

  6.2. Prohibited Actions (Negative Constraints)

- НЕ хранить секреты в открытом виде; использовать .env для секретов
- НЕ печатать сырые данные в консоль в продакшн-режиме
- НЕ использовать синхронные сетевые вызовы в критическом цикле
- НЕ оборачивать конфигурационные файлы (.yaml, .json) внутрь скриптов
- НЕ менять версии или путей при реконструкции

7. Verification & Testing (Верификация)

Герхин сценарии:

Feature: Quest 10_3 Script Functionality
Scenario: Successful execution
Given MNIST данные доступны и CUDA устройство доступно
When скрипт обучает Голема и выполняет экзамен на одной рукописи
Then финальная Loss является числом и выводится предсказание правильной цифры
Scenario: Failure due to CUDA недоступно
Given CUDA устройство недоступно
When скрипт пытается разместить модель на CUDA
Then скрипт должен завершиться с ошибкой и вывести информативное сообщение об ограничении

ИНСТРУКЦИЯ ПО РАЗДЕЛАМ В СОСТАВЕ ЭКСПЕРТИЗЫ:

- Инфо о Мета-Системе: указана студия языка, контекст проекта, рамки сложности, связанные библиотеки
- Цель: легенда без пустых вступлений; зачем этот файл и как он взаимодействует с архитектурой
- Интерфейс: чистые TS-interfaces для входов и выходов, без домыслов полей
- Реализация: описание алгоритма шаг за шагом без вставки кода
- Declarative Content: инвентарь и конфигурации 1-в-1 для воссоздания
- Декомпозиция: список функций и классов проекта
- Контекст и Ограничения: технические ограничения и запреты
- Верификация: готовые сценарии на языке Gherkin

ДОПОЛНИТЕЛЬНЫЕ СУЩЕСТВЕННЫЕ АНАЛОГИИ

- Ритуал = Скрипт
- Скрижаль = Скрижаль конфигураций
- Эфир = Данные MNIST и входные источники
- Хаос = Ошибки выполнения или недоступности вычислительных ресурсов

ЗАПОМНИ: этот артефакт посвящён quest_10_3.py и передаёт знания во Вселенной Кодекса через точную архитектуру, законченную логику и ясные тестовые сценарии, сохраняя стиль прикладной техномагии.
