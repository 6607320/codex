# **Архитектурные Основы Сверточных Нейронных Сетей: Глубокий Анализ Прототипа "Башня Прозрения" для Классификации MNIST**

## **1\. Исполнительное Резюме: От Алхимии Кода к Архитектуре Интеллекта**

Переход от манипуляции разрозненными вычислительными примитивами — тензорами и матричными умножениями — к проектированию интегрированных архитектур глубокого обучения знаменует собой фундаментальный сдвиг в квалификации специалиста по данным. В контексте рассматриваемого технологического квеста, именуемого "Сборка Рунного Камня", этот переход метафорически описывается как эволюция от начертания отдельных "рун" к возведению "Башни Прозрения". Данный отчет представляет собой исчерпывающий технический анализ архитектуры Сверточной Нейронной Сети (CNN), разработанной для решения классической задачи компьютерного зрения — распознавания рукописных цифр из набора данных MNIST.

Несмотря на то, что MNIST часто называют "Hello World" в машинном обучении, архитектурные принципы, заложенные в решение этой задачи, являются абсолютным фундаментом для промышленных систем искусственного интеллекта. Рассматриваемая в отчете модель, использующая модули nn.Conv2d и nn.Linear библиотеки PyTorch, демонстрирует полный цикл работы современного архитектора нейронных сетей: от точного математического расчета размерностей тензоров до управления динамикой градиентного спуска и интерпретации извлеченных признаков. Особое внимание в отчете уделено демистификации "магических чисел", возникающих при трансформации многомерных карт признаков в плоские векторы, а также критическому анализу процессов нормализации данных и оптимизации весов.

Мы проследим путь данных от сырых пиксельных интенсивностей через сверточные слои, выполняющие роль детекторов визуальных паттернов, к полносвязным слоям, принимающим семантические решения. Далее анализ экстраполирует эти академические концепции на реальные бизнес-сценарии, демонстрируя, как идентичные алгоритмические структуры управляют роботизированными линиями контроля качества на автомобильных заводах, обеспечивают работу бескассовых магазинов Amazon Go и помогают радиологам в ранней диагностике онкологических заболеваний легких.

## **2\. Теоретическая Физика Сверточного Слоя**

Для того чтобы понять, как "Башня Прозрения" обретает способность "видеть", необходимо углубиться в математическую природу её основного строительного блока — свертки. В отличие от полносвязных (Dense) слоев, которые рассматривают входное изображение как неупорядоченный набор пикселей, разрушая пространственную структуру, сверточные слои (Convolutional Layers) спроектированы для сохранения локальных связей и инвариантности к сдвигу.

### **2.1. Математический Механизм и Ядро Свертки**

В библиотеке PyTorch модуль nn.Conv2d реализует операцию, которая в строгом математическом смысле является взаимной корреляцией (cross-correlation), хотя в терминологии глубокого обучения повсеместно именуется сверткой. Суть операции заключается в скольжении небольшого фильтра, называемого ядром (kernel), по входному изображению или карте признаков.

Пусть $I$ — входное двумерное изображение, а $K$ — двумерное ядро размера $k\_h \\times k\_w$. Выходное значение $O(i, j)$ в позиции $(i, j)$ карты признаков вычисляется как сумма поэлементных произведений значений ядра и соответствующего участка изображения:

$$O(i, j) \= (I \* K)(i, j) \= \\sum\_{m=0}^{k\_h-1} \\sum\_{n=0}^{k\_w-1} I(i+m, j+n) \\cdot K(m, n) \+ b$$  
Где $b$ — это смещение (bias), обучаемый параметр, позволяющий сдвигать функцию активации. Ядро $K$ представляет собой набор обучаемых весов. В процессе обучения методом обратного распространения ошибки сеть автоматически подбирает такие значения весов ядра, которые позволяют ему реагировать на специфические визуальные паттерны. Например, ядро может научиться быть детектором вертикальных границ (имея положительные веса слева и отрицательные справа), детектором углов или цветовых градиентов.

Фундаментальное отличие свертки от полносвязного слоя заключается в концепции разделения весов (parameter sharing). Один и тот же фильтр применяется ко всему изображению. Это означает, что если сеть научилась распознавать горизонтальную линию в левом верхнем углу изображения, она автоматически сможет распознать её и в правом нижнем углу. Это свойство, называемое эквивариантностью к трансляции, критически важно для эффективной обработки визуальных данных и существенно снижает количество обучаемых параметров по сравнению с полносвязными сетями.1

### **2.2. Динамика Размерностей: Расчет Тензорной Геометрии**

Одной из главных компетенций Архитектора нейронных сетей является умение точно предсказывать изменение пространственных размерностей тензора при его прохождении через слои сети. В запросе "Техноманта" фигурирует выражение x \= x.view(-1, 32 \* 7 \* 7). Понимание происхождения этих чисел требует детального анализа формулы выходного размера свертки.

Размер выходной карты признаков ($O\_{dim}$) зависит от размера входа ($I\_{dim}$), размера ядра ($k$), шага свертки (stride, $s$), паддинга (padding, $p$) и дилатации (dilation, $d$). Стандартная формула в PyTorch выглядит следующим образом 1:

$$O\_{dim} \= \\left\\lfloor \\frac{I\_{dim} \+ 2p \- d \\cdot (k \- 1\) \- 1}{s} \+ 1 \\right\\rfloor$$  
В нашей архитектуре дилатация $d$ по умолчанию равна 1, что упрощает формулу до:

$$O\_{dim} \= \\left\\lfloor \\frac{I\_{dim} \- k \+ 2p}{s} \\right\\rfloor \+ 1$$

#### **2.2.1. Стратегия Padding и Сохранение Пространства**

В первом сверточном слое (conv1) архитектуры используются следующие параметры:

- Входной размер ($I\_{dim}$): $28$ (для изображения 28x28 пикселей).
- Размер ядра ($k$): $3$ (ядро 3x3).
- Паддинг ($p$): $1$.
- Шаг ($s$): $1$.

Подставим эти значения в формулу:

$$H\_{out} \= \\frac{28 \- 3 \+ 2(1)}{1} \+ 1 \= \\frac{27}{1} \+ 1 \= 28$$  
Мы видим, что выходной размер (28x28) совпадает с входным. Это не случайность, а результат осознанного выбора параметров. Такая конфигурация называется "Same Padding" (или сохраняющий паддинг). Использование padding=1 для ядра 3x3 добавляет рамку из нулей шириной в один пиксель вокруг изображения. Это позволяет центру ядра (фильтра) накладываться на самые крайние пиксели изображения. Без паддинга размер изображения уменьшался бы с каждым сверточным слоем (в данном случае до 26x26), что привело бы к быстрой потере пространственной информации и невозможности построения глубоких сетей. Кроме того, паддинг устраняет проблему "краевого эффекта", когда пиксели на границах участвуют в свертке меньше раз, чем центральные пиксели.3

#### **2.2.2. Стратегия Pooling и Агрессивное Сжатие**

Сразу за сверточными слоями в архитектуре следуют слои подвыборки (Pooling), конкретно nn.MaxPool2d. Их задача — уменьшить пространственную размерность, снизить вычислительную нагрузку и обеспечить инвариантность к малым смещениям.

Для слоя max_pool2d(kernel_size=2, stride=2) расчет выглядит так:

- Вход: $28$ (после conv1).
- Ядро: $2$.
- Шаг: $2$ (по умолчанию в PyTorch равен размеру ядра для пулинга).5
- Паддинг: $0$.

$$H\_{out} \= \\frac{28 \- 2 \+ 0}{2} \+ 1 \= 13 \+ 1 \= 14$$  
Операция Max Pooling разбивает изображение на непересекающиеся квадраты 2x2 и выбирает максимальное значение из каждого. Это уменьшает размер карты признаков ровно в два раза по каждой оси, сокращая общее количество пикселей в 4 раза, при этом сохраняя наиболее выраженные признаки.

## **3\. Деконструкция Архитектуры "Башня Прозрения"**

Архитектура, предложенная в квесте, представляет собой классическую сверточную сеть, идеологически восходящую к LeNet-5. Проследим путь тензора через все этапы, чтобы математически обосновать число $1568$ ($32 \\times 7 \\times 7$), вызвавшее вопрос у Техноманта.

### **3.1. Этап 1: Извлечение Первичных Признаков**

- **Вход:** Тензор размерности $(N, 1, 28, 28)$, где $N$ — размер батча (пакета данных), 1 — количество каналов (оттенки серого).
- **Слой:** nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1).
- **Трансформация:** Сеть применяет 32 различных фильтра. Каждый фильтр генерирует свою карту признаков. Пространственные размеры сохраняются благодаря паддингу.
- **Выход:** $(N, 32, 28, 28)$. Теперь у нас не одна картинка, а "стопка" из 32 карт, каждая из которых подчеркивает определенные детали (границы, штрихи).

### **3.2. Этап 2: Первое Пространственное Сжатие**

- **Слой:** nn.MaxPool2d(kernel_size=2, stride=2).
- **Трансформация:** Каждая из 32 карт признаков уменьшается вдвое по ширине и высоте.
- **Выход:** $(N, 32, 14, 14)$. Глубина тензора (32) остается неизменной, так как пулинг работает независимо для каждого канала.

### **3.3. Этап 3: Композиция Сложных Признаков**

- Слой: nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1).  
  (Примечание: В классических архитектурах количество каналов часто удваивается с глубиной, например, до 64\. Однако, исходя из формулы 32 \* 7 \* 7 в вопросе, в данной реализации количество выходных каналов второго слоя сохраняется равным 32, либо используется только один блок свертки-пулинга перед финальным сплющиванием, но формула подразумевает два пулинга: $28 \\to 14 \\to 7$. Следовательно, мы рассматриваем вариант с двумя этапами пулинга и сохранением 32 каналов).
- **Трансформация:** Этот слой ищет корреляции между 32 простыми признаками (например, пересечение вертикальной и горизонтальной линий), формируя более сложные паттерны. Пространственный размер снова сохраняется ($14 \\times 14$).
- **Выход:** $(N, 32, 14, 14)$.

### **3.4. Этап 4: Второе Пространственное Сжатие**

- **Слой:** nn.MaxPool2d(kernel_size=2, stride=2).
- **Трансформация:** Повторное уменьшение размерности вдвое.
- **Выход:** $(N, 32, 7, 7)$.

Именно здесь мы приходим к ответу на вопрос Техноманта. На выходе сверточной части сети мы имеем тензор, состоящий из $N$ примеров, каждый из которых представляет собой куб данных глубиной 32 и пространственным размером $7 \\times 7$.

### **3.5. Великое Сплющивание (Flattening)**

Полносвязный слой (nn.Linear), который выступает в роли классификатора ("Зал Раздумий"), математически представляет собой матричное умножение. Он не умеет работать с трехмерными структурами (каналы, высота, ширина), он понимает только плоские вектора признаков.

Поэтому необходимо выполнить операцию flatten или view:

$$\\text{Total Elements per Image} \= \\text{Channels} \\times \\text{Height} \\times \\text{Width} \= 32 \\times 7 \\times 7 \= 1568$$  
Команда x.view(-1, 32 \* 7 \* 7\) преобразует тензор формы $(N, 32, 7, 7)$ в матрицу формы $(N, 1568)$. Число $-1$ указывает PyTorch автоматически вычислить размерность батча $N$, исходя из общего количества элементов. Если архитектор ошибется в этом расчете (например, напишет 1500 вместо 1568), возникнет ошибка несовпадения размерностей (RuntimeError: shape mismatch), так как количество входных нейронов в nn.Linear жестко задано при инициализации.7

| Этап        | Операция           | Входная Размерность        | Выходная Размерность       | Описание                    |
| :---------- | :----------------- | :------------------------- | :------------------------- | :-------------------------- |
| **Вход**    | \-                 | \-                         | $1 \\times 28 \\times 28$  | Сырое изображение           |
| **Conv1**   | Свертка 3x3, pad=1 | $1 \\times 28 \\times 28$  | $32 \\times 28 \\times 28$ | Генерация 32 карт признаков |
| **Pool1**   | MaxPool 2x2        | $32 \\times 28 \\times 28$ | $32 \\times 14 \\times 14$ | Уменьшение размера в 2 раза |
| **Conv2**   | Свертка 3x3, pad=1 | $32 \\times 14 \\times 14$ | $32 \\times 14 \\times 14$ | Композиция признаков        |
| **Pool2**   | MaxPool 2x2        | $32 \\times 14 \\times 14$ | $32 \\times 7 \\times 7$   | Уменьшение размера в 2 раза |
| **Flatten** | Выпрямление        | $32 \\times 7 \\times 7$   | $1568$                     | Подготовка для Linear       |
| **Linear**  | Классификация      | $1568$                     | $10$                       | Вероятности классов (0-9)   |

## **4\. Алхимия Данных: Статистическая Нормализация MNIST**

Перед тем как данные попадут в "жернова" сверток, они должны пройти процесс предобработки. В коде квеста используется нормализация с конкретными числами: среднее (mean) **0.1307** и стандартное отклонение (std) **0.3081**. Эти значения не являются случайными "магическими константами", а представляют собой результат статистического анализа всего обучающего набора MNIST.10

### **4.1. Происхождение Констант**

Исходные изображения MNIST хранятся в формате целых чисел от 0 до 255 (градации серого).

1. **Глобальное Среднее:** Если сложить значения всех пикселей всех 60,000 изображений обучающей выборки и разделить на общее количество пикселей, мы получим значение примерно 33.31.
2. **Глобальное Отклонение:** Аналогичный расчет стандартного отклонения дает значение примерно 78.56.

Однако нейронные сети работают эффективнее с числами в диапазоне или \[-1, 1\]. Трансформация transforms.ToTensor() автоматически конвертирует изображения в диапазон , деля исходные значения на 255\.  
Следовательно, параметры нормализации также должны быть масштабированы:

- Масштабированное среднее: $33.31 / 255 \\approx 0.1307$.
- Масштабированное отклонение: $78.56 / 255 \\approx 0.3081$.12

### **4.2. Физический Смысл Нормализации**

Применение transforms.Normalize((0.1307,), (0.3081,)) выполняет операцию Z-стандартизации (Z-score normalization):

$$x\_{norm} \= \\frac{x \- \\mu}{\\sigma}$$

В результате распределение входных данных центрируется вокруг нуля и имеет единичную дисперсию. Зачем это нужно Архитектору?

1. **Симметрия Градиентов:** Если входные данные всегда положительны (например, ), то при обратном распространении ошибки градиенты весов первого слоя будут иметь одинаковый знак (все положительные или все отрицательные). Это заставляет вектор весов обновляться зигзагообразно, что замедляет сходимость. Нулевое центрирование устраняет эту проблему.
2. **Обусловленность Поверхности Ошибки:** Ненормализованные данные могут привести к тому, что поверхность функции потерь будет вытянутой (эллиптической). Градиентный спуск в таких условиях склонен к осцилляциям. Нормализация делает поверхность более сферической, позволяя оптимизатору двигаться к минимуму по более прямой траектории и использовать более высокие скорости обучения (Learning Rate).
3. **Стабильность Численных Методов:** Исключение слишком больших или слишком малых значений предотвращает проблемы затухания или взрыва градиентов в глубоких сетях.12

Важно отметить, что тестовый набор данных должен нормализовываться с использованием _тех же самых_ параметров (среднего и отклонения), вычисленных на обучающем наборе, а не на тестовом. Это обеспечивает корректность работы модели, так как она "видит" тестовые данные через ту же "призму", через которую училась.10

## **5\. Ритуал Обучения: Динамика Оптимизации**

Центральным элементом квеста является цикл обучения — "Ритуал Наставления". Этот процесс цикличен и состоит из четырех тактов: прямой проход (Forward Pass), вычисление ошибки (Loss Calculation), обратный проход (Backward Pass) и шаг оптимизатора (Optimizer Step).

### **5.1. Тайна zero_grad(): Управление Памятью Градиентов**

Начинающие Архитекторы часто забывают вызывать optimizer.zero_grad() в начале итерации, что приводит к катастрофическим последствиям. В PyTorch градиенты по умолчанию **аккумулируются** (суммируются). При вызове loss.backward() вычисленные градиенты добавляются к уже существующим значениям в атрибуте .grad каждого параметра, а не перезаписывают их.14

Этот механизм создан намеренно для реализации сложных техник, таких как Gradient Accumulation (накопление градиентов с нескольких мини-батчей для эмуляции большого размера батча при нехватке видеопамяти).16 Однако в стандартном цикле обучения нам нужны градиенты только от текущей порции данных. Если их не обнулить, градиенты будут накапливаться от эпохи к эпохе, вектор обновления весов станет огромным, и процесс оптимизации "взорвется", уводя веса в бесконечность. Команда zero_grad() очищает буфер градиентов, подготавливая "чистый лист" для новой итерации.

### **5.2. Функция Потерь: CrossEntropy и Численная Стабильность**

Для задачи многоклассовой классификации (распознавание цифр от 0 до 9\) стандартом является функция потерь перекрестной энтропии (Cross Entropy Loss):

$$H(p, q) \= \-\\sum\_{x} p(x) \\log q(x)$$

В PyTorch класс nn.CrossEntropyLoss является комбинированным инструментом. Он внутри себя последовательно применяет две операции: LogSoftmax и NLLLoss (Negative Log Likelihood).17  
Это архитектурное решение продиктовано соображениями численной стабильности. Функция Softmax использует экспоненты ($e^x$), которые могут давать очень большие числа. Взятие логарифма от очень малых чисел (близких к нулю) также проблематично. Вычисление log(softmax(x)) как единой математической операции (используя Log-Sum-Exp trick) позволяет избежать ошибок переполнения (overflow) или потери точности (underflow).

Следовательно, Архитектор не должен ставить слой Softmax в конце своей сети, если использует CrossEntropyLoss. Сеть должна выдавать "сырые" значения (логиты). Если добавить Softmax вручную, а потом подать результат в CrossEntropyLoss, функция активации будет применена дважды, что исказит вероятностную картину и ухудшит обучение.19

## **6\. Интерпретируемость: Что видит "Башня"?**

Одним из главных озарений квеста является понимание иерархической природы зрения машины. Визуализация внутренних состояний сверточной сети раскрывает процесс декомпозиции визуального образа.21

### **6.1. Слой 1: Геометрия Линий**

Если визуализировать веса 32 фильтров первого слоя, мы увидим паттерны, напоминающие фильтры Габора: наклонные штрихи под разными углами, переходы от черного к белому. На этом этапе сеть не "видит" цифру "5". Она видит лишь набор примитивов: "здесь есть вертикальная линия", "здесь есть горизонтальная граница". Это уровень локальных детекторов краев (edge detectors).22

### **6.2. Слой 2: Геометрия Форм**

На более глубоких уровнях (те самые карты 7x7) происходит комбинация примитивов. Активации здесь соответствуют более сложным структурам: углам, дугам, петлям. Например, нейрон второго слоя может активироваться, если на входе одновременно сработали детекторы "верхней дуги" и "вертикальной линии справа", что может указывать на верхнюю часть девятки.

### **6.3. Линейный Слой: Семантический Синтез**

Вектор размером 1568 подается на полносвязный слой. Этот слой уже не анализирует картинку, он анализирует _наличие признаков_. Он работает как взвешенное голосование: "Если есть верхняя петля (сильный сигнал от соответствующего нейрона) И есть нижняя дуга, но НЕТ вертикальной палки посередине, то с вероятностью 99% это цифра 8".

## **7\. Бизнес-Ценность: От MNIST к Индустрии 4.0**

Освоенные в квесте принципы — не просто учебное упражнение. Архитектура "Башни Прозрения" (свертка \-\> пулинг \-\> активация \-\> классификация) является универсальным шаблоном, лежащим в основе многомиллиардных индустрий. Рассмотрим три ключевых направления, где применяются идентичные подходы.

### **7.1. Промышленная Дефектоскопия (Manufacturing)**

В современном производстве визуальный контроль качества перестал полагаться на человеческий глаз. Системы компьютерного зрения, такие как решения от Landing AI, используют CNN для обнаружения брака.

- **Проблема:** Традиционные алгоритмы (rule-based machine vision) плохо справляются с дефектами, имеющими вариативную форму, например, порами в сварных швах, неравномерностью нанесения клея или вмятинами на отражающих поверхностях кузова автомобиля.24
- **Решение:** CNN обучается на тысячах примеров "хороших" и "плохих" деталей. Аналогично тому, как наша сеть учится игнорировать индивидуальные особенности почерка в MNIST, сохраняя суть цифры, промышленная нейросеть учится игнорировать допустимые вариации текстуры металла, но реагировать на критические аномалии (трещины, царапины).
- **Технология:** Используются более глубокие архитектуры (ResNet, U-Net), но базовый принцип свертки для выделения признаков (текстура, границы разрыва) и пулинга для обобщения остается неизменным.

### **7.2. Ритейл Будущего: Amazon Go**

Технология "Just Walk Out" в магазинах Amazon Go — это вершина применения компьютерного зрения в ритейле.

- **Задача:** Отследить, какой товар взял покупатель, и отличить его от возврата товара на полку.
- **Архитектура:** Система использует так называемый Sensor Fusion (слияние сенсоров). Данные с камер (CNN, распознающие товары) объединяются с данными весовых датчиков на полках.26
- **Окклюзия:** Одной из сложнейших проблем является окклюзия (перекрытие), когда рука покупателя или другой покупатель закрывает обзор камере. CNN в таких системах обучаются "достраивать" образ предмета по видимым фрагментам и использовать временнýю последовательность кадров (tracking), чтобы не потерять объект. Принципы устойчивости к шуму и частичному перекрытию закладываются именно на этапе тренировки сверточных слоев.
- **Edge Computing:** Для снижения задержек первичная обработка (сверточные слои) часто выполняется прямо на камерах или локальных серверах в магазине (Edge), а в облако отправляются только сжатые векторы признаков.28

### **7.3. Медицинская Визуализация: Диагностика Рака**

В здравоохранении CNN выступают в роли ассистентов радиологов, помогая обнаруживать патологии на ранних стадиях, например, легочные узлы на КТ-снимках.

- **Объемные Данные:** В отличие от плоских картинок MNIST, томография дает 3D-данные. Поэтому здесь часто применяются 3D-свертки (nn.Conv3d), где ядро перемещается не по плоскости, а по объему ($x, y, z$). Однако математика паддинга и страйда остается той же.29
- **Точность:** Системы достигают точности обнаружения узлов порядка 90-97%, что сопоставимо с показателями опытных врачей.29 Нейросеть способна заметить микроскопические паттерны плотности ткани, которые глаз человека может пропустить из\-за усталости.
- **Цена Ошибки:** Здесь, как и в обучении нашей "Башни", критически важна работа с функцией потерь и балансировка классов, так как примеров "болезни" всегда намного меньше, чем "здоровья" (проблема несбалансированных данных).

### **7.4. Финансовый Сектор: OCR и Документооборот**

Прямым наследником MNIST является оптическое распознавание символов (OCR) в банковской сфере.

- **Применение:** Автоматическое считывание рукописных сумм на чеках, цифровая обработка ипотечных анкет и инвойсов.33
- **Эффективность:** Внедрение OCR на базе CNN позволяет сократить ручной труд при вводе данных, минимизировать ошибки человеческого фактора и ускорить принятие решений по кредитам. Современные системы способны распознавать не только изолированные символы, но и слитный рукописный текст, используя рекуррентные слои поверх сверточных (CRNN).

## **8\. Заключение**

Квест 10.3 "Сборка Рунного Камня" — это не просто упражнение в написании кода на Python. Это ритуал инициации в мир глубокого обучения. Поняв, почему тензор сжимается до размера $7 \\times 7$, почему данные должны быть нормализованы к среднему 0.1307, и как "обнуление градиентов" предотвращает хаос в весах, "Техномант" обретает зрение "Архитектора".

Мы выяснили, что "магические числа" — это результат строгого детерминированного расчета, а "интуиция" нейросети — это иерархическая композиция простых геометрических детекторов. Те же самые принципы, которые позволяют "Башне Прозрения" отличить тройку от восьмерки, сегодня управляют качеством сборки автомобилей, обеспечивают работу автономных магазинов и спасают жизни через раннюю диагностику заболеваний. Вы построили фундамент, на котором стоит современный искусственный интеллект.

#### **Источники**

1. 7.3. Padding and Stride — Dive into Deep Learning 1.0.3 documentation, дата последнего обращения: декабря 19, 2025, [https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html](https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html)
2. Output Dimensions of convolution in PyTorch \- python \- Stack Overflow, дата последнего обращения: декабря 19, 2025, [https://stackoverflow.com/questions/70231487/output-dimensions-of-convolution-in-pytorch](https://stackoverflow.com/questions/70231487/output-dimensions-of-convolution-in-pytorch)
3. дата последнего обращения: декабря 19, 2025, [https://medium.com/@akp83540/padding-in-a-convolution-operation-f914efd7e8b7\#:\~:text=Then%20when%20you%20use%20the,the%20pixels%20in%20the%20middle.](https://medium.com/@akp83540/padding-in-a-convolution-operation-f914efd7e8b7#:~:text=Then%20when%20you%20use%20the,the%20pixels%20in%20the%20middle.)
4. Padding in a Convolution Operation | by Abhishek Kumar Pandey | Medium, дата последнего обращения: декабря 19, 2025, [https://medium.com/@akp83540/padding-in-a-convolution-operation-f914efd7e8b7](https://medium.com/@akp83540/padding-in-a-convolution-operation-f914efd7e8b7)
5. MaxPool2d — PyTorch 2.9 documentation \- PyTorch documentation, дата последнего обращения: декабря 19, 2025, [https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)
6. Dimensions produce by PyTorch convolution and pooling \- Cross Validated, дата последнего обращения: декабря 19, 2025, [https://stats.stackexchange.com/questions/435450/dimensions-produce-by-pytorch-convolution-and-pooling](https://stats.stackexchange.com/questions/435450/dimensions-produce-by-pytorch-convolution-and-pooling)
7. PyTorch CNN linear layer shape after conv2d \[duplicate\] \- Stack Overflow, дата последнего обращения: декабря 19, 2025, [https://stackoverflow.com/questions/65982152/pytorch-cnn-linear-layer-shape-after-conv2d](https://stackoverflow.com/questions/65982152/pytorch-cnn-linear-layer-shape-after-conv2d)
8. Linear layer input neurons number calculation after conv2d \- vision \- PyTorch Forums, дата последнего обращения: декабря 19, 2025, [https://discuss.pytorch.org/t/linear-layer-input-neurons-number-calculation-after-conv2d/28659](https://discuss.pytorch.org/t/linear-layer-input-neurons-number-calculation-after-conv2d/28659)
9. How to calculate dimensions of first linear layer of a CNN \- vision \- PyTorch Forums, дата последнего обращения: декабря 19, 2025, [https://discuss.pytorch.org/t/how-to-calculate-dimensions-of-first-linear-layer-of-a-cnn/126867](https://discuss.pytorch.org/t/how-to-calculate-dimensions-of-first-linear-layer-of-a-cnn/126867)
10. Example: classifying the MNIST dataset \- Training in Research Computing, дата последнего обращения: декабря 19, 2025, [https://mint.westdri.ca/ai/pt/pt_mnist](https://mint.westdri.ca/ai/pt/pt_mnist)
11. How mean and deviation come out with MNIST dataset? \- Data Science Stack Exchange, дата последнего обращения: декабря 19, 2025, [https://datascience.stackexchange.com/questions/46228/how-mean-and-deviation-come-out-with-mnist-dataset](https://datascience.stackexchange.com/questions/46228/how-mean-and-deviation-come-out-with-mnist-dataset)
12. python \- Correct way of normalizing and scaling the MNIST dataset ..., дата последнего обращения: декабря 19, 2025, [https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset](https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset)
13. MNIST normalizing and scaling the dataset at the same time \- vision \- PyTorch Forums, дата последнего обращения: декабря 19, 2025, [https://discuss.pytorch.org/t/mnist-normalizing-and-scaling-the-dataset-at-the-same-time/95218](https://discuss.pytorch.org/t/mnist-normalizing-and-scaling-the-dataset-at-the-same-time/95218)
14. Why Do We Need to Call zero_grad() in PyTorch? \- GeeksforGeeks, дата последнего обращения: декабря 19, 2025, [https://www.geeksforgeeks.org/deep-learning/why-do-we-need-to-call-zerograd-in-pytorch/](https://www.geeksforgeeks.org/deep-learning/why-do-we-need-to-call-zerograd-in-pytorch/)
15. Zeroing out gradients in PyTorch, дата последнего обращения: декабря 19, 2025, [https://docs.pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html](https://docs.pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html)
16. Why do we need to call zero_grad() in PyTorch? \- Stack Overflow, дата последнего обращения: декабря 19, 2025, [https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)
17. Why there is no LOG operator in implementation of torch.nn.NLLLoss \- PyTorch Forums, дата последнего обращения: декабря 19, 2025, [https://discuss.pytorch.org/t/why-there-is-no-log-operator-in-implementation-of-torch-nn-nllloss/16610](https://discuss.pytorch.org/t/why-there-is-no-log-operator-in-implementation-of-torch-nn-nllloss/16610)
18. CrossEntropyLoss — PyTorch 2.9 documentation, дата последнего обращения: декабря 19, 2025, [https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html](https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
19. What classification loss should I choose when I have used a softmax function?, дата последнего обращения: декабря 19, 2025, [https://discuss.pytorch.org/t/what-classification-loss-should-i-choose-when-i-have-used-a-softmax-function/65121](https://discuss.pytorch.org/t/what-classification-loss-should-i-choose-when-i-have-used-a-softmax-function/65121)
20. cross entropy \- PyTorch LogSoftmax vs Softmax for CrossEntropyLoss \- Stack Overflow, дата последнего обращения: декабря 19, 2025, [https://stackoverflow.com/questions/65192475/pytorch-logsoftmax-vs-softmax-for-crossentropyloss](https://stackoverflow.com/questions/65192475/pytorch-logsoftmax-vs-softmax-for-crossentropyloss)
21. Visualizing Convolutional Networks | by Vikram Pande | Medium, дата последнего обращения: декабря 19, 2025, [https://medium.com/@vikrampande783/visualizing-convolutional-networks-787810e1f6ea](https://medium.com/@vikrampande783/visualizing-convolutional-networks-787810e1f6ea)
22. CNN Explainer \- Polo Club of Data Science, дата последнего обращения: декабря 19, 2025, [https://poloclub.github.io/cnn-explainer/](https://poloclub.github.io/cnn-explainer/)
23. What can we learn from visualizing Feature Maps \- Data Science Stack Exchange, дата последнего обращения: декабря 19, 2025, [https://datascience.stackexchange.com/questions/111780/what-can-we-learn-from-visualizing-feature-maps](https://datascience.stackexchange.com/questions/111780/what-can-we-learn-from-visualizing-feature-maps)
24. 2020 State of AI-Based Machine Vision \- Landing AI, дата последнего обращения: декабря 19, 2025, [https://landing.ai/wp-content/uploads/2020/11/MachineVisionSurvey.pdf](https://landing.ai/wp-content/uploads/2020/11/MachineVisionSurvey.pdf)
25. Deep Learning for Automotive Inspection: The Landing AI and ..., дата последнего обращения: декабря 19, 2025, [https://landing.ai/wp-content/uploads/2021/08/LandingAI_CaseStudy_Automotive.pdf](https://landing.ai/wp-content/uploads/2021/08/LandingAI_CaseStudy_Automotive.pdf)
26. AMAZON GO – JUST WALKOUT TECHNOLOGY \- IJNRD, дата последнего обращения: декабря 19, 2025, [https://www.ijnrd.org/papers/IJNRD2404401.pdf](https://www.ijnrd.org/papers/IJNRD2404401.pdf)
27. How the Amazon Go Store's AI Works | by Ryan Gross | TDS Archive \- Medium, дата последнего обращения: декабря 19, 2025, [https://medium.com/data-science/how-the-amazon-go-store-works-a-deep-dive-3fde9d9939e9](https://medium.com/data-science/how-the-amazon-go-store-works-a-deep-dive-3fde9d9939e9)
28. How is computer vision implemented in Amazon Go? \- Milvus, дата последнего обращения: декабря 19, 2025, [https://milvus.io/ai-quick-reference/how-is-computer-vision-implemented-in-amazon-go](https://milvus.io/ai-quick-reference/how-is-computer-vision-implemented-in-amazon-go)
29. Lung Nodule Detection Using Convolutional ... \- Berkeley EECS, дата последнего обращения: декабря 19, 2025, [https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-27.pdf](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-27.pdf)
30. Multi-Task Deep Learning for Lung Nodule Detection and Segmentation in CT Scans: A Review \- MDPI, дата последнего обращения: декабря 19, 2025, [https://www.mdpi.com/2079-9292/14/15/3009](https://www.mdpi.com/2079-9292/14/15/3009)
31. "A convolutional neural network (CNN) for defect detection of additivel" by Musarrat Farzana Rahman \- Scholars' Mine, дата последнего обращения: декабря 19, 2025, [https://scholarsmine.mst.edu/masters_theses/8095/](https://scholarsmine.mst.edu/masters_theses/8095/)
32. Early Detection of Lung Nodules Using a Revolutionized Deep Learning Model \- MDPI, дата последнего обращения: декабря 19, 2025, [https://www.mdpi.com/2075-4418/13/22/3485](https://www.mdpi.com/2075-4418/13/22/3485)
33. Business applications of Convolutional Neural Networks \- App Solutions, дата последнего обращения: декабря 19, 2025, [https://theappsolutions.com/blog/development/convolutional-neural-networks/](https://theappsolutions.com/blog/development/convolutional-neural-networks/)
34. OCR Algorithms That Improve Business Processes | Lightpoint Global, дата последнего обращения: декабря 19, 2025, [https://lightpointglobal.com/blog/ocr-algorithm-to-improve-business-processes](https://lightpointglobal.com/blog/ocr-algorithm-to-improve-business-processes)
