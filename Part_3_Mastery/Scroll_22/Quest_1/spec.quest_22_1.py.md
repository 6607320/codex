# quest_22_1.py Specification

## 1. Meta Information

- Domain: Scripting
- Complexity: Medium
- Language: Python
- Frameworks: PyTorch, transformers, datasets, PIL
- Context: ../AGENTS.md

## 2. Goal & Purpose (Цель и Назначение)

- Context for Creator: Этот модуль представляет ритуал обучения и демонстрации применения мультимодального голема CLIP. Он берет изображение и набор текстовых гипотез, оценивает их соответствие и выводит вероятности сопоставления. Миссия — иллюстрировать переход домена между визуальным и текстовым пространством и демонстрировать базовую логику сравнения.
- Instruction for AI: Этот элемент поясняет, зачем нужен код и какова его общая идея — загрузить CLIP и процессор, подобрать изображение из набора данных, сравнить его с текстами и вывести вероятности сопоставления.

Легенда: В этом артефакте заложена практика использования мультимодального голема CLIP для сопоставления изображений и текстов, чтобы показать как работает “сдвиг домена” и как формируются вероятности соответствия между видимым и вербальным пространством.

## 3. Interface Contract (Интерфейсный Контракт)

### 3.1. Inputs (Входы)

- Source: CLI Args
- Format: JSON
- Schema (описание полей без кода):
  - text_descriptions: массив строк, каждая строка — текстовая гипотеза описания изображения
  - image_descriptor: объект с путём к изображению или данными изображения (опционально; в данном артефакте используется внутренний поток данных и изображение извлекается из набора)
  - target_label: целевая метка класса в наборе CIFAR-100 (например, 20 для кота)

  Примечание: в реальном скрипте входы напрямую не парсятся через CLI и значения задаются внутри кода, но контракт выше описывает ожидаемую форму входных данных для обвязки вокруг артефакта.

### 3.2. Outputs (Выходы)

- Destination: STDOUT
- Format: Text
- Success Criteria: Exit Code 0
- Schema (описание полей без кода):
  - results: массив объектов, каждый объект содержит описание гипотезы и соответствующую вероятность
  - verdict_message: итоговое сообщение о выводе вердикта, например заголовок “Вердикт Магического Компаса”

  Примечание: фактический вывод артефакта формируется как текстовые строки, печаталются вероятности для каждой гипотезы и финальное сообщение о завершении ритуала.

## 4. Implementation Details (The Source DNA / Исходный Код)

### 4.1. Algorithmic Logic (Для исполняемого кода)

1. Определяем устройство вычислений: если доступна CUDA, используем GPU, иначе CPU. Сообщаем выбранное устройство на рамке ритуала.
2. Призываем и призываем к жизни мультимодального голема CLIP, загружаем модель и обработчик (processor) по имени openai/clip-vit-base-patch32 и отправляем модели на выбранное устройство.
3. Загружаем эталонное изображение из набора CIFAR-100 с режимом streaming, чтобы не скачать всю книгу сразу.
4. Ищем в потоке изображения, соответствующее целевой метке класса (например, метка 20 для “кот”). Как только найдена, берем само изображение и приводим его к RGB, чтобы получить трёхканальное полотно.
5. Подготавливаем текстовые гипотезы (например: “фотография кота”, “рисунок собаки”, “пейзаж с горами”).
6. Готовим входы для CLIP через процессор: текст и изображение вместе, применяем паддинг для уравнивания длин последовательностей, переводим тензоры на устройство.
7. Прогоняем входы через модель CLIP, извлекаем logits_per_image и применяем softmax по оси гипотез, превращая их в вероятности.
8. Выводим вердикт: для каждой гипотезы печатаем вероятность сопоставления в виде процентов. Итогом становится набор вероятностей по всем гипотезам и одно общее сообщение о завершении ритуала.
9. Завершение: оформляем финальное сообщение и выход с кодом 0.

### 4.2. Declarative Content (Для конфигураций и данных)

- Артефакт основан на следующих данных:
  - Модель: openai/clip-vit-base-patch32
  - Обработчик: CLIPProcessor
  - Модель CLIP: CLIPModel
  - Набор данных: CIFAR-100, train, streaming=True
  - Целевая метка: target_label = 20 (кот)
  - Изображение: cat_image, после конвертации в RGB
  - Текстовые гипотезы: ["фотография кота", "рисунок собаки", "пейзаж с горами"]
  - Устройство: DEVICE = "cuda" если доступно, иначе "cpu"

- Лекционная последовательность:
  - Загрузка и связывание голема CLIP
  - Поиск нужной иллюстрации в потоке данных
  - Подготовка описаний и изображения
  - Прогон через голема и получение вероятностей
  - Вывод результатов и завершение ритуала

## 5. Structural Decomposition (Декомпозиция структуры)

- Функции и концептуальные блоки:
  - initialize_device: определить доступность CUDA и выбрать устройство
  - load_clip_components: загрузка CLIPModel и CLIPProcessor
  - load_and_stream_dataset: загрузка CIFAR-100 в режиме streaming
  - locate_target_image: проход по потоку и поиск изображения с нужной меткой
  - prepare_text_and_image: подготовка текстовых гипотез и изображения под входы модели
  - run_clip_inference: прогон входов через модель CLIP и получение logits_per_image
  - compute_probabilities: применение softmax и извлечение вероятностей
  - present_results: печать гипотез и их вероятностей, финальное сообщение
- Концептуальные классы (если бы были реализованы как части архитектуры):
  - CLIPActor: обертка вокруг модели и процессора
  - DataStreamer: абстракция потоковой загрузки набора CIFAR-100
  - ResultFormatter: формирование текстового вывода и финального сообщения

## 6. System Context & Constraints (Системный контекст и Ограничения)

### 6.1. Technical Constraints

- Performance: стандартный режим — оптимизирован под обычные CPU/GPU; использование streaming позволяет работать с большими наборами без полной загрузки.
- Concurrency: операции в главном потоке; внутренняя потоковая загрузка набора осуществляется через потоковую поставку элементов, но без асинхронной суперструктуры.
- Dependencies: torch, datasets, transformers, pillow (PIL)

### 6.2. Prohibited Actions (Negative Constraints)

- DO NOT хранить секреты в открытом виде в тексте файла или коде; используйте .env для чувствительных данных.
- DO NOT печатать исходные данные в консоль в продакшн-режиме без фильтрации.
- DO NOT выполнять синхронные сетевые вызовы в главном циклe, если речь идёт о динамических запросах.
- DO NOT оборачивать конфигурационные файлы (.yaml, .json) внутрь скриптов (как часть кода).
- DO NOT изменять версии библиотек или пути к моделям во время реконструкции артефакта.

## 7. Verification & Testing (Верификация)

Герхин-сценарии:

Функционал: [Script Functionality]
Сценарий: Успешное выполнение
Дано пройдена потоковая загрузка набора и найдена целевая картинка
Когда скрипт выполняется
Тогда выведутся вероятности сопоставления для каждой гипотезы и итоговое сообщение о завершении ритуала; код выхода — 0

Функционал: [Script Functionality]
Сценарий: Ошибка при отсутствии изображения
Дано набор доступен, но целевое изображение кота не найдено
Когда скрипт запускается
Тогда будет сгенерировано исключение о невозможности найти изображение кота и выполнение прекратится

ИССЛЕДУЕМЫЙ АРТЕФАКТ: quest_22_1.py
