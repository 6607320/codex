# Великий Кодекс Техномагии
# Свиток 19: Голос в Терминале
# Квест 19.2: Оживление в терминале (Симулированная версия)

# --- Часть I: Импорт Магических Гримуаров ---

# 'os' - гримуар для взаимодействия с операционной системой (например, для создания папок).
import os

# 'time' - гримуар для управления временем (например, для создания пауз в ритуале).
import time

# 'librosa' - мощная библиотека для анализа и преобразования аудио-материи.
import librosa

# 'torch' - основа всей нашей техномагии, управляет потоками маны и вычислениями на Кристалле.
import torch

# НОВЫЙ ГРИМУАР: 'gtts' (Google Text-to-Speech) - дух-глашатай, способный превращать текст в речь.
from gtts import gTTS

# 'transformers' - великий гримуар, хранящий знания о призыве готовых големов (моделей) и их конвейеров.
from transformers import (
    GPT2LMHeadModel,
    GPT2Tokenizer,
    WhisperForConditionalGeneration,
    WhisperProcessor,
    pipeline,
)

# 'numpy' (np) - магический калькулятор, незаменимый для работы с "сырой материей" данных в виде массивов.


# --- Часть II: Описание Ритуальных Функций ---
# Функции-чертежи для наших големов остаются теми же, что и в прошлых квестах.
# Их модульность - наша сила. Мы просто вызываем их, не меняя внутренностей.

# --- Шаг 0: Подготовка к ритуалу ---
# Определяем устройство ('cuda' - Кристалл Маны GPU, 'cpu' - Разум CPU), где будет вершиться магия.
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# Оповещаем о выбранном устройстве.
print(f"Магия будет вершиться на устройстве: {DEVICE}")


# --- НОВАЯ Функция 1: Создание Театральных Реквизитов (Аудиофайлов) ---
def prepare_dialogue_props(dialogue_script, lang="ru"):
    """
    Создает аудиофайлы для каждой реплики в нашем "сценарии".
    """
    # Оповещение о начале подготовительного ритуала.
    print("\n[Подготовка] Создание реквизита (аудиофайлов)...")
    # Заклинание из гримуара 'os': "Создай папку 'dialogue_audio', если ее еще не существует".
    # 'exist_ok=True' - мудрая руна, которая предотвращает ошибку, если папка уже есть.
    os.makedirs("dialogue_audio", exist_ok=True)

    # Запускаем цикл, который пройдет по каждой реплике в нашем списке-сценарии.
    # 'enumerate' - хитрый дух-счетчик, который дает нам и номер реплики (i), и ее текст (text).
    for i, text in enumerate(dialogue_script):
        # Создаем уникальное имя для файла, используя номер реплики.
        filename = f"dialogue_audio/step_{i}.mp3"
        # Сообщаем, какую именно реплику мы сейчас создаем.
        print(f"-> Создаю реплику '{text}' -> {filename}")
        # Призываем духа-глашатая 'gTTS', передавая ему текст и язык ('ru' - русский).
        tts = gTTS(text=text, lang=lang)
        # Приказываем духу "материализовать" свою речь в mp3-файл.
        tts.save(filename)
    # Сообщаем, что вся подготовка завершена.
    print("...реквизит готов.\n")


# --- Функция 2: Призыв Голема-Писца (Whisper STT) ---
def transcribe_audio(audio_path):
    """Призывает Голема-Писца (Whisper), который преобразует аудио в текст."""
    # Оповещение о призыве.
    print("[Акт 1] Призыв Голема-Писца (Whisper)...")
    # Загружаем 'процессор' - он готовит аудио-материю для понимания Големом.
    processor = WhisperProcessor.from_pretrained("openai/whisper-tiny")
    # Загружаем самого голема 'whisper-tiny' и отправляем его на Кристалл Маны.
    model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-tiny").to(
        DEVICE
    )
    # С помощью librosa читаем наш аудиофайл (mp3 или wav).
    audio_input, sample_rate = librosa.load(audio_path, sr=16000)
    # Процессор превращает звук в тензоры, понятные Голему.
    input_features = processor(
        audio_input, sampling_rate=sample_rate, return_tensors="pt"
    ).input_features.to(DEVICE)
    # Команда Голему: "Сгенерируй руны (токены) на основе услышанного".
    predicted_ids = model.generate(input_features)
    # Расшифровываем руны-токены в понятный человеку текст.
    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
    # Показываем результат работы Голема.
    print(f"-> Услышано: '{transcription}'")
    # Изгоняем голема и его компоненты из памяти.
    del model, processor
    # Принудительно очищаем Кристалл Маны (VRAM).
    torch.cuda.empty_cache()
    # Сообщаем об успешном изгнании.
    print("...Голем-Писец изгнан.")
    # Возвращаем распознанный текст.
    return transcription


# --- Функция 3: Призыв Голема-Толкователя (Intent Classifier) ---
def classify_intent(text):
    """Призывает Голема-Толкователя для определения намерения в тексте."""
    # Оповещение о призыве.
    print("[Акт 2] Призыв Голема-Толкователя...")
    # Создаем конвейер для классификации.
    classifier = pipeline(
        "zero-shot-classification", model="valhalla/distilbart-mnli-12-3", device=DEVICE
    )
    # Определяем возможные намерения, которые Голем должен распознать.
    candidate_labels = [
        "узнать погоду",
        "включить музыку",
        "рассказать шутку",
        "неизвестная команда",
    ]
    # Голем анализирует текст и выбирает наиболее подходящее намерение.
    result = classifier(text, candidate_labels)
    # Извлекаем самое вероятное намерение из результата.
    intent = result["labels"][0]
    # Показываем, какое намерение было определено.
    print(f"-> Намерение определено как: '{intent}'")
    # Изгоняем голема из памяти.
    del classifier
    # Очищаем Кристалл Маны.
    torch.cuda.empty_cache()
    # Сообщаем об изгнании.
    print("...Голем-Толкователь изгнан.")
    # Возвращаем определенное намерение.
    return intent


# --- Функция 4: Призыв Голема-Оракула (Text Generator) ---
def generate_response(intent):
    """Призывает Голема-Оракула (GPT-2) для генерации ответа на основе намерения."""
    # Оповещение о призыве.
    print("[Акт 3] Призыв Голема-Оракула...")
    # Загружаем токенизатор для 'distilgpt2'.
    tokenizer = GPT2Tokenizer.from_pretrained("distilgpt2")
    # Загружаем самого голема 'distilgpt2'.
    model = GPT2LMHeadModel.from_pretrained("distilgpt2").to(DEVICE)
    # Устанавливаем специальный токен для паддинга.
    tokenizer.pad_token = tokenizer.eos_token
    # Используем словарь для чистоты и расширяемости кода.
    prompts = {
        "узнать погоду": "Ответ на вопрос о погоде: ",
        "включить музыку": "Конечно, включаю вашу любимую музыку: ",
        "рассказать шутку": "Вот одна из моих любимых шуток: ",
        "неизвестная команда": "Я не совсем понял команду, попробуйте переформулировать: ",
    }
    # .get() - безопасный способ получить значение, если намерения нет в словаре.
    prompt = prompts.get(intent, prompts["неизвестная команда"])
    # Превращаем затравку в руны (токены).
    inputs = tokenizer(prompt, return_tensors="pt").to(DEVICE)
    # Голем генерирует продолжение текста.
    output_ids = model.generate(
        **inputs, max_length=50, num_return_sequences=1, no_repeat_ngram_size=2
    )
    # Декодируем сгенерированные руны в человеческий текст.
    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    # Изгоняем голема и его компоненты.
    del model, tokenizer
    # Очищаем Кристалл Маны.
    torch.cuda.empty_cache()
    # Сообщаем об изгнании.
    print("...Голем-Оракул изгнан.")
    # Возвращаем финальный ответ.
    return response


# --- Часть III: Ритуал "Театра Марионеток" ---
# Эта конструкция ('if __name__ == "__main__":') - священное начало любого пергамента.
if __name__ == "__main__":
    # Наш "сценарий" - список команд, которые мы хотим протестировать по очереди.
    dialogue_script = [
        "Расскажи мне шутку",
        "Какая сегодня погода?",
        "Хватит",  # Эта реплика будет нашим "словом-ключом" для выхода.
    ]

    # Шаг 1: Вызываем подготовительный ритуал, чтобы создать все аудиофайлы заранее.
    prepare_dialogue_props(dialogue_script)

    # Приветствие Мастера, выводится один раз при запуске.
    print("=" * 50)
    # Сообщение о начале симуляции.
    print("Симуляция диалога с ассистентом начинается.")
    # Финальный разделитель для красоты.
    print("=" * 50 + "\n")

    # Запускаем цикл, который пройдет по каждой реплике в нашем списке-сценарии.
    for i, text_command in enumerate(dialogue_script):
        # Используем заклинание 'сна' из гримуара 'time', чтобы создать паузу в 2 секунды.
        # Это делает симуляцию более похожей на реальный диалог.
        time.sleep(2)
        # Имитируем реплику пользователя, выводя ее в терминал.
        print(f">>> Пользователь говорит: '{text_command}'")

        # Указываем путь к нужному аудиофайлу, используя его номер.
        audio_file = f"dialogue_audio/step_{i}.mp3"

        # Шаг 2: Вызываем ритуал распознавания речи, передавая ему аудиофайл.
        command_text = transcribe_audio(audio_file)

        # Шаг 3: Проверяем, не содержит ли распознанный текст наше "слово-ключ".
        if "стоп" in command_text.lower() or "хватит" in command_text.lower():
            # Если да, выводим прощальное сообщение.
            print("\nАссистент: Повинуюсь, Мастер. Завершаю работу.")
            # И разрушаем цикл с помощью заклинания 'break'.
            break

        # Шаг 4: Проверяем, не пуст ли результат распознавания.
        if command_text.strip():
            # Если текст есть, запускаем остальную часть конвейера.
            user_intent = classify_intent(command_text)
            final_response = generate_response(user_intent)
        else:
            # Если Голем-Писец ничего не услышал, формируем ответ-извинение.
            final_response = "Я ничего не услышал."

        # Шаг 5: Выводим финальный ответ ассистента.
        print("\n" + "-" * 20 + " ОТВЕТ АССИСТЕНТА " + "-" * 20)
        # Печатаем ответ, который был либо сгенерирован, либо является сообщением об ошибке.
        print(final_response)
        # Печатаем красивую нижнюю рамку.
        print("-" * (43 + len(" ОТВЕТ АССИСТЕНТА ")) + "\n")
