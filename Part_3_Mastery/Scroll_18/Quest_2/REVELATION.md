# **Отчет о разработке системы подсчета объектов: Алгоритмическая стабилизация, Логика памяти и Интеграция YOLOv5 с OpenCV**

## **1\. Введение и Постановка Задачи**

В современной экосистеме компьютерного зрения задача автоматического подсчета объектов (Object Counting) трансформировалась из академического упражнения в критически важный инструмент бизнес-аналитики. Способность алгоритмических систем не просто детектировать наличие объектов, но и отслеживать их уникальные траектории, сохраняя идентичность во времени, лежит в основе решений для "умных городов", ритейл-аналитики и промышленной автоматизации. Данный отчет представляет собой исчерпывающее техническое руководство и исследовательский анализ, посвященный реализации скрипта для подсчета объектов с использованием архитектуры YOLOv5 и библиотеки OpenCV. Особое внимание уделяется решению проблемы "мерцания" детекции и реализации логики памяти (Tracker) для стабилизации результатов.

### **1.1 Актуальность задачи**

Запрос на разработку ("Квест 18.2") затрагивает фундаментальную проблему одноэтапных детекторов: отсутствие временной когерентности. Нейронная сеть, обрабатывающая видеопоток, воспринимает каждый кадр как независимое событие. Без дополнительного слоя логики — "памяти" — система не способна отличить нового посетителя магазина от того же человека, который на секунду был перекрыт стеллажом. Решение этой задачи требует синтеза глубокого обучения (для выделения признаков) и классических алгоритмов трекинга (для связывания данных во времени).

### **1.2 Цели и Объем Исследования**

Настоящий отчет охватывает полный цикл разработки:

1. **Теоретический базис:** Анализ архитектуры YOLOv5 и формата выходных тензоров.
2. **Алгоритмическое ядро:** Разработка математической модели трекера центроидов (Centroid Tracker) и методов ассоциации данных.
3. **Программная реализация:** Детальный разбор логики скрипта на Python, использующего PyTorch для инференса и OpenCV для визуализации.
4. **Стабилизация:** Методы сглаживания джиттера и обработки окклюзий.
5. **Прикладное значение:** Анализ применимости решения в реальных сценариях (ритейл, агротех, транспорт).

## ---

**2\. Архитектура Детекции: Глубокий Анализ YOLOv5**

Выбор архитектуры YOLOv5 (You Only Look Once v5) компании Ultralytics для решения задачи подсчета обусловлен оптимальным балансом между скоростью инференса и точностью обнаружения (mAP — mean Average Precision). В отличие от двухстадийных детекторов (например, Faster R-CNN), которые сначала генерируют регионы интереса, а затем классифицируют их, YOLOv5 решает задачу как единую регрессионную проблему, предсказывая координаты рамок и вероятности классов непосредственно из пикселей изображения за один проход.1

### **2.1 Структурные Компоненты Модели**

Понимание внутренней структуры модели критически важно для корректной интерпретации её выходных данных при написании скрипта.

- **Backbone (CSPDarknet):** Эта часть сети отвечает за извлечение признаков. Использование Cross-Stage Partial (CSP) связей позволяет модели обучаться более богатым градиентным сочетаниям при меньшем количестве вычислений. Это критично для систем реального времени, где задержка обработки кадра (latency) напрямую влияет на точность подсчета быстро движущихся объектов.
- **Neck (PANet):** Сеть агрегации путей (Path Aggregation Network) улучшает поток информации. Она помогает модели "видеть" объекты разного масштаба. В контексте подсчета это означает, что система одинаково эффективно распознает человека, стоящего прямо перед камерой, и человека, находящегося в глубине торгового зала.3
- **Head (Выходной слой):** Генерирует три типа предсказаний для каждой ячейки сетки: координаты ограничивающей рамки ($x, y, w, h$), оценку уверенности (objectness score) и распределение вероятностей по классам.

### **2.2 Выбор Модели и Ресурсные Ограничения**

Для реализации скрипта подсчета на стандартном оборудовании (CPU или потребительский GPU) оптимальным выбором является модель **YOLOv5s** (small) или **YOLOv5n** (nano). Как указывается в документации 4, модель YOLOv5s обладает размером всего около 14 МБ и обеспечивает высокую скорость работы (до 100+ FPS на GPU), что оставляет значительный запас вычислительного времени для работы логики трекинга и визуализации OpenCV.

| Модель      | Размер (пиксели) | mAPval 50-95 | Примечание                                       |
| :---------- | :--------------- | :----------- | :----------------------------------------------- |
| **YOLOv5n** | 640              | 28.0         | Сверхбыстрая, для мобильных устройств и дронов.4 |
| **YOLOv5s** | 640              | 37.4         | Рекомендуемый старт. Баланс скорости и точности. |
| **YOLOv5m** | 640              | 45.4         | Для сложных сцен с мелкими объектами.            |
| **YOLOv5l** | 640              | 49.0         | Высокая точность, требует мощного GPU.           |

Использование модели **YOLOv5x** 4 оправдано только в сценариях, где объекты крайне малы или сцена перегружена, но это существенно снизит FPS, что может негативно сказаться на качестве трекинга (объекты будут "прыгать" между кадрами слишком сильно для корректной ассоциации).

### **2.3 Формат Выходных Данных Тензора**

При загрузке модели через torch.hub.load 1 и передаче изображения, на выходе формируется объект Detections. Для программной обработки наиболее удобен формат .xyxy, который представляет собой тензор размерности $(N, 6)$, где $N$ — количество обнаруженных объектов.

Структура строки тензора:

1. **x_min** (float): Координата левого края рамки.
2. **y_min** (float): Координата верхнего края.
3. **x_max** (float): Координата правого края.
4. **y_max** (float): Координата нижнего края.
5. **confidence** (float): Уверенность модели (0.0 \- 1.0).
6. **class** (int): Индекс класса (например, 0 для 'person' в COCO).5

Именно эти "сырые" данные служат входным сигналом для нашей системы памяти. Ошибки на этапе интерпретации этого тензора (например, игнорирование масштабирования координат при ресайзе изображения 3) приводят к тому, что рамки "плывут" относительно объектов, делая точный подсчет невозможным.

## ---

**3\. Логика Памяти и Стабилизации Детекции (The Memory Logic)**

Центральным требованием задания является "логика памяти для стабилизации детекции". Без неё любой счетчик будет давать ложные срабатывания из\-за флуктуаций нейросети. Мы реализуем алгоритм, основанный на концепции **Centroid Tracking** с добавлением гистерезиса исчезновения.

### **3.1 Проблема "Мерцания" и ID-Switching**

В видеопотоке детекция объекта может пропадать на несколько кадров из\-за:

- Размытия в движении (Motion Blur).
- Частичного перекрытия (Occlusion).
- Изменения освещения или ракурса.

Если скрипт просто считает "количество рамок в кадре", то один и тот же человек, "мерцающий" 5 раз за проход, будет посчитан как 5 разных людей. Логика памяти должна присвоить объекту уникальный **ID** и удерживать его даже при временном отсутствии детекции.

### **3.2 Реализация Класса Tracker**

Для решения задачи создается класс Tracker, который хранит состояние системы. Его ключевые компоненты:

1. **Реестр объектов (objects):** Словарь, где ключ — уникальный object_id, а значение — центроид объекта $(c\_x, c\_y)$.
2. **Счетчик исчезновений (disappeared):** Словарь, хранящий количество последовательных кадров, в которых объект с данным ID не был найден.
3. **Максимальное "терпение" (max_disappeared):** Пороговое значение (например, 20-30 кадров). Если объект не обновлялся дольше этого времени, система считает, что он окончательно покинул кадр, и удаляет его из памяти ("забывает").7

#### **Алгоритм обновления трекера (Update Step)**

При поступлении новых детекций (Rects) от YOLOv5, алгоритм выполняет следующие шаги:

1. Расчет центроидов: Для каждой входящей рамки $(x\_1, y\_1, x\_2, y\_2)$ вычисляется центр:

   $$C\_x \= \\frac{x\_1 \+ x\_2}{2}, \\quad C\_y \= \\frac{y\_1 \+ y\_2}{2}$$

2. **Если объектов нет в памяти:** Все новые центроиды регистрируются как новые объекты с новыми ID.
3. **Если объекты есть:**
   - Вычисляется **Матрица Расстояний** (обычно Евклидово расстояние) между _каждым_ существующим объектом (из памяти) и _каждым_ новым входным центроидом.
   - Решается задача о назначениях (Assignment Problem). Цель — найти такие пары "Старый ID — Новый Центроид", чтобы суммарное расстояние перемещения было минимальным. Для строгой математической оптимизации используется Венгерский алгоритм (Hungarian Algorithm), но для простых сцен достаточно "жадного" подхода (найти минимум, назначить, исключить строку и столбец).
4. **Обработка сопоставлений:**
   - Для найденных пар: обновляем координаты центроида в памяти, сбрасываем счетчик disappeared в 0\.
   - Для ненайденных старых объектов: увеличиваем disappeared. Если счетчик превышает порог — удаляем ID.
   - Для ненайденных новых детекций: регистрируем как новые объекты.

Этот подход обеспечивает **стабилизацию**: даже если YOLO "потеряет" человека на 5 кадров, наш Tracker будет помнить его ID. Когда детекция вернется, она (с высокой вероятностью) будет ближе всего к последней известной позиции этого ID, и связь восстановится.8

## ---

**4\. Разработка Скрипта Подсчета: Техническая Реализация**

Ниже представлено детальное описание структуры скрипта, интегрирующего YOLOv5, OpenCV и разработанную логику памяти. Скрипт строится по модульному принципу.

### **4.1 Инициализация и Загрузка Модели**

Использование torch.hub — наиболее эффективный способ интеграции. Код должен автоматически определять доступность GPU (CUDA) для ускорения вычислений.

Python

import torch  
import cv2  
import numpy as np  
from scipy.spatial import distance as dist

\# Определение устройства  
device \= torch.device('cuda' if torch.cuda.is_available() else 'cpu')

\# Загрузка модели (автоматическое скачивание весов)  
\# Испольуем 'custom' если есть свои веса, или 'yolov5s' для COCO  
model \= torch.hub.load('ultralytics/yolov5', 'yolov5s', device=device)  
\# Настройка параметров инференса  
model.conf \= 0.5 \# Порог уверенности (Confidence Threshold)  
model.iou \= 0.45 \# Порог NMS IoU  
model.classes \= \# 0 \- индекс класса 'person' в COCO. Убрать фильтр для всех классов.

Фильтрация классов (model.classes \= ) критически важна для сценариев подсчета людей (people counting), чтобы исключить ложные срабатывания на манекены, постеры или другие объекты.10

### **4.2 Ядро Трекера (Implementation of Memory Logic)**

Реализация класса CentroidTracker является ответом на требование "включить логику памяти".

Python

class CentroidTracker:  
 def \_\_init\_\_(self, max_disappeared=50):  
 self.next_object_id \= 0  
 self.objects \= {} \# ID \-\> (centroid_x, centroid_y)  
 self.disappeared \= {} \# ID \-\> frames_missing_count  
 self.max_disappeared \= max_disappeared

    def register(self, centroid):
        self.objects\[self.next\_object\_id\] \= centroid
        self.disappeared\[self.next\_object\_id\] \= 0
        self.next\_object\_id \+= 1

    def deregister(self, object\_id):
        del self.objects\[object\_id\]
        del self.disappeared\[object\_id\]

    def update(self, rects):
        \# Если детекций нет, увеличиваем счетчик исчезновения для всех
        if len(rects) \== 0:
            for object\_id in list(self.disappeared.keys()):
                self.disappeared\[object\_id\] \+= 1
                if self.disappeared\[object\_id\] \> self.max\_disappeared:
                    self.deregister(object\_id)
            return self.objects

        \# Расчет входных центроидов
        input\_centroids \= np.zeros((len(rects), 2), dtype="int")
        for (i, (start\_x, start\_y, end\_x, end\_y)) in enumerate(rects):
            c\_x \= int((start\_x \+ end\_x) / 2.0)
            c\_y \= int((start\_y \+ end\_y) / 2.0)
            input\_centroids\[i\] \= (c\_x, c\_y)

        \# Если трекер пуст, регистрируем все входные
        if len(self.objects) \== 0:
            for i in range(0, len(input\_centroids)):
                self.register(input\_centroids\[i\])
        else:
            \# Сопоставление через Евклидово расстояние
            object\_ids \= list(self.objects.keys())
            object\_centroids \= list(self.objects.values())
            D \= dist.cdist(np.array(object\_centroids), input\_centroids)

            \# Находим минимальные значения в матрице D
            rows \= D.min(axis=1).argsort()
            cols \= D.argmin(axis=1)\[rows\]

            used\_rows \= set()
            used\_cols \= set()

            for (row, col) in zip(rows, cols):
                if row in used\_rows or col in used\_cols:
                    continue

                \# Обновляем координаты объекта
                object\_id \= object\_ids\[row\]
                self.objects\[object\_id\] \= input\_centroids\[col\]
                self.disappeared\[object\_id\] \= 0
                used\_rows.add(row)
                used\_cols.add(col)

            \# Обработка исчезнувших и новых объектов (логика, описанная в 3.2)
            \#... (код регистрации и дерегистрации)

        return self.objects

_Примечание к реализации:_ Для повышения робастности в продакшн-системах, вместо простого Евклидова расстояния часто используют IoU (Intersection over Union) или комбинацию дистанции и визуальных эмбеддингов (как в DeepSORT 8), но для базового скрипта "Квест 18.2" центроидный метод является стандартом де\-факто благодаря своей высокой скорости.

### **4.3 Логика Подсчета: Пересечение Линии (Line Crossing)**

Простой подсчет уникальных ID ненадежен, так как объекты могут топтаться на месте. Индустриальный стандарт — **подсчет пересечений виртуальной линии**.

1. Задаем линию (например, горизонтальную посередине кадра).
2. Храним траекторию движения объекта (список предыдущих центроидов).
3. Проверяем вектор перемещения:
   - Если $Y\_{prev} \< Y\_{line}$ и $Y\_{curr} \\ge Y\_{line}$ — объект движется **ВНИЗ**.
   - Если $Y\_{prev} \> Y\_{line}$ и $Y\_{curr} \\le Y\_{line}$ — объект движется **ВВЕРХ**.
4. Для исключения множественных срабатываний (когда объект стоит на линии), вводится буферная зона (гистерезис), например, $\\pm 10$ пикселей от линии. Счетчик инкрементируется только при полном проходе этой зоны.

### **4.4 Основной Цикл Обработки (Main Loop)**

Цикл while cap.isOpened(): объединяет все компоненты.

1. **Захват кадра:** ret, frame \= cap.read().
2. **Инференс:** results \= model(frame).
3. **Парсинг:** Извлечение координат из results.xyxy в список rects. Важно конвертировать тензоры в целые числа (int) для работы с OpenCV.13
4. **Трекинг:** objects \= tracker.update(rects).
5. **Визуализация:** Отрисовка линии, ID объектов и текущего счета.

## ---

**5\. Визуализация и Интерфейс с OpenCV**

Качество визуализации критично для отладки и демонстрации работы алгоритма. OpenCV предоставляет мощный инструментарий для отрисовки, но требует правильного подхода для получения эстетичного результата.

### **5.1 Прозрачные Оверлеи (Transparent Overlays)**

Отрисовка сплошных прямоугольников (cv2.rectangle) может перекрывать важные детали кадра. Более профессиональный подход, упоминаемый в исследовательских материалах 14, — использование полупрозрачных заливок.

Python

overlay \= frame.copy()  
cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 255, 0), \-1) \# Залитый прямоугольник  
alpha \= 0.4 \# Коэффициент прозрачности  
\# Смешивание изображений  
cv2.addWeighted(overlay, alpha, frame, 1 \- alpha, 0, frame)

Эта техника позволяет выделить объект, сохраняя видимость того, что находится за ним (например, номерной знак автомобиля или товар в руках покупателя).

### **5.2 Информативный Текст**

Для вывода ID и класса объекта используется cv2.putText. Чтобы текст был читаем на любом фоне (пестром или темном), необходимо:

1. Рисовать текст с обводкой (нарисовать толстый черный текст, затем тонкий белый поверх).
2. Либо рисовать фоновую "плашку" под текстом.  
   Использование шрифта cv2.FONT_HERSHEY_SIMPLEX с параметром cv2.LINE_AA (Anti-Aliased) обеспечивает сглаживание краев букв, убирая эффект "лесенки".16

## ---

**6\. Промышленные Применения и Бизнес-Ценность**

Разработанный скрипт — это не просто учебная задача, а прототип решений, используемых в различных отраслях экономики.

### **6.1 Ритейл-Аналитика**

В розничной торговле точность подсчета посетителей напрямую влияет на расчет конверсии (отношение числа покупок к числу вошедших).

- **Сценарий:** Камера над входом.
- **Применение:** Скрипт считает входящих и выходящих (In/Out). Эти данные помогают оптимизировать графики работы персонала (выводить больше кассиров в часы пик) и оценивать эффективность маркетинговых кампаний (увеличился ли трафик после запуска рекламы).18
- **Специфика:** Важна фильтрация персонала (по униформе) и групп людей. Стабилизация памяти критична при плотном потоке, когда люди перекрывают друг друга.

### **6.2 Интеллектуальные Транспортные Системы (ITS)**

Мониторинг дорожного трафика требует классификации транспортных средств.

- **Классы YOLO:** car, bus, truck, motorcycle.
- **Применение:** Оценка загруженности перекрестков, адаптивное управление светофорами.
- **Проблема:** Окклюзии крупными грузовиками. Логика памяти позволяет "держать" легковушку, пока она скрыта за автобусом, предотвращая повторный счет при её появлении.8

### **6.3 Агротех и Производство**

- **Конвейеры:** Подсчет продукции на ленте. Высокая скорость YOLOv5 позволяет работать с быстро движущимися объектами.21
- **Агро-дроны:** Подсчет скота на пастбищах или фруктов на деревьях.22 Здесь стабилизация компенсирует дрожание камеры дрона и прерывистость видимости из\-за листвы.

## ---

**7\. Оптимизация Производительности**

Для достижения реального времени (Real-Time) при работе скрипта необходимо учитывать аппаратные и программные узкие места.

| Метод Оптимизации         | Описание                                                                                                                                           | Влияние на FPS                                              |
| :------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------- |
| **CUDA / GPU**            | Перенос вычислений модели на видеокарту (model.to('cuda')).                                                                                        | Критическое (рост в 10-50 раз по сравнению с CPU).1         |
| **Half Precision (FP16)** | Использование вычислений с половинной точностью (model.half()). Поддерживается современными GPU.                                                   | Ускорение на 20-40% при минимальной потере точности.6       |
| **Изменение разрешения**  | Снижение входного разрешения (inference size) с 640 до 320 или 416\.                                                                               | Значительный рост скорости, но риск потери мелких объектов. |
| **Пропуск кадров**        | Запуск детекции YOLO только на каждом N-ном кадре (например, каждом 3-м), а в промежутках использование быстрого оптического трекера (KCF, MOSSE). | Разгрузка GPU, но усложнение логики синхронизации.          |

Важно отметить, что Python (через Global Interpreter Lock \- GIL) может стать узким местом при визуализации. Использование многопоточности (threading) для захвата кадров в отдельном потоке (cv2.VideoCapture) позволяет модели не простаивать, ожидая ввода-вывода.

## ---

**8\. Заключение**

Реализация скрипта для подсчета объектов на базе YOLOv5 и OpenCV — это комплексная инженерная задача, выходящая за рамки простого запуска нейросети. Ключевым фактором успеха является интеграция **логики памяти (Tracker)**, которая превращает хаотичный набор мгновенных детекций в структурированные траектории объектов.

Представленный подход с использованием центроидного трекинга и линейной логики подсчета обеспечивает:

1. **Высокую точность** за счет мощного экстрактора признаков YOLOv5.
2. **Стабильность результатов** благодаря алгоритмическому сглаживанию и удержанию ID при окклюзиях.
3. **Гибкость внедрения**, позволяя адаптировать решение под задачи ритейла, транспорта или промышленности путем простой смены весов модели и настройки зон подсчета.

Дальнейшее развитие системы может включать внедрение Re-Identification (ReID) сетей (как в DeepSORT) для восстановления треков после длительных исчезновений и миграцию на переферийные устройства (Edge AI) для снижения нагрузки на каналы связи.

#### **Источники**

1. Loading YOLOv5 from PyTorch Hub \- Ultralytics YOLO Docs, дата последнего обращения: декабря 21, 2025, [https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading/](https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading/)
2. A simple way of creating a custom object detection model | by Piotr Skalski \- Medium, дата последнего обращения: декабря 21, 2025, [https://medium.com/data-science/chess-rolls-or-basketball-lets-create-a-custom-object-detection-model-ef53028eac7d](https://medium.com/data-science/chess-rolls-or-basketball-lets-create-a-custom-object-detection-model-ef53028eac7d)
3. understand model output · Issue \#5304 · ultralytics/yolov5 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/ultralytics/yolov5/issues/5304](https://github.com/ultralytics/yolov5/issues/5304)
4. YOLOv5 \- PyTorch, дата последнего обращения: декабря 21, 2025, [https://pytorch.org/hub/ultralytics_yolov5/](https://pytorch.org/hub/ultralytics_yolov5/)
5. How navigate and extract information in results.pandas().xyxy\[0\] · Issue \#7180 · ultralytics/yolov5 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/ultralytics/yolov5/issues/7180](https://github.com/ultralytics/yolov5/issues/7180)
6. Custom Training Pipeline for Object Detection Models \- Towards Data Science, дата последнего обращения: декабря 21, 2025, [https://towardsdatascience.com/custom-training-pipeline-for-object-detection-models/](https://towardsdatascience.com/custom-training-pipeline-for-object-detection-models/)
7. Yolov8, Sort and DeepSort \- Medium, дата последнего обращения: декабря 21, 2025, [https://medium.com/@mosesdaudu001/yolov8-sort-and-deepsort-9aa7059cf09c](https://medium.com/@mosesdaudu001/yolov8-sort-and-deepsort-9aa7059cf09c)
8. Sort and Deep-SORT Based Multi-Object Tracking for Mobile Robotics: Evaluation with New Data Association Metrics \- MDPI, дата последнего обращения: декабря 21, 2025, [https://www.mdpi.com/2076-3417/12/3/1319](https://www.mdpi.com/2076-3417/12/3/1319)
9. Understanding Multiple Object Tracking using DeepSORT \- Learn OpenCV, дата последнего обращения: декабря 21, 2025, [https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/](https://learnopencv.com/understanding-multiple-object-tracking-using-deepsort/)
10. How to extract class(label) from webcam recognition results? · Issue \#2868 \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/ultralytics/ultralytics/issues/2868](https://github.com/ultralytics/ultralytics/issues/2868)
11. yolov5/data/coco.yaml at master \- GitHub, дата последнего обращения: декабря 21, 2025, [https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml)
12. Microsoft COCO Classes Reference List \- Roboflow Blog, дата последнего обращения: декабря 21, 2025, [https://blog.roboflow.com/microsoft-coco-classes/](https://blog.roboflow.com/microsoft-coco-classes/)
13. how do we extract the xyxy coordinates of the yolov5 detection image and crop it?, дата последнего обращения: декабря 21, 2025, [https://stackoverflow.com/questions/74928034/how-do-we-extract-the-xyxy-coordinates-of-the-yolov5-detection-image-and-crop-it](https://stackoverflow.com/questions/74928034/how-do-we-extract-the-xyxy-coordinates-of-the-yolov5-detection-image-and-crop-it)
14. Transparent overlays with OpenCV \- PyImageSearch, дата последнего обращения: декабря 21, 2025, [https://pyimagesearch.com/2016/03/07/transparent-overlays-with-opencv/](https://pyimagesearch.com/2016/03/07/transparent-overlays-with-opencv/)
15. Transparent overlays with Python OpenCV \- GeeksforGeeks, дата последнего обращения: декабря 21, 2025, [https://www.geeksforgeeks.org/python/transparent-overlays-with-python-opencv/](https://www.geeksforgeeks.org/python/transparent-overlays-with-python-opencv/)
16. Drawing Functions \- OpenCV Documentation, дата последнего обращения: декабря 21, 2025, [https://docs.opencv.org/4.x/d6/d6e/group\_\_imgproc\_\_draw.html](https://docs.opencv.org/4.x/d6/d6e/group__imgproc__draw.html)
17. Drawing Shapes and Text in Images with OpenCV \- Python in Plain English, дата последнего обращения: декабря 21, 2025, [https://python.plainenglish.io/drawing-shapes-and-text-in-images-with-opencv-00a497c919e1](https://python.plainenglish.io/drawing-shapes-and-text-in-images-with-opencv-00a497c919e1)
18. How to Measure Retail Store Traffic | Methods & Tools Explained \- \- Abakus Analytics, дата последнего обращения: декабря 21, 2025, [https://www.abakusanalytics.com/how-to-measure-retail-store-traffic/](https://www.abakusanalytics.com/how-to-measure-retail-store-traffic/)
19. People Counts: Why Camera Vision AI Is Essential for Modern Retail \- Safari AI, дата последнего обращения: декабря 21, 2025, [https://www.getsafari.ai/blog/blog-post-title-one-swyaf](https://www.getsafari.ai/blog/blog-post-title-one-swyaf)
20. Top 15 Computer Vision Use Cases with Examples \- Research AIMultiple, дата последнего обращения: декабря 21, 2025, [https://research.aimultiple.com/computer-vision-use-cases/](https://research.aimultiple.com/computer-vision-use-cases/)
21. Count Objects on a Conveyor Belt Using Computer Vision \- Roboflow Blog, дата последнего обращения: декабря 21, 2025, [https://blog.roboflow.com/counting-objects-conveyor-belt/](https://blog.roboflow.com/counting-objects-conveyor-belt/)
22. Vision-based automatic fruit counting with UAV \- arXiv, дата последнего обращения: декабря 21, 2025, [https://arxiv.org/html/2503.13080v1](https://arxiv.org/html/2503.13080v1)
23. Intelligent Integrated System for Fruit Detection Using Multi-UAV Imaging and Deep Learning \- PMC, дата последнего обращения: декабря 21, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10975253/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10975253/)
